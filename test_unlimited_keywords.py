# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ— é™åˆ¶å…³é”®è¯æå–çš„ç”¨æˆ·æ³¨æ„åŠ›ä¼˜åŒ–æ•ˆæœ
"""

import os
import sys

# æ·»åŠ å·¥ä½œæµç»„ä»¶è·¯å¾„
workflow_path = os.path.join(os.path.dirname(__file__), 'workflow', 'component')
sys.path.insert(0, workflow_path)

from volcengine_asr import VolcengineASR

def test_unlimited_keywords_extraction():
    """æµ‹è¯•æ— é™åˆ¶å…³é”®è¯æå–åŠŸèƒ½"""
    print("=" * 80)
    print("æµ‹è¯•æ— é™åˆ¶å…³é”®è¯æå–çš„ç”¨æˆ·æ³¨æ„åŠ›ä¼˜åŒ–æ•ˆæœ")
    print("=" * 80)
    
    # åˆ›å»ºASRå®ä¾‹
    asr = VolcengineASR(
        appid="6046310832",
        access_token="fMotJVOsyk6K_dDRoqM14kGdMJYBrcJY",
        doubao_token="adac0afb-5fd4-4c66-badb-370a7ff42df5",
        doubao_model="doubao-1-5-pro-32k-250115"
    )
    
    # æµ‹è¯•æ–‡æœ¬ï¼ˆæ‹†è¿ç›¸å…³å†…å®¹ï¼‰
    test_text = """ä¸­å›½ä»¥åè¿˜ä¼šæœ‰å¤§è§„æ¨¡æ‹†è¿å—ï¼Ÿç­”æ¡ˆæ˜¯ï¼šä¼šã€‚
ä»äºŒé›¶äºŒäº”å¹´å¼€å§‹ï¼Œå›½å®¶å°†æŠŠæ‹†è¿æ”¹é€ èŒƒå›´ä»ä¸‰åä¸ªåŸå¸‚æ‰©å¤§åˆ°ä¸‰ç™¾ä¸ªï¼Œå…¨é¢æ¨è¿›åŸä¸­æ‘å’Œè€æ—§å°åŒºæ›´æ–°ï¼Œå¹¶é‡æ–°æå€¡"è´§å¸åŒ–å®‰ç½®"â€”â€”ä¹Ÿå°±æ˜¯ç›´æ¥å‘æ”¾ç°é‡‘è¡¥å¿ã€‚
è¿™æ„å‘³ç€ï¼Œä¸€æ‰¹æ‹†è¿æˆ·å°†è·å¾—æ•°ç™¾ä¸‡å…ƒç”šè‡³ä¸Šåƒä¸‡å…ƒçš„è¡¥å¿æ¬¾ï¼Œç¡®å®æœ‰å¯èƒ½æˆä¸ºåƒä¸‡å¯Œç¿ã€‚ä½†å…³é”®åœ¨äºé’±æ€ä¹ˆç”¨ï¼šç”¨äºæ”¹å–„ä½æˆ¿æˆ–ç¨³å¥é…ç½®ï¼Œè´¢å¯Œæ‰èƒ½ç•™å­˜ï¼›è‹¥ç›²ç›®æ¶ˆè´¹æˆ–æŠ•æœºï¼Œä¹Ÿå¯èƒ½"ä¸€å¤œæš´å¯Œã€è½¬çœ¼å½’é›¶"ã€‚
ä¸è¿‡å»ä¸åŒï¼Œè¿™ä¸€è½®æ”¹é€ æœ‰ä¸¤ä¸ªé‡è¦å˜åŒ–ï¼š
ä¸€æ˜¯"å¤šæ‹†å°‘å»º"ã€‚å½“å‰å…¨å›½æˆ¿äº§åº“å­˜åé«˜ï¼Œæ‹†æ—§ä¸ç­‰äºå¤§å»ºï¼Œè€Œæ˜¯ä¸¥æ§æ–°å¢ä¾›åº”ã€‚
äºŒæ˜¯"æ‹†å°å»ºå¤§"ã€‚æ‹†é™¤çš„ä¸»è¦æ˜¯è€ç ´å°ï¼Œæ–°å»ºçš„åˆ™æ˜¯å¤§é¢ç§¯ã€æ”¹å–„å‹ã€èˆ’é€‚å‹ä½å®…ï¼Œæ¨åŠ¨å±…ä½å“è´¨å‡çº§ã€‚
ç›®å‰å°æˆ·å‹åº“å­˜å……è¶³ï¼Œèƒ½æ»¡è¶³åˆšéœ€ï¼Œæ”¿ç­–é‡å¿ƒå·²è½¬å‘æ”¯æŒæ”¹å–„å‹éœ€æ±‚ã€‚
è¿™ä¸€è½®ä¸æ˜¯ç®€å•æ‹†è¿ï¼Œè€Œæ˜¯é€šè¿‡åŸå¸‚æ›´æ–°ä¼˜åŒ–ä½æˆ¿ç»“æ„ã€æ¿€æ´»å†…éœ€ã€å¸¦åŠ¨ç»æµã€‚
é¢å¯¹è¿™ç¬”è¡¥å¿æ¬¾ï¼Œç†æ€§è§„åˆ’æ¯”ä¸€æ—¶è‡´å¯Œæ›´é‡è¦ã€‚
ç†è§£æ”¿ç­–æ–¹å‘ï¼Œæ‰èƒ½çœŸæ­£æŠŠæ¡æ—¶ä»£çº¢åˆ©ã€‚"""
    
    print(f"[INFO] æµ‹è¯•æ–‡æœ¬å†…å®¹:")
    print(f"  æ–‡æœ¬é•¿åº¦: {len(test_text)} å­—ç¬¦")
    print(f"  å†…å®¹ä¸»é¢˜: æ‹†è¿æ”¿ç­–ä¸è´¢å¯Œæœºä¼š")
    print()
    
    print(f"[INFO] å¼€å§‹æ— é™åˆ¶å…³é”®è¯æå–æµ‹è¯•...")
    print(f"  ğŸ¯ ç›®æ ‡: æœ€å¤§åŒ–ç”¨æˆ·æ³¨æ„åŠ›å’Œç•™å­˜")
    print(f"  ğŸ§  ç­–ç•¥: æ™ºèƒ½è¯†åˆ«é«˜ä»·å€¼è¯æ±‡ï¼Œæ— æ•°é‡é™åˆ¶")
    print()
    
    try:
        # æµ‹è¯•AIå…³é”®è¯æå–ï¼ˆæ— é™åˆ¶æ¨¡å¼ï¼‰
        print("ğŸ¤– æµ‹è¯•è±†åŒ…AIå…³é”®è¯æå–ï¼ˆæ— é™åˆ¶æ¨¡å¼ï¼‰:")
        print("-" * 60)
        
        ai_keywords = asr.extract_keywords_with_ai(test_text)
        
        if ai_keywords:
            print(f"âœ… AIæå–æˆåŠŸ: {len(ai_keywords)} ä¸ªå…³é”®è¯")
            print("ğŸ¯ å…³é”®è¯åˆ†æ:")
            
            # æŒ‰è¯æ±‡ç±»å‹åˆ†ç±»
            wealth_words = [w for w in ai_keywords if any(x in w for x in ['å¯Œ', 'é’±', 'è´¢', 'ä¸‡', 'å…ƒ', 'è¡¥å¿', 'æ”¶å…¥'])]
            policy_words = [w for w in ai_keywords if any(x in w for x in ['æ”¿ç­–', 'å›½å®¶', 'æ”¹é€ ', 'æ‹†è¿', 'å®‰ç½®'])]
            emotion_words = [w for w in ai_keywords if any(x in w for x in ['æš´å¯Œ', 'å½’é›¶', 'æœºä¼š', 'é‡è¦', 'å…³é”®'])]
            action_words = [w for w in ai_keywords if any(x in w for x in ['è·å¾—', 'å®ç°', 'æ¨åŠ¨', 'æ¿€æ´»', 'æŠŠæ¡'])]
            
            print(f"  ğŸ’° è´¢å¯Œç›¸å…³è¯æ±‡({len(wealth_words)}ä¸ª): {wealth_words[:10]}")
            print(f"  ğŸ“Š æ”¿ç­–ç›¸å…³è¯æ±‡({len(policy_words)}ä¸ª): {policy_words[:10]}")
            print(f"  ğŸ”¥ æƒ…æ„Ÿè§¦å‘è¯æ±‡({len(emotion_words)}ä¸ª): {emotion_words[:10]}")
            print(f"  ğŸš€ è¡ŒåŠ¨å¯¼å‘è¯æ±‡({len(action_words)}ä¸ª): {action_words[:10]}")
            print()
            
            print("ğŸ“‹ å®Œæ•´å…³é”®è¯åˆ—è¡¨:")
            for i, keyword in enumerate(ai_keywords, 1):
                print(f"  {i:2d}. {keyword}")
            
        else:
            print("âŒ AIå…³é”®è¯æå–å¤±è´¥ï¼Œæµ‹è¯•å¤‡ç”¨æ–¹æ³•")
        
        print("\n" + "=" * 60)
        print("ğŸ§  æµ‹è¯•æœ¬åœ°æ™ºèƒ½ç®—æ³•ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰:")
        print("-" * 60)
        
        # æµ‹è¯•å¤‡ç”¨å…³é”®è¯æå–
        local_keywords = asr._fallback_keyword_extraction(test_text)
        
        if local_keywords:
            print(f"âœ… æœ¬åœ°ç®—æ³•æå–æˆåŠŸ: {len(local_keywords)} ä¸ªå…³é”®è¯")
            print("ğŸ“‹ æœ¬åœ°ç®—æ³•å…³é”®è¯åˆ—è¡¨:")
            for i, keyword in enumerate(local_keywords, 1):
                print(f"  {i:2d}. {keyword}")
        
        print("\n" + "=" * 80)
        print("ğŸ“Š ç”¨æˆ·æ³¨æ„åŠ›ä¼˜åŒ–æ•ˆæœåˆ†æ")
        print("=" * 80)
        
        final_keywords = ai_keywords if ai_keywords else local_keywords
        
        if final_keywords:
            print(f"ğŸ¯ å…³é”®è¯è¦†ç›–ç‡åˆ†æ:")
            
            # è®¡ç®—è¦†ç›–çš„å­—ç¬¦æ•°
            covered_chars = 0
            for keyword in final_keywords:
                if keyword in test_text:
                    covered_chars += len(keyword) * test_text.count(keyword)
            
            coverage_rate = (covered_chars / len(test_text)) * 100
            print(f"  ğŸ“ˆ æ–‡æœ¬è¦†ç›–ç‡: {coverage_rate:.1f}% ({covered_chars}/{len(test_text)} å­—ç¬¦)")
            
            # åˆ†æå…³é”®è¯ç±»å‹åˆ†å¸ƒ
            high_value_count = len([w for w in final_keywords if len(w) >= 3])
            medium_value_count = len([w for w in final_keywords if len(w) == 2])
            
            print(f"  ğŸ† é«˜ä»·å€¼è¯æ±‡(3å­—ä»¥ä¸Š): {high_value_count} ä¸ª ({high_value_count/len(final_keywords)*100:.1f}%)")
            print(f"  ğŸ“ ä¸­ç­‰ä»·å€¼è¯æ±‡(2å­—): {medium_value_count} ä¸ª ({medium_value_count/len(final_keywords)*100:.1f}%)")
            
            # ç”¨æˆ·æ³¨æ„åŠ›é¢„ä¼°
            attention_score = min(100, len(final_keywords) * 2 + coverage_rate)
            retention_score = min(100, high_value_count * 3 + len(wealth_words) * 5)
            
            print(f"  ğŸ‘ï¸  é¢„ä¼°æ³¨æ„åŠ›æŒ‡æ•°: {attention_score:.0f}/100")
            print(f"  ğŸ¯ é¢„ä¼°ç•™å­˜æŒ‡æ•°: {retention_score:.0f}/100")
            
            print(f"\nğŸš€ ç”¨æˆ·ä½“éªŒä¼˜åŒ–å»ºè®®:")
            print(f"  âœ… å…³é”®è¯æ•°é‡å……è¶³ï¼Œèƒ½å¤ŸæŒç»­å¸å¼•ç”¨æˆ·æ³¨æ„åŠ›")
            print(f"  âœ… è´¢å¯Œç›¸å…³è¯æ±‡ä¸°å¯Œï¼Œæ»¡è¶³ç”¨æˆ·ç—›ç‚¹éœ€æ±‚")
            print(f"  âœ… æƒ…æ„Ÿè§¦å‘è¯æ±‡åˆç†ï¼Œèƒ½å¤Ÿæ¿€å‘ç”¨æˆ·å…´è¶£")
            print(f"  âœ… æ— æ•°é‡é™åˆ¶ç­–ç•¥æœ‰æ•ˆï¼Œæœ€å¤§åŒ–å†…å®¹ä»·å€¼")
            
            if len(final_keywords) > 20:
                print(f"  ğŸŠ å…³é”®è¯æ•°é‡ä¼˜ç§€({len(final_keywords)}ä¸ª)ï¼Œè¿œè¶…ä¼ ç»Ÿé™åˆ¶")
            elif len(final_keywords) > 15:
                print(f"  ğŸ‘ å…³é”®è¯æ•°é‡è‰¯å¥½({len(final_keywords)}ä¸ª)ï¼Œæ˜æ˜¾æ”¹å–„")
            else:
                print(f"  âš ï¸  å…³é”®è¯æ•°é‡é€‚ä¸­({len(final_keywords)}ä¸ª)ï¼Œä»æœ‰ä¼˜åŒ–ç©ºé—´")
        
        else:
            print("âŒ å…³é”®è¯æå–å®Œå…¨å¤±è´¥")
        
        print("\nâœ… æ— é™åˆ¶å…³é”®è¯æå–æµ‹è¯•å®Œæˆï¼")
        print("ğŸ’¡ å»ºè®®åœ¨å®é™…è§†é¢‘ä¸­æµ‹è¯•é«˜äº®æ•ˆæœï¼Œè§‚å¯Ÿç”¨æˆ·åé¦ˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_unlimited_keywords_extraction()