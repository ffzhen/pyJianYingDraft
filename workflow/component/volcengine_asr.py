#!/usr/bin/env python3
"""
ç«å±±å¼•æ“è¯­éŸ³è¯†åˆ«é›†æˆ
ä½¿ç”¨ç«å±±å¼•æ“ASRæ¥å£æ›¿ä»£Whisperè¿›è¡ŒéŸ³é¢‘è½¬å½•
"""

import time
import requests
import json
from typing import Dict, Any, List, Optional


class VolcengineASR:
    """ç«å±±å¼•æ“è¯­éŸ³è¯†åˆ«å®¢æˆ·ç«¯"""
    
    def __init__(self, appid: str, access_token: str, doubao_token: str = None, doubao_model: str = "doubao-1-5-pro-32k-250115"):
        """åˆå§‹åŒ–ç«å±±å¼•æ“ASRå®¢æˆ·ç«¯
        
        Args:
            appid: ç«å±±å¼•æ“ASRåº”ç”¨ID
            access_token: ç«å±±å¼•æ“ASRè®¿é—®ä»¤ç‰Œ
            doubao_token: è±†åŒ…APIè®¿é—®ä»¤ç‰Œï¼ˆç”¨äºå…³é”®è¯æå–ï¼‰
            doubao_model: è±†åŒ…æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸ºdoubao-1-5-pro-32k-250115
        """
        # ç«å±±å¼•æ“ASRé…ç½®
        self.base_url = 'https://openspeech.bytedance.com/api/v1/vc'
        self.appid = appid
        self.access_token = access_token
        
        # è±†åŒ…APIé…ç½®ï¼ˆç”¨äºå…³é”®è¯æå–ï¼‰
        self.doubao_token = doubao_token
        self.doubao_model = doubao_model
        
    def submit_audio_file(self, file_url: str, language: str = 'zh-CN') -> Optional[str]:
        """æäº¤éŸ³é¢‘æ–‡ä»¶è¿›è¡Œè¯†åˆ«
        
        Args:
            file_url: éŸ³é¢‘æ–‡ä»¶URL
            language: è¯­è¨€ä»£ç ï¼Œé»˜è®¤ä¸­æ–‡
            
        Returns:
            ä»»åŠ¡IDï¼Œå¤±è´¥è¿”å›None
        """
        print(f"[INFO] æäº¤éŸ³é¢‘æ–‡ä»¶è¿›è¡Œè¯†åˆ«: {file_url}")
        
        try:
            response = requests.post(
                f'{self.base_url}/submit',
                params={
                    'appid': self.appid,
                    'language': language,
                    'use_itn': 'True',           # å¯ç”¨é€†æ–‡æœ¬æ ‡å‡†åŒ–
                    'use_capitalize': 'True',    # å¯ç”¨é¦–å­—æ¯å¤§å†™
                    'max_lines': 1,              # æ¯è¡Œæœ€å¤š1å¥
                    'words_per_line': 10,        # æ¯è¡Œæœ€å¤š15è¯
                },
                json={
                    'url': file_url,
                },
                headers={
                    'content-type': 'application/json',
                    'Authorization': f'Bearer; {self.access_token}'
                }
            )
            
            print(f"[INFO] æäº¤å“åº”: {response.text}")
            
            if response.status_code == 200:
                result = response.json()
                if result.get('message') == 'Success':
                    job_id = result.get('id')
                    print(f"[OK] ä»»åŠ¡æäº¤æˆåŠŸï¼Œä»»åŠ¡ID: {job_id}")
                    return job_id
                else:
                    print(f"[ERROR] ä»»åŠ¡æäº¤å¤±è´¥: {result}")
                    return None
            else:
                print(f"[ERROR] HTTPé”™è¯¯: {response.status_code}, {response.text}")
                return None
                
        except Exception as e:
            print(f"[ERROR] æäº¤éŸ³é¢‘æ–‡ä»¶å¼‚å¸¸: {e}")
            return None
    
    def query_result(self, job_id: str) -> Optional[Dict[str, Any]]:
        """æŸ¥è¯¢è¯†åˆ«ç»“æœ
        
        Args:
            job_id: ä»»åŠ¡ID
            
        Returns:
            è¯†åˆ«ç»“æœï¼Œå¤±è´¥è¿”å›None
        """
        try:
            response = requests.get(
                f'{self.base_url}/query',
                params={
                    'appid': self.appid,
                    'id': job_id,
                },
                headers={
                    'Authorization': f'Bearer; {self.access_token}'
                }
            )
            
            if response.status_code == 200:
                result = response.json()
                print(f"[INFO] æŸ¥è¯¢å“åº”: {json.dumps(result, ensure_ascii=False, indent=2)}")
                return result
            else:
                print(f"[ERROR] æŸ¥è¯¢HTTPé”™è¯¯: {response.status_code}, {response.text}")
                return None
                
        except Exception as e:
            print(f"[ERROR] æŸ¥è¯¢ç»“æœå¼‚å¸¸: {e}")
            return None
    
    def wait_for_completion(self, job_id: str, max_wait_time: int = 300) -> Optional[Dict[str, Any]]:
        """ç­‰å¾…è¯†åˆ«å®Œæˆ
        
        Args:
            job_id: ä»»åŠ¡ID
            max_wait_time: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            æœ€ç»ˆè¯†åˆ«ç»“æœï¼Œå¤±è´¥è¿”å›None
        """
        print(f"[INFO] ç­‰å¾…è¯†åˆ«å®Œæˆï¼Œæœ€å¤§ç­‰å¾…æ—¶é—´: {max_wait_time}ç§’")
        
        start_time = time.time()
        wait_interval = 5  # æ¯5ç§’æŸ¥è¯¢ä¸€æ¬¡
        
        while time.time() - start_time < max_wait_time:
            result = self.query_result(job_id)
            
            if result is None:
                print("[ERROR] æŸ¥è¯¢å¤±è´¥")
                return None
            
            # æ£€æŸ¥æ˜¯å¦æœ‰utterancesæ•°æ®ï¼Œå¦‚æœæœ‰å°±è¡¨ç¤ºæˆåŠŸ
            utterances = result.get('utterances', [])
            code = result.get('code', -1)
            message = result.get('message', '')
            
            print(f"[INFO] å½“å‰çŠ¶æ€ç : {code}, æ¶ˆæ¯: {message}")
            
            if code == 0 and utterances:
                print("[OK] è¯†åˆ«å®Œæˆ!")
                return result
            elif code != 0:
                print(f"[ERROR] è¯†åˆ«å¤±è´¥! é”™è¯¯ç : {code}, æ¶ˆæ¯: {message}")
                return None
            else:
                print(f"[INFO] è¯†åˆ«è¿›è¡Œä¸­ï¼Œç­‰å¾…{wait_interval}ç§’åé‡è¯•...")
                time.sleep(wait_interval)
        
        print("[ERROR] ç­‰å¾…è¶…æ—¶")
        return None
    
    def process_audio_file(self, file_url: str, language: str = 'zh-CN') -> List[Dict[str, Any]]:
        """å®Œæ•´å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼Œè¿”å›å­—å¹•æ ¼å¼æ•°æ®
        
        Args:
            file_url: éŸ³é¢‘æ–‡ä»¶URL
            language: è¯­è¨€ä»£ç 
            
        Returns:
            å­—å¹•å¯¹è±¡æ•°ç»„
        """
        print(f"ğŸ¯ å¼€å§‹ç«å±±å¼•æ“è¯­éŸ³è¯†åˆ«: {file_url}")
        
        # 1. æäº¤ä»»åŠ¡
        job_id = self.submit_audio_file(file_url, language)
        if not job_id:
            return []
        
        # 2. ç­‰å¾…å®Œæˆ
        result = self.wait_for_completion(job_id)
        if not result:
            return []
        
        # 3. è§£æç»“æœ
        subtitles = self.parse_result_to_subtitles(result)
        print(f"[OK] ç«å±±å¼•æ“è¯†åˆ«å®Œæˆï¼Œç”Ÿæˆ {len(subtitles)} æ®µå­—å¹•")
        
        return subtitles
    
    def transcribe_audio_for_silence_detection(self, file_url: str, language: str = 'zh-CN') -> Optional[Dict[str, Any]]:
        """è½¬å½•éŸ³é¢‘ç”¨äºåœé¡¿æ£€æµ‹ï¼ˆè¿”å›åŸå§‹ASRç»“æœï¼‰
        
        Args:
            file_url: éŸ³é¢‘æ–‡ä»¶URL
            language: è¯­è¨€ä»£ç ï¼Œé»˜è®¤ä¸­æ–‡
            
        Returns:
            åŸå§‹ASRç»“æœï¼Œå¤±è´¥è¿”å›None
        """
        print(f"[INFO] è½¬å½•éŸ³é¢‘ç”¨äºåœé¡¿æ£€æµ‹: {file_url}")
        
        try:
            # æäº¤éŸ³é¢‘æ–‡ä»¶
            job_id = self.submit_audio_file(file_url, language)
            if not job_id:
                return None
            
            # ç­‰å¾…è¯†åˆ«å®Œæˆ
            result = self.wait_for_completion(job_id)
            if not result:
                return None
            
            # æ£€æŸ¥è¯†åˆ«ç»“æœ
            if result.get('code') != 0:
                print(f"[ERROR] è¯†åˆ«å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                return None
            
            utterances = result.get('utterances', [])
            if not utterances:
                print("âš ï¸ æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹")
                return None
            
            print(f"[OK] éŸ³é¢‘è½¬å½•å®Œæˆï¼Œè¯†åˆ«åˆ° {len(utterances)} ä¸ªè¯­éŸ³ç‰‡æ®µ")
            return result
            
        except Exception as e:
            print(f"[ERROR] éŸ³é¢‘è½¬å½•å¤±è´¥: {e}")
            return None
    
    def parse_result_to_subtitles(self, result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è§£æç«å±±å¼•æ“ç»“æœä¸ºå­—å¹•æ ¼å¼
        
        Args:
            result: ç«å±±å¼•æ“è¯†åˆ«ç»“æœ
            
        Returns:
            å­—å¹•å¯¹è±¡æ•°ç»„
        """
        subtitles = []
        
        try:
            # è·å–è¯†åˆ«æ•°æ® - æ ¹æ®APIæ–‡æ¡£ï¼Œutterancesåœ¨æ ¹å±‚çº§
            utterances = result.get('utterances', [])
            
            if not utterances:
                print("âš ï¸ æœªæ‰¾åˆ°è¯†åˆ«ç»“æœ")
                return []
            
            print(f"[INFO] è§£æ {len(utterances)} ä¸ªè¯­éŸ³ç‰‡æ®µ")
            
            for i, utterance in enumerate(utterances):
                text = utterance.get('text', '').strip()
                start_time = utterance.get('start_time', 0) / 1000.0  # è½¬æ¢ä¸ºç§’
                end_time = utterance.get('end_time', 0) / 1000.0      # è½¬æ¢ä¸ºç§’
                
                if text:
                    # æ¸…ç†æ–‡æœ¬ï¼ˆç§»é™¤æ ‡ç‚¹ç¬¦å·ï¼‰
                    clean_text = self.clean_text(text)
                    
                    subtitle = {
                        'text': clean_text,
                        'start': start_time,
                        'end': end_time
                    }
                    subtitles.append(subtitle)
                    
                    duration = end_time - start_time
                    print(f"   ç¬¬{i+1}æ®µ: [{start_time:.3f}s-{end_time:.3f}s] ({duration:.1f}s) {clean_text}")
            
            return subtitles
            
        except Exception as e:
            print(f"[ERROR] è§£æç»“æœå¼‚å¸¸: {e}")
            return []
    
    def clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤æ ‡ç‚¹ç¬¦å·"""
        import re
        
        # ç§»é™¤æ ‡ç‚¹ç¬¦å·ï¼Œä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—
        cleaned = re.sub(r'[^\u4e00-\u9fff\w\s]', '', text)
        
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()
        
        return cleaned
    
    def extract_keywords_with_ai(self, text: str, max_keywords: int = 10) -> List[str]:
        """ä½¿ç”¨AIæå–å…³é”®è¯
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            max_keywords: æœ€å¤§å…³é”®è¯æ•°é‡
            
        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        print(f"[INFO] ä½¿ç”¨AIæå–å…³é”®è¯: {text[:50]}...")
        
        try:
            # æ£€æŸ¥è±†åŒ…APIé…ç½®
            if not self.doubao_token:
                print("âš ï¸ æœªé…ç½®è±†åŒ…API tokenï¼Œä½¿ç”¨æœ¬åœ°ç®—æ³•")
                return self._fallback_keyword_extraction(text, max_keywords)
            
            # è±†åŒ…APIè¿›è¡Œå…³é”®è¯æå–
            response = requests.post(
                'https://ark.cn-beijing.volces.com/api/v3/chat/completions',
                headers={
                    'Content-Type': 'application/json',
                    'Authorization': f'Bearer {self.doubao_token}'  # ä½¿ç”¨è±†åŒ…token
                },
                json={
                    "model": self.doubao_model,  # ä½¿ç”¨è±†åŒ…æ¨¡å‹åç§°
                    "messages": [
                        {
                            "role": "system",
                            "content": f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å…³é”®è¯æå–ä¸“å®¶ã€‚è¯·ä»ç»™å®šçš„æ–‡æœ¬ä¸­æå–æœ€é‡è¦çš„{max_keywords}ä¸ªå…³é”®è¯ï¼Œç”¨äºè§†é¢‘å­—å¹•é«˜äº®æ˜¾ç¤ºã€‚\n\nè¦æ±‚ï¼š\n1. æå–æœ‰æ„ä¹‰çš„è¯æ±‡ï¼Œå¦‚åè¯ã€åŠ¨è¯ã€å½¢å®¹è¯\n2. é¿å…æå–åŠ©è¯ã€ä»‹è¯ã€è¿è¯ç­‰åŠŸèƒ½è¯\n3. é¿å…æå–ä¸å®Œæ•´çš„è¯ç»„ç‰‡æ®µ\n4. å…³é”®è¯é•¿åº¦åœ¨2-4ä¸ªå­—ä¹‹é—´\n5. ä¼˜å…ˆæå–æ ¸å¿ƒæ¦‚å¿µå’Œé‡è¦åŠ¨ä½œ\n6. åªè¿”å›å…³é”®è¯åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¸è¦å…¶ä»–è¯´æ˜æ–‡å­—\n\nç¤ºä¾‹ï¼š\nè¾“å…¥ï¼š'å¹´è½»äººè¦å­¦ä¼šäº«å—ç”Ÿæ´»ï¼Œåœ¨ç»æµæ¡ä»¶å…è®¸çš„æƒ…å†µä¸‹é€‚å½“åƒå–ç©ä¹'\nè¾“å‡ºï¼šå¹´è½»,äº«å—,ç”Ÿæ´»,ç»æµæ¡ä»¶,åƒå–ç©ä¹"
                        },
                        {
                            "role": "user",
                            "content": f"è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å…³é”®è¯ï¼š{text}"
                        }
                    ],
                    "max_tokens": 200,
                    "temperature": 0.3
                }
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result.get('choices', [{}])[0].get('message', {}).get('content', '')
                
                # è§£æå…³é”®è¯
                keywords = [kw.strip() for kw in content.split(',') if kw.strip()]
                keywords = keywords[:max_keywords]  # é™åˆ¶æ•°é‡
                
                print(f"[OK] AIæå–å…³é”®è¯: {keywords}")
                return keywords
            else:
                print(f"[ERROR] AIå…³é”®è¯æå–å¤±è´¥: {response.status_code}, {response.text}")
                print("[INFO] ä½¿ç”¨æœ¬åœ°æ™ºèƒ½ç®—æ³•ä½œä¸ºå¤‡ç”¨")
                return self._fallback_keyword_extraction(text, max_keywords)
                
        except Exception as e:
            print(f"[ERROR] AIå…³é”®è¯æå–å¼‚å¸¸: {e}")
            print("[INFO] ä½¿ç”¨æœ¬åœ°æ™ºèƒ½ç®—æ³•ä½œä¸ºå¤‡ç”¨")
            return self._fallback_keyword_extraction(text, max_keywords)
    
    def _fallback_keyword_extraction(self, text: str, max_keywords: int = 10) -> List[str]:
        """å¤‡ç”¨å…³é”®è¯æå–æ–¹æ³•ï¼ˆæ”¹è¿›çš„è¯é¢‘ç»Ÿè®¡ + è§„åˆ™è¿‡æ»¤ï¼‰
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            max_keywords: æœ€å¤§å…³é”®è¯æ•°é‡
            
        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        print("[INFO] ä½¿ç”¨å¤‡ç”¨å…³é”®è¯æå–æ–¹æ³•ï¼ˆæ™ºèƒ½è¯é¢‘ç»Ÿè®¡ï¼‰")
        
        import re
        from collections import Counter
        
        # ç§»é™¤æ ‡ç‚¹ç¬¦å·ï¼Œåªä¿ç•™ä¸­æ–‡å’Œè‹±æ–‡
        cleaned_text = re.sub(r'[^\u4e00-\u9fff\w\s]', '', text)
        
        # é¢„å®šä¹‰çš„å¸¸è§æœ‰æ„ä¹‰è¯æ±‡æ¨¡å¼
        meaningful_patterns = [
            # 4å­—è¯æ±‡ï¼ˆå®Œæ•´æ¦‚å¿µï¼‰
            r'(ç»æµæ¡ä»¶|äº«å—ç”Ÿæ´»|åƒå–ç©ä¹|ç§‘æŠ€å‘å±•|äººå·¥æ™ºèƒ½|å·¥ä½œæ–¹å¼|ç¤¾ä¼šè¿›æ­¥|æ— é™å¯èƒ½)',
            # 3å­—è¯æ±‡
            r'(å¹´è½»äºº|æ”¹å˜|å‘å±•|è¿›æ­¥|æœªæ¥|è§¦åŠ¨|é€€ä¼‘|æ¶ˆè´¹|é¢†åŸŸ|åº”ç”¨|ç”Ÿæ´»|å˜åŒ–)',
            # 2å­—è¯æ±‡
            r'(å¹´è½»|äº«å—|ç§‘æŠ€|æ™ºèƒ½|å·¥ä½œ|ç¤¾ä¼š|å¯èƒ½|è§¦åŠ¨|é€€ä¼‘|æ¶ˆè´¹|é¢†åŸŸ|åº”ç”¨|ç”Ÿæ´»|å˜åŒ–|å‘å±•|è¿›æ­¥|æœªæ¥)'
        ]
        
        candidate_words = []
        
        # é¦–å…ˆä½¿ç”¨é¢„å®šä¹‰æ¨¡å¼æå–
        for pattern in meaningful_patterns:
            matches = re.findall(pattern, cleaned_text)
            candidate_words.extend(matches)
        
        # ç„¶åä½¿ç”¨é€šç”¨æ¨¡å¼è¡¥å……
        # ä¼˜å…ˆæå–è¾ƒé•¿çš„è¿ç»­ä¸­æ–‡è¯æ±‡
        general_words = re.findall(r'[\u4e00-\u9fff]{2,4}', cleaned_text)
        candidate_words.extend(general_words)
        
        # æ‰©å±•åœç”¨è¯åˆ—è¡¨ï¼Œè¿‡æ»¤æ— æ„ä¹‰è¯æ±‡
        stop_words = {
            # ä»£è¯
            'æˆ‘ä»¬', 'è¿™ä¸ª', 'é‚£ä¸ª', 'ä»–ä»¬', 'å¥¹ä»¬', 'å®ƒä»¬', 'è‡ªå·±', 'å¤§å®¶',
            # å‰¯è¯å’Œè¿è¯
            'å¯ä»¥', 'åº”è¯¥', 'éå¸¸', 'æ¯”è¾ƒ', 'è¿˜æ˜¯', 'å°±æ˜¯', 'è¿™æ ·', 'é‚£æ ·', 'å› ä¸º', 'æ‰€ä»¥', 'ä½†æ˜¯', 'ç„¶å', 'å¦‚æœ',
            # ä»‹è¯å’ŒåŠ©è¯
            'åœ¨äº', 'å…³äº', 'å¯¹äº', 'ç”±äº', 'é€šè¿‡', 'æ ¹æ®', 'æŒ‰ç…§', 'ä¸ºäº†', 'æ¥è¯´', 'è€Œä¸”', 'ä¸è¿‡', 'è™½ç„¶',
            # æ—¶é—´è¯ï¼ˆå¸¸è§ä½†ä¸å¤ªé‡è¦ï¼‰
            'æ—¶å€™', 'ç°åœ¨', 'ä»¥å‰', 'ä»¥å', 'ä»Šå¤©', 'æ˜å¤©', 'æ˜¨å¤©', 'åˆšæ‰', 'é©¬ä¸Š', 'ç«‹å³',
            # ç¨‹åº¦è¯
            'ç‰¹åˆ«', 'å°¤å…¶', 'æ›´åŠ ', 'æœ€å', 'é¦–å…ˆ', 'å…¶æ¬¡', 'å¦å¤–', 'åŒæ—¶',
            # å…¶ä»–å¸¸è§ä½†æ— æ„ä¹‰çš„è¯
            'ä¸€äº›', 'ä¸€ä¸ª', 'è¿™äº›', 'é‚£äº›', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'å“ªé‡Œ'
        }
        
        # è¿‡æ»¤åœç”¨è¯å’Œè¿‡çŸ­è¯æ±‡
        filtered_words = []
        for word in candidate_words:
            if (word not in stop_words and 
                len(word) >= 2 and 
                not re.match(r'^[\u4e00-\u9fff]{1}[çš„äº†ç€è¿‡]$', word) and  # è¿‡æ»¤å¦‚"åšçš„"ã€"è¯´äº†"ç­‰
                not re.match(r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+$', word)):  # è¿‡æ»¤çº¯æ•°å­—
                filtered_words.append(word)
        
        # ç»Ÿè®¡è¯é¢‘ï¼Œä¼˜å…ˆé€‰æ‹©è¾ƒé•¿çš„è¯æ±‡
        word_freq = Counter(filtered_words)
        
        # æŒ‰è¯é¢‘å’Œé•¿åº¦æ’åºï¼ˆé•¿åº¦è¶Šé•¿æƒé‡è¶Šé«˜ï¼‰
        sorted_words = sorted(word_freq.items(), 
                            key=lambda x: (x[1], len(x[0])), 
                            reverse=True)
        
        # é¢„å®šä¹‰çš„é«˜è´¨é‡å…³é”®è¯ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        priority_keywords = [
            'ç»æµæ¡ä»¶', 'äº«å—ç”Ÿæ´»', 'åƒå–ç©ä¹', 'ç§‘æŠ€å‘å±•', 'äººå·¥æ™ºèƒ½', 'å·¥ä½œæ–¹å¼', 'ç¤¾ä¼šè¿›æ­¥',
            'å¹´è½»', 'è§¦åŠ¨', 'é€€ä¼‘', 'æ¶ˆè´¹', 'æ”¹å˜', 'å‘å±•', 'è¿›æ­¥', 'æœªæ¥', 'ç§‘æŠ€', 'æ™ºèƒ½',
            'äº«å—', 'ç”Ÿæ´»', 'é¢†åŸŸ', 'åº”ç”¨', 'å˜åŒ–'
        ]
        
        # å…ˆæå–é¢„å®šä¹‰çš„é«˜è´¨é‡å…³é”®è¯
        final_keywords = []
        for priority_word in priority_keywords:
            if priority_word in text and priority_word not in final_keywords:
                final_keywords.append(priority_word)
                if len(final_keywords) >= max_keywords:
                    break
        
        # å¦‚æœè¿˜éœ€è¦æ›´å¤šå…³é”®è¯ï¼Œä»é¢‘ç‡ç»Ÿè®¡ä¸­è¡¥å……
        if len(final_keywords) < max_keywords:
            for word, freq in sorted_words:
                if word not in final_keywords:
                    # æ£€æŸ¥æ˜¯å¦ä¸å·²é€‰æ‹©çš„å…³é”®è¯é‡å¤
                    is_duplicate = False
                    for existing in final_keywords:
                        if (word in existing or existing in word) and word != existing:
                            is_duplicate = True
                            break
                    
                    if not is_duplicate:
                        final_keywords.append(word)
                    
                    if len(final_keywords) >= max_keywords:
                        break
        
        print(f"[INFO] å¤‡ç”¨æ–¹æ³•æå–å…³é”®è¯: {final_keywords}")
        return final_keywords


def test_volcengine_asr():
    """æµ‹è¯•ç«å±±å¼•æ“ASRåŠŸèƒ½"""
    
    print("ğŸ§ª ç«å±±å¼•æ“ASRæµ‹è¯•")
    print("=" * 50)
    
    # ä½¿ç”¨æ‚¨æä¾›çš„å‡­æ®
    appid = "6046310832"
    access_token = "fMotJVOsyk6K_dDRoqM14kGdMJYBrcJY"
    
    # åˆ›å»ºASRå®¢æˆ·ç«¯
    asr = VolcengineASR(appid, access_token)
    
    # æµ‹è¯•éŸ³é¢‘æ–‡ä»¶URLï¼ˆæ‚¨éœ€è¦æä¾›ä¸€ä¸ªå¯è®¿é—®çš„éŸ³é¢‘URLï¼‰
    file_url = "https://oss.oemi.jdword.com/prod/temp/srt/V20250901152556001.wav"
    
    print(f"[INFO] æµ‹è¯•éŸ³é¢‘: {file_url}")
    print("[INFO] é¢„æœŸç»“æœ: ç”Ÿæˆç²¾ç¡®çš„å­—å¹•æ—¶é—´æˆ³")
    
    try:
        # å¤„ç†éŸ³é¢‘æ–‡ä»¶
        subtitles = asr.process_audio_file(file_url)
        
        if subtitles:
            print(f"\n[OK] è¯†åˆ«æˆåŠŸ! ç”Ÿæˆ {len(subtitles)} æ®µå­—å¹•")
            print("\nğŸ“‹ å­—å¹•å†…å®¹:")
            print("-" * 40)
            
            for i, subtitle in enumerate(subtitles, 1):
                duration = subtitle['end'] - subtitle['start']
                print(f"{i:2d}. [{subtitle['start']:6.3f}s-{subtitle['end']:6.3f}s] ({duration:4.1f}s) {subtitle['text']}")
            
            # ç”ŸæˆSRTæ–‡ä»¶
            srt_content = generate_srt(subtitles)
            
            output_path = "volcengine_test_result.srt"
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(srt_content)
            
            print(f"\nğŸ“ SRTæ–‡ä»¶å·²ä¿å­˜: {output_path}")
            
        else:
            print("[ERROR] è¯†åˆ«å¤±è´¥")
            
    except Exception as e:
        print(f"[ERROR] æµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()


def generate_srt(subtitles: List[Dict[str, Any]]) -> str:
    """ç”ŸæˆSRTæ ¼å¼å†…å®¹"""
    srt_content = []
    
    for i, subtitle in enumerate(subtitles, 1):
        start_time = subtitle['start']
        end_time = subtitle['end']
        text = subtitle['text']
        
        # è½¬æ¢ä¸ºSRTæ—¶é—´æ ¼å¼
        start_srt = seconds_to_srt_time(start_time)
        end_srt = seconds_to_srt_time(end_time)
        
        srt_content.append(f"{i}")
        srt_content.append(f"{start_srt} --> {end_srt}")
        srt_content.append(text)
        srt_content.append("")
    
    return "\n".join(srt_content)


def seconds_to_srt_time(seconds: float) -> str:
    """å°†ç§’æ•°è½¬æ¢ä¸ºSRTæ—¶é—´æ ¼å¼"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    milliseconds = int((seconds % 1) * 1000)
    
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"


if __name__ == "__main__":
    test_volcengine_asr()
