"""
åŸºäºflow.jsonçš„Pythonå®ç° - ç®€åŒ–ç‰ˆï¼ˆåªä½¿ç”¨ç«å±±å¼•æ“ASRï¼‰
ä½¿ç”¨pyJianYingDraftåŒ…é‡æ–°å®ç°è§†é¢‘ç¼–è¾‘å·¥ä½œæµé€»è¾‘
"""

import os
import json
import sys
import tempfile
import subprocess

# æ·»åŠ æœ¬åœ° pyJianYingDraft æ¨¡å—è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.join(current_dir, '..', '..')
sys.path.insert(0, project_root)

import pyJianYingDraft as draft
from pyJianYingDraft import TrackType, trange, tim, TextShadow, IntroType, TransitionType
from typing import List, Dict, Any, Optional, Tuple
import requests
from datetime import datetime
from urllib.parse import urlparse
import re
import math

# ç«å±±å¼•æ“ASR - å”¯ä¸€å­—å¹•è¯†åˆ«æ–¹æ¡ˆ
try:
    from .volcengine_asr import VolcengineASR
    from .asr_silence_processor import ASRBasedSilenceRemover, ASRSilenceDetector
except ImportError:
    # å½“ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶ï¼Œä½¿ç”¨ç»å¯¹å¯¼å…¥
    from volcengine_asr import VolcengineASR
    from asr_silence_processor import ASRBasedSilenceRemover, ASRSilenceDetector


class VideoEditingWorkflow:
    """è§†é¢‘ç¼–è¾‘å·¥ä½œæµç±»ï¼ŒåŸºäºflow.jsonçš„é€»è¾‘å®ç°"""
    
    def __init__(self, draft_folder_path: str, project_name: str = "flow_project"):
        """åˆå§‹åŒ–å·¥ä½œæµ
        
        Args:
            draft_folder_path: å‰ªæ˜ è‰ç¨¿æ–‡ä»¶å¤¹è·¯å¾„
            project_name: é¡¹ç›®åç§°
        """
        self.draft_folder = draft.DraftFolder(draft_folder_path)
        self.project_name = project_name
        self.script = None
        self.audio_duration = 0  # éŸ³é¢‘æ€»æ—¶é•¿ï¼ˆç§’ï¼‰
        self.video_duration = 0  # è§†é¢‘æ€»æ—¶é•¿ï¼ˆç§’ï¼‰
        self.project_duration = 0  # é¡¹ç›®æ€»æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œå–éŸ³è§†é¢‘æœ€é•¿è€…
        self.volcengine_asr = None  # ç«å±±å¼•æ“ASRå®¢æˆ·ç«¯
        self.silence_remover = None  # åœé¡¿ç§»é™¤å™¨
        self.digital_video_path = None  # æ•°å­—äººè§†é¢‘è·¯å¾„
        self.material_video_path = None  # ç´ æè§†é¢‘è·¯å¾„
        
        # åˆå§‹åŒ–å­—å¹•ç›¸å…³å±æ€§
        self.adjusted_subtitles = None  # è°ƒæ•´åçš„å­—å¹•ï¼ˆåœé¡¿ç§»é™¤åï¼‰
        self.original_subtitles = None  # åŸå§‹å­—å¹•ï¼ˆåœé¡¿ç§»é™¤å‰ï¼‰
        
    def _generate_unique_filename(self, prefix: str, extension: str = ".mp4") -> str:
        """ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶åï¼Œé¿å…ä¸åŒé¡¹ç›®ä¹‹é—´çš„æ–‡ä»¶å†²çª
        
        Args:
            prefix: æ–‡ä»¶åå‰ç¼€
            extension: æ–‡ä»¶æ‰©å±•å
            
        Returns:
            å”¯ä¸€çš„æ–‡ä»¶è·¯å¾„
        """
        import time
        import uuid
        
        # ä½¿ç”¨æ—¶é—´æˆ³å’ŒUUIDç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        unique_id = str(uuid.uuid4())[:8]  # ä½¿ç”¨UUIDçš„å‰8ä½
        filename = f"{prefix}_{timestamp}_{unique_id}{extension}"
        
        # ç¡®ä¿temp_materialsç›®å½•å­˜åœ¨
        os.makedirs("temp_materials", exist_ok=True)
        
        return f"temp_materials/{filename}"
    
    def initialize_asr(self, volcengine_appid: str = None, volcengine_access_token: str = None,
                       doubao_token: str = None, doubao_model: str = "ep-20241227135740-g7v7w"):
        """åˆå§‹åŒ–ç«å±±å¼•æ“ASR
        
        Args:
            volcengine_appid: ç«å±±å¼•æ“ASR AppID
            volcengine_access_token: ç«å±±å¼•æ“ASR AccessToken
            doubao_token: è±†åŒ…API Tokenï¼ˆç”¨äºæ ‡é¢˜æ‹†åˆ†ï¼‰
            doubao_model: è±†åŒ…æ¨¡å‹åç§°
        """
        if volcengine_appid and volcengine_access_token:
            self.volcengine_asr = VolcengineASR(
                appid=volcengine_appid, 
                access_token=volcengine_access_token,
                doubao_token=doubao_token,
                doubao_model=doubao_model
            )
            print(f"[OK] ç«å±±å¼•æ“ASRå·²åˆå§‹åŒ– (AppID: {volcengine_appid})")
        else:
            print("[ERROR] ASRåˆå§‹åŒ–å¤±è´¥ï¼šç¼ºå°‘å¿…éœ€çš„å‚æ•°")
            raise ValueError("å¿…é¡»æä¾› volcengine_appid å’Œ volcengine_access_token å‚æ•°")
        
    def _split_title_to_three_lines(self, title: str) -> List[str]:
        """ä½¿ç”¨è±†åŒ…æ¨¡å‹å°†æ ‡é¢˜æ™ºèƒ½æ‹†åˆ†ä¸º3è¡Œï¼›å¤±è´¥æ—¶ä½¿ç”¨æœ¬åœ°å›é€€è§„åˆ™ã€‚
        Returns: [line1, line2, line3]
        """
        title = (title or "").strip()
        if not title:
            return ["", "", ""]

        # ä¼˜å…ˆèµ°è±†åŒ…API
        try:
            if self.volcengine_asr and self.volcengine_asr.doubao_token:
                payload = {
                    "model": self.volcengine_asr.doubao_model,
                    "messages": [
                        {"role": "system", "content": (
                            "ä½ æ˜¯æ–‡æ¡ˆæ’ç‰ˆåŠ©æ‰‹ã€‚è¯·æŠŠç»™å®šä¸­æ–‡æ ‡é¢˜åˆç†æ–­å¥ä¸º3è¡Œï¼Œ" \
                            "æ¯è¡Œå°½é‡è¯­ä¹‰å®Œæ•´ã€é•¿åº¦å‡è¡¡ã€‚åªè¿”å›ä¸‰è¡Œå†…å®¹ï¼Œç”¨\nåˆ†éš”ï¼Œä¸è¦é¢å¤–è¯´æ˜ã€‚"
                        )},
                        {"role": "user", "content": f"æ ‡é¢˜ï¼š{title}\nè¾“å‡º3è¡Œï¼š"}
                    ],
                    "max_tokens": 200,
                    "temperature": 0.3
                }
                resp = requests.post(
                    'https://ark.cn-beijing.volces.com/api/v3/chat/completions',
                    headers={
                        'Content-Type': 'application/json',
                        'Authorization': f'Bearer {self.volcengine_asr.doubao_token}'
                    },
                    json=payload,
                    timeout=20
                )
                if resp.status_code == 200:
                    content = resp.json().get('choices', [{}])[0].get('message', {}).get('content', '')
                    lines = [ln.strip() for ln in content.split("\n") if ln.strip()]
                    if len(lines) >= 3:
                        return lines[:3]
        except Exception as _:
            pass

        # æœ¬åœ°å›é€€ï¼šæŒ‰ä¸­æ–‡æ ‡ç‚¹åˆ‡åˆ†ï¼Œå†å‡åŒ€åˆå¹¶åˆ°ä¸‰ä»½
        import re
        tokens = re.split(r'[ï¼Œã€‚ï¼ï¼Ÿã€;ï¼›\s]+', title)
        tokens = [t for t in tokens if t]
        if not tokens:
            # æœ€ç®€å•é€€åŒ–ï¼šå¹³å‡åˆ‡å­—ç¬¦
            n = len(title)
            a = max(1, n // 3)
            b = max(1, (n - a) // 2)
            return [title[:a], title[a:a+b], title[a+b:]]

        target = [[], [], []]
        lengths = [0, 0, 0]
        for tok in tokens:
            i = lengths.index(min(lengths))
            target[i].append(tok)
            lengths[i] += len(tok)
        return [''.join(x) for x in target]

    def add_three_line_title(self, title: str,
                             start: float = 0.0,
                             duration: Optional[float] = None,
                             *,
                             transform_y: float = 0.72,
                             line_spacing: int = 4,
                             highlight_color: Tuple[float, float, float] = (1.0, 0.7529411765, 0.2470588235),
                             track_name: str = "æ ‡é¢˜å­—å¹•è½¨é“") -> draft.TextSegment:
        """æ·»åŠ ä¸‰è¡Œæ ‡é¢˜ï¼šä¸­é—´ä¸€è¡Œé«˜äº®ã€‚
        - å­—ä½“ï¼šä¿ªé‡‘é»‘ï¼›å­—å·ï¼š15ï¼›å·¦å¯¹é½ï¼›max_line_width=0.6ï¼›è‡ªåŠ¨æ¢è¡Œ
        - transform_y=0.72ï¼›è¡Œé—´è·å¯é…
        """
        if not self.script:
            raise ValueError("è¯·å…ˆåˆ›å»ºè‰ç¨¿")

        lines = self._split_title_to_three_lines(title)
        # ä¿éšœä¸‰è¡Œ
        while len(lines) < 3:
            lines.append("")
        text = "\n".join(lines[:3])

        # è®¡ç®—æ—¶é—´
        if duration is None:
            base = self.project_duration or self.audio_duration or 5.0
            duration = max(1.0, min(base, base))

        style = draft.TextStyle(
            size=15.0,
            bold=True,
            align=0,  # å·¦å¯¹é½
            color=(1.0, 1.0, 1.0),
            auto_wrapping=True,
            max_line_width=0.7,
            line_spacing=line_spacing
        )

        seg = draft.TextSegment(
            text,
            trange(tim(f"{start}s"), tim(f"{duration}s")),
            font=draft.FontType.ä¿ªé‡‘é»‘,
            style=style,
            clip_settings=draft.ClipSettings(transform_y=transform_y)
        )

        # ä¸­é—´è¡Œé«˜äº®ï¼šè®¡ç®—å­—ç¬¦åŒºé—´
        line1 = lines[0]
        line2 = lines[1]
        start_idx = len(line1) + 1  # åŒ…å«æ¢è¡Œ
        end_idx = start_idx + len(line2)
        if len(line2) > 0:
            seg.add_highlight(start_idx, end_idx, color=highlight_color, bold=True)

        # ç¡®ä¿è½¨é“ï¼ˆæŒ‰è°ƒç”¨é¡ºåºè®¾ç½®å±‚çº§ï¼‰
        try:
            _ = self.script.tracks[track_name]
        except KeyError:
            # è®¡ç®—ä¸‹ä¸€ä¸ªå¯ç”¨çš„ç›¸å¯¹ç´¢å¼•ï¼ˆåŸºäºç°æœ‰è½¨é“æ•°é‡ï¼‰
            existing_text_tracks = [name for name in self.script.tracks.keys() 
                                  if self.script.tracks[name].track_type == TrackType.text]
            next_index = len(existing_text_tracks) + 1
            self.script.add_track(TrackType.text, track_name, relative_index=next_index)

        self.script.add_segment(seg, track_name=track_name)
        print(f"[OK] ä¸‰è¡Œæ ‡é¢˜å·²æ·»åŠ åˆ° {track_name}: {lines}")
        return seg

    def _update_project_duration(self):
        """æ›´æ–°é¡¹ç›®æ€»æ—¶é•¿ï¼Œå–éŸ³è§†é¢‘ä¸­çš„æœ€é•¿è€…"""
        self.project_duration = max(self.audio_duration, self.video_duration)
        if self.project_duration > 0:
            print(f"[INFO] é¡¹ç›®æ€»æ—¶é•¿æ›´æ–°ä¸º: {self.project_duration:.1f} ç§’ (éŸ³é¢‘: {self.audio_duration:.1f}s, è§†é¢‘: {self.video_duration:.1f}s)")
        
    def download_material(self, url: str, local_path: str) -> str:
        """ä¸‹è½½ç½‘ç»œç´ æåˆ°æœ¬åœ°
        
        Args:
            url: ç´ æURL
            local_path: æœ¬åœ°ä¿å­˜è·¯å¾„
            
        Returns:
            æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœä¸‹è½½æˆåŠŸï¼‰æˆ–åŸå§‹URLï¼ˆå¦‚æœä¸‹è½½å¤±è´¥ï¼‰
        """
        if not url or url.startswith('file://') or os.path.exists(url):
            return url
            
        try:
            print(f"[DEBUG] å°è¯•ä¸‹è½½: {url} -> {local_path}")
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(local_path), exist_ok=True)
            
            with open(local_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            print(f"[DEBUG] ä¸‹è½½æˆåŠŸ: {local_path}")
            return local_path
        except Exception as e:
            print(f"[DEBUG] ä¸‹è½½å¤±è´¥: {url}, é”™è¯¯: {e}")
            print(f"[DEBUG] è¿”å›åŸå§‹URL: {url}")
            return url  # è¿”å›åŸURLï¼Œè®©ç”¨æˆ·å¤„ç†
    
    def create_draft(self, width: int = 1080, height: int = 1920, fps: int = 30):
        """åˆ›å»ºå‰ªæ˜ è‰ç¨¿
        
        Args:
            width: è§†é¢‘å®½åº¦
            height: è§†é¢‘é«˜åº¦  
            fps: å¸§ç‡
        """
        try:
            self.script = self.draft_folder.create_draft(
                self.project_name, width, height, allow_replace=True
            )
        except PermissionError as e:
            # å¯èƒ½å­˜åœ¨ .locked æ–‡ä»¶æˆ–è‰ç¨¿è¢«å ç”¨ï¼›å›é€€ä¸ºæ—¶é—´æˆ³æ–°åç§°é¿å…å†²çª
            ts = datetime.now().strftime('%Y%m%d_%H%M%S')
            fallback_name = f"{self.project_name}_{ts}"
            print(f"[WARN] å‘ç°é”å®šæ–‡ä»¶æˆ–å ç”¨ï¼Œåˆ‡æ¢åˆ°æ–°é¡¹ç›®åç§°: {fallback_name}")
            self.project_name = fallback_name
            self.script = self.draft_folder.create_draft(
                self.project_name, width, height, allow_replace=False
            )
        except Exception as e:
            # å…¶ä»–å¼‚å¸¸ä¹Ÿå°è¯•ä½¿ç”¨æ—¶é—´æˆ³æ–°åç§°
            ts = datetime.now().strftime('%Y%m%d_%H%M%S')
            fallback_name = f"{self.project_name}_{ts}"
            print(f"âš ï¸  åˆ›å»ºè‰ç¨¿å¤±è´¥({e})ï¼Œæ”¹ç”¨æ–°é¡¹ç›®åç§°: {fallback_name}")
            self.project_name = fallback_name
            self.script = self.draft_folder.create_draft(
                self.project_name, width, height, allow_replace=False
            )
        
        # æ·»åŠ åŸºç¡€è½¨é“ï¼ˆé€šè¿‡è°ƒç”¨é¡ºåºæ§åˆ¶å±‚çº§ï¼Œç´¢å¼•é€’å¢ï¼‰
        self.script.add_track(TrackType.video, "ä¸»è§†é¢‘è½¨é“", relative_index=1)
        self.script.add_track(TrackType.video, "æ•°å­—äººè§†é¢‘è½¨é“", relative_index=2)  
        self.script.add_track(TrackType.audio, "éŸ³é¢‘è½¨é“", relative_index=3)
        self.script.add_track(TrackType.audio, "èƒŒæ™¯éŸ³ä¹è½¨é“", relative_index=4)
        # æ–‡æœ¬ç±»ï¼šæŒ‰è°ƒç”¨é¡ºåºè®¾ç½®å±‚çº§
        self.script.add_track(TrackType.text, "å†…å®¹å­—å¹•è½¨é“", relative_index=5)
        self.script.add_track(TrackType.text, "æ ‡é¢˜å­—å¹•è½¨é“", relative_index=6)
        
        return self.script
    
    def add_videos(self, video_urls: List[str], timelines: List[Dict[str, int]], 
                   volume: float = 1.0, track_index: int = 0) -> List[draft.VideoSegment]:
        """æ‰¹é‡æ·»åŠ è§†é¢‘
        
        Args:
            video_urls: è§†é¢‘URLåˆ—è¡¨
            timelines: æ—¶é—´è½´ä¿¡æ¯åˆ—è¡¨ï¼ŒåŒ…å«startå’Œend(å•ä½ï¼šç§’)
            volume: éŸ³é‡(0-1)
            track_index: è½¨é“ç´¢å¼•
            
        Returns:
            è§†é¢‘ç‰‡æ®µåˆ—è¡¨
        """
        if not self.script:
            raise ValueError("è¯·å…ˆåˆ›å»ºè‰ç¨¿")
            
        video_segments = []
        total_video_duration = 0
        
        for i, (video_url, timeline) in enumerate(zip(video_urls, timelines)):
            # ä¸‹è½½è§†é¢‘åˆ°æœ¬åœ°
            local_video_path = self.download_material(
                video_url, 
                f"temp_materials/video_{i}.mp4"
            )
            
            # ä¿å­˜ç´ æè§†é¢‘è·¯å¾„ï¼ˆåªä¿å­˜ç¬¬ä¸€ä¸ªï¼‰
            if i == 0:
                self.material_video_path = local_video_path
            
            # è®¡ç®—æ—¶é—´èŒƒå›´
            start_time = timeline.get('start', 0)  # ç§’
            duration = timeline.get('end', 10) - start_time  # æŒç»­æ—¶é•¿
            
            # åˆ›å»ºè§†é¢‘ç‰‡æ®µ
            video_segment = draft.VideoSegment(
                local_video_path,
                trange(tim(f"{start_time}s"), tim(f"{duration}s"))
            )
            
            # è®¾ç½®éŸ³é‡
            if hasattr(video_segment, 'set_volume'):
                video_segment.set_volume(volume)
            
            video_segments.append(video_segment)
            
            # æ·»åŠ åˆ°ä¸»è§†é¢‘è½¨é“
            self.script.add_segment(video_segment, track_name="ä¸»è§†é¢‘è½¨é“")
            
            # ç´¯è®¡è§†é¢‘æ—¶é•¿
            total_video_duration += duration
            
        # æ›´æ–°è§†é¢‘æ€»æ—¶é•¿
        self.video_duration = total_video_duration
        self._update_project_duration()
        print(f"[INFO] è§†é¢‘æ€»æ—¶é•¿: {self.video_duration:.1f} ç§’")
            
        return video_segments
    
    def add_digital_human_video(self, digital_video_url: str, duration: int = None, remove_pauses: bool = False,
                               min_pause_duration: float = 0.2, max_word_gap: float = 0.8):
        """æ·»åŠ æ•°å­—äººè§†é¢‘
        
        Args:
            digital_video_url: æ•°å­—äººè§†é¢‘URL
            duration: æŒç»­æ—¶é•¿(ç§’)ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨æ•´ä¸ªè§†é¢‘
            remove_pauses: æ˜¯å¦ç§»é™¤è§†é¢‘ä¸­çš„éŸ³é¢‘åœé¡¿ï¼Œé»˜è®¤False
            min_pause_duration: æœ€å°åœé¡¿æ—¶é•¿(ç§’)ï¼Œé»˜è®¤0.2ç§’
            max_word_gap: å•è¯é—´æœ€å¤§é—´éš”(ç§’)ï¼Œé»˜è®¤0.8ç§’
        """
        # æ£€æŸ¥æ˜¯å¦å·²ç»æ‰‹åŠ¨å¤„ç†è¿‡å¤šç‰‡æ®µ
        if hasattr(self, 'skip_normal_processing') and self.skip_normal_processing:
            print(f"[DEBUG] è·³è¿‡æ­£å¸¸çš„æ•°å­—äººè§†é¢‘å¤„ç†ï¼Œå› ä¸ºå·²ç»æ‰‹åŠ¨æ·»åŠ äº†å¤šç‰‡æ®µ")
            # é‡ç½®æ ‡å¿—
            self.skip_normal_processing = False
            return None
        if not self.script:
            raise ValueError("è¯·å…ˆåˆ›å»ºè‰ç¨¿")
            
        # ä¸‹è½½æ•°å­—äººè§†é¢‘ï¼ˆä½¿ç”¨å”¯ä¸€æ–‡ä»¶åï¼‰
        digital_video_local_path = self._generate_unique_filename("digital_human")
        local_path = self.download_material(
            digital_video_url,
            digital_video_local_path
        )
        
        # å¦‚æœéœ€è¦ç§»é™¤åœé¡¿ï¼Œå¤„ç†è§†é¢‘ä¸­çš„éŸ³é¢‘
        if remove_pauses and self.volcengine_asr:
            print("[DEBUG] å¼€å§‹å¤„ç†è§†é¢‘ä¸­çš„éŸ³é¢‘åœé¡¿ç§»é™¤...")
            
            # 1. æå–è§†é¢‘ä¸­çš„éŸ³é¢‘
            temp_audio_path = self._generate_unique_filename("video_audio", ".mp3")
            try:
                # ä½¿ç”¨FFmpegæå–éŸ³é¢‘
                subprocess.run([
                    'ffmpeg', '-i', local_path, '-q:a', '0', '-map', 'a', temp_audio_path, '-y'
                ], check=True, capture_output=True)
                print(f"[DEBUG] éŸ³é¢‘æå–æˆåŠŸ: {temp_audio_path}")
                
                # 2. ä½¿ç”¨ASRå¤„ç†éŸ³é¢‘åœé¡¿
                asr_result = self.volcengine_asr.transcribe_audio_for_silence_detection(digital_video_url)
                
                if asr_result:
                    # 3. åˆ†æåœé¡¿æ®µè½
                    pause_detector = ASRSilenceDetector(min_pause_duration, max_word_gap)
                    pause_segments = pause_detector.detect_pauses_from_asr(asr_result)
                    
                    # 4. ç”ŸæˆåŸå§‹å­—å¹•
                    subtitle_objects = self.volcengine_asr.parse_result_to_subtitles(asr_result)
                    self.original_subtitles = subtitle_objects
                    
                    if pause_segments:
                        print(f"[DEBUG] æ£€æµ‹åˆ° {len(pause_segments)} ä¸ªåœé¡¿æ®µè½")
                        
                        # 5. å¤„ç†éŸ³é¢‘åœé¡¿
                        processed_audio_path = self._process_audio_pauses_with_asr_result(
                            temp_audio_path, asr_result, pause_segments, 
                            min_pause_duration, max_word_gap
                        )
                        
                        if processed_audio_path:
                            # 6. è°ƒæ•´å­—å¹•æ—¶é—´è½´
                            adjusted_subtitles = self._adjust_subtitle_timings(
                                subtitle_objects, pause_segments
                            )
                            self.adjusted_subtitles = adjusted_subtitles
                            self.original_subtitles = subtitle_objects
                            
                            # 7. ä½¿ç”¨è§†é¢‘ç‰‡æ®µåˆ‡å‰²æ–¹å¼å¤„ç†åœé¡¿ï¼ˆä¿æŒåŸå§‹è§†é¢‘è´¨é‡ï¼‰
                            processed_video_segments = self._process_video_pauses_by_segmentation(
                                local_path, "", pause_segments
                            )
                            
                            if len(processed_video_segments) == 1:
                                # åªæœ‰ä¸€ä¸ªç‰‡æ®µï¼Œç›´æ¥ä½¿ç”¨
                                local_path = processed_video_segments[0]
                                print(f"[OK] è§†é¢‘åœé¡¿ç§»é™¤å®Œæˆï¼ˆä¿æŒåŸå§‹è´¨é‡ï¼‰ï¼Œæ–°è§†é¢‘: {local_path}")
                            else:
                                # å¤šä¸ªç‰‡æ®µï¼šç»Ÿä¸€æ·»åŠ æ‰€æœ‰ç‰‡æ®µåˆ°æ•°å­—äººè§†é¢‘è½¨é“
                                print(f"[OK] è§†é¢‘åœé¡¿ç§»é™¤å®Œæˆï¼Œç”Ÿæˆ {len(processed_video_segments)} ä¸ªç‰‡æ®µ")
                                print(f"[DEBUG] ç»Ÿä¸€æ·»åŠ æ‰€æœ‰ç‰‡æ®µåˆ°æ•°å­—äººè§†é¢‘è½¨é“")
                                
                                # æš‚æ—¶ç¦ç”¨è‡ªåŠ¨æ—¶é•¿è®¡ç®—ï¼Œæˆ‘ä»¬æ‰‹åŠ¨ç®¡ç†
                                temp_adjusted_subtitles = self.adjusted_subtitles
                                self.adjusted_subtitles = None  # ä¸´æ—¶ç¦ç”¨å­—å¹•æ—¶é•¿è®¡ç®—
                                
                                # ç»Ÿä¸€æ·»åŠ æ‰€æœ‰ç‰‡æ®µ
                                current_time_offset = 0
                                total_duration = 0
                                
                                for i, segment_path in enumerate(processed_video_segments):
                                    try:
                                        # è·å–ç‰‡æ®µå®é™…æ—¶é•¿
                                        probe_cmd = [
                                            'ffprobe', '-v', 'quiet', '-show_entries', 'format=duration',
                                            '-of', 'csv=p=0', segment_path
                                        ]
                                        result = subprocess.run(probe_cmd, capture_output=True, text=True, check=True)
                                        segment_duration = float(result.stdout.strip())
                                        
                                        print(f"[DEBUG] æ·»åŠ ç‰‡æ®µ {i+1}: {segment_path} (æ—¶é•¿: {segment_duration:.3f}s, æ—¶é—´åç§»: {current_time_offset:.3f}s)")
                                        
                                        # ç›´æ¥åˆ›å»ºè§†é¢‘ç‰‡æ®µå¹¶æ·»åŠ åˆ°æ•°å­—äººè§†é¢‘è½¨é“
                                        video_material = draft.VideoMaterial(segment_path)
                                        
                                        # åˆ›å»ºè§†é¢‘ç‰‡æ®µ
                                        # target_timerange: åœ¨è½¨é“ä¸Šçš„ä½ç½®ï¼ˆä» current_time_offset å¼€å§‹ï¼‰
                                        # source_timerange: ä»ç´ æä¸­æˆªå–çš„èŒƒå›´ï¼ˆä» 0 å¼€å§‹ï¼Œå› ä¸ºå·²ç»åˆ‡å‰²å¥½äº†ï¼‰
                                        # ä½¿ç”¨ç´ æçš„å®é™…æ—¶é•¿è€Œä¸æ˜¯è®¡ç®—æ—¶é•¿ï¼Œé¿å…ç²¾åº¦é—®é¢˜
                                        material_duration = video_material.duration / 1000000  # è½¬æ¢ä¸ºç§’
                                        video_segment = draft.VideoSegment(
                                            video_material,
                                            trange(tim(f"{current_time_offset}s"), tim(f"{material_duration}s")),
                                            source_timerange=trange(tim("0s"), tim(f"{material_duration}s"))
                                        )
                                        
                                        # æ·»åŠ åˆ°æ•°å­—äººè§†é¢‘è½¨é“
                                        self.script.add_segment(video_segment, track_name="æ•°å­—äººè§†é¢‘è½¨é“")
                                        
                                        print(f"[DEBUG] è§†é¢‘ç‰‡æ®µ {i+1} å·²æ·»åŠ åˆ°æ•°å­—äººè§†é¢‘è½¨é“ï¼Œæ—¶é—´ä½ç½®: {current_time_offset:.3f}s-{current_time_offset+material_duration:.3f}s")
                                        
                                        # æ›´æ–°æ—¶é—´åç§»å’Œæ€»æ—¶é•¿
                                        current_time_offset += material_duration
                                        total_duration += material_duration
                                        
                                    except Exception as e:
                                        print(f"[ERROR] æ·»åŠ è§†é¢‘ç‰‡æ®µ {i+1} å¤±è´¥: {e}")
                                
                                print(f"[DEBUG] æ‰€æœ‰ç‰‡æ®µæ·»åŠ å®Œæˆï¼Œæ€»æ—¶é•¿: {total_duration:.3f}s")
                                
                                # æ¢å¤å­—å¹•è®¾ç½®
                                self.adjusted_subtitles = temp_adjusted_subtitles
                                
                                # è®¾ç½®ç¬¬ä¸€ä¸ªç‰‡æ®µè·¯å¾„ï¼ˆç”¨äºå…¼å®¹æ€§ï¼‰
                                local_path = processed_video_segments[0]
                                
                                # æ‰‹åŠ¨æ›´æ–°è§†é¢‘æ—¶é•¿
                                self.video_duration = total_duration
                                print(f"[DEBUG] æ‰‹åŠ¨æ›´æ–°è§†é¢‘æ—¶é•¿ä¸º: {total_duration:.3f}s")
                                
                                # æ›´æ–°é¡¹ç›®æ—¶é•¿
                                self._update_project_duration()
                                
                                # è®¾ç½®æ ‡å¿—ï¼Œè¡¨ç¤ºå·²ç»æ‰‹åŠ¨æ·»åŠ äº†æ‰€æœ‰ç‰‡æ®µï¼Œéœ€è¦è·³è¿‡æ­£å¸¸çš„ add_digital_human_video é€»è¾‘
                                self.skip_normal_processing = True
                            
                            # 8. æ·»åŠ è°ƒæ•´åçš„å­—å¹•åˆ°è§†é¢‘
                            if adjusted_subtitles:
                                print(f"[DEBUG] æ·»åŠ è°ƒæ•´åçš„å­—å¹•åˆ°è§†é¢‘: {len(adjusted_subtitles)} æ®µ")
                                print(f"[DEBUG] æ‰“å°å»é™¤åœé¡¿åçš„å­—å¹•ä¿¡æ¯:")
                                for i, subtitle in enumerate(adjusted_subtitles):
                                    print(f"  å­—å¹•{i+1}: [{subtitle['start']:.3f}s-{subtitle['end']:.3f}s] {subtitle['text']}")
                                
                                # æå–å…³é”®è¯ç”¨äºé«˜äº®
                                all_text = " ".join([sub['text'] for sub in adjusted_subtitles])
                                keywords = self.volcengine_asr.extract_keywords_with_ai(all_text, max_keywords=8)
                                
                                if keywords:
                                    print(f"[OK] è§†é¢‘å­—å¹•æå–åˆ° {len(keywords)} ä¸ªå…³é”®è¯: {keywords}")
                                else:
                                    print("[WARN] è§†é¢‘å­—å¹•æœªæå–åˆ°å…³é”®è¯")
                                
                                # æ¸…ç†ç°æœ‰çš„å­—å¹•è½¨é“ä»¥é¿å…é‡å 
                                self._clear_caption_tracks()
                                
                                # æ·»åŠ å­—å¹•ï¼ˆå¸¦å…³é”®è¯é«˜äº®ï¼‰
                                self.add_captions(adjusted_subtitles, track_name="å†…å®¹å­—å¹•è½¨é“", position="bottom",
                                                keywords=keywords, 
                                                base_color=(1.0, 1.0, 1.0),  # ç™½è‰²
                                                base_font_size=8.0,  # 8å·
                                                font_type=draft.FontType.ä¿ªé‡‘é»‘,  # ä¿ªé‡‘é»‘
                                                highlight_size=10.0,  # é«˜äº®10å·
                                                highlight_color=(1.0, 0.7529411765, 0.2470588235),  # #ffc03f
                                                scale=1.39)  # ç¼©æ”¾1.39
                                
                                # ä¸ºå­—å¹•æ·»åŠ èƒŒæ™¯è‰²å—
                                self.add_caption_backgrounds(adjusted_subtitles, position="bottom", 
                                                           bottom_transform_y=-0.3, scale=1.39)
                                
                                print(f"[OK] è°ƒæ•´åçš„å­—å¹•å·²æ·»åŠ åˆ°è§†é¢‘ï¼ˆå«å…³é”®è¯é«˜äº®å’ŒèƒŒæ™¯è‰²å—ï¼‰")
                        else:
                            print("[WARN] éŸ³é¢‘åœé¡¿å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹è§†é¢‘")
                    else:
                        print("[DEBUG] æœªæ£€æµ‹åˆ°éœ€è¦ç§»é™¤çš„åœé¡¿")
                else:
                    print("[WARN] ASRè¯†åˆ«å¤±è´¥ï¼Œè·³è¿‡åœé¡¿ç§»é™¤")
                    
            except Exception as e:
                print(f"[WARN] è§†é¢‘éŸ³é¢‘åœé¡¿å¤„ç†å¤±è´¥: {e}")
        
        # ä¿å­˜æ•°å­—äººè§†é¢‘è·¯å¾„
        self.digital_video_path = local_path
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»æ‰‹åŠ¨å¤„ç†è¿‡å¤šç‰‡æ®µ
        if hasattr(self, 'skip_normal_processing') and self.skip_normal_processing:
            print(f"[DEBUG] è·³è¿‡æ­£å¸¸çš„æ•°å­—äººè§†é¢‘ç‰‡æ®µæ·»åŠ ï¼Œå› ä¸ºå·²ç»æ‰‹åŠ¨æ·»åŠ äº†å¤šç‰‡æ®µ")
            # é‡ç½®æ ‡å¿—
            self.skip_normal_processing = False
            return None
        
        # è·å–è§†é¢‘ç´ æä¿¡æ¯
        video_material = draft.VideoMaterial(local_path)
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæŒç»­æ—¶é•¿ï¼Œä½¿ç”¨æ•´ä¸ªè§†é¢‘
        if duration is None:
            duration_microseconds = video_material.duration
            duration_seconds = duration_microseconds / 1000000
            
            # å¦‚æœè¿›è¡Œäº†åœé¡¿ç§»é™¤ï¼Œä½¿ç”¨å¤„ç†åçš„éŸ³é¢‘æ—¶é•¿
            if remove_pauses and hasattr(self, 'adjusted_subtitles') and self.adjusted_subtitles:
                # è®¡ç®—å¤„ç†åçš„æ€»æ—¶é•¿
                if self.adjusted_subtitles:
                    processed_duration = self.adjusted_subtitles[-1]['end']
                    print(f"[DEBUG] ä½¿ç”¨åœé¡¿ç§»é™¤åçš„æ—¶é•¿: {processed_duration:.1f} ç§’ (åŸå§‹: {duration_seconds:.1f} ç§’)")
                    
                    # ç¡®ä¿ä¸è¶…è¿‡åŸå§‹è§†é¢‘æ—¶é•¿
                    if processed_duration <= duration_seconds:
                        duration_seconds = processed_duration
                        duration_microseconds = tim(f"{duration_seconds}s")
                        print(f"[DEBUG] ä½¿ç”¨å¤„ç†åçš„æ—¶é•¿: {duration_seconds:.1f}s")
                    else:
                        print(f"[WARN] å¤„ç†åæ—¶é•¿({processed_duration:.1f}s)è¶…è¿‡åŸå§‹è§†é¢‘æ—¶é•¿({duration_seconds:.1f}s)ï¼Œä½¿ç”¨åŸå§‹æ—¶é•¿")
                        duration_microseconds = tim(f"{duration_seconds}s")
        else:
            duration_microseconds = tim(f"{duration}s")
            duration_seconds = duration
        
        # åˆ›å»ºæ•°å­—äººè§†é¢‘ç‰‡æ®µ
        digital_segment = draft.VideoSegment(
            video_material,
            trange(tim("0s"), duration_microseconds)
        )
        
        # æ·»åŠ åˆ°æ•°å­—äººè§†é¢‘è½¨é“
        self.script.add_segment(digital_segment, track_name="æ•°å­—äººè§†é¢‘è½¨é“")
        
        # æ›´æ–°è§†é¢‘æ—¶é•¿
        self.video_duration = max(self.video_duration, duration_seconds)
        print(f"[INFO] æ•°å­—äººè§†é¢‘æ—¶é•¿: {duration_seconds:.1f} ç§’")
        
        self._update_project_duration()
        
        return digital_segment
    
    def add_audio(self, audio_url: str, duration: int = None, volume: float = 1.0, remove_pauses: bool = False,
                  min_pause_duration: float = 0.2, max_word_gap: float = 0.8):
        """æ·»åŠ éŸ³é¢‘
        
        Args:
            audio_url: éŸ³é¢‘URL
            duration: æŒç»­æ—¶é•¿(ç§’)ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ•´ä¸ªéŸ³é¢‘ï¼Œå¦‚æœæœ‰è§†é¢‘åˆ™é™åˆ¶ä¸ºè§†é¢‘æ—¶é•¿
            volume: éŸ³é‡(0-1)
            remove_pauses: æ˜¯å¦è‡ªåŠ¨ç§»é™¤åœé¡¿ï¼Œé»˜è®¤False
            min_pause_duration: æœ€å°åœé¡¿æ—¶é•¿(ç§’)ï¼Œé»˜è®¤0.2ç§’
            max_word_gap: å•è¯é—´æœ€å¤§é—´éš”(ç§’)ï¼Œé»˜è®¤0.8ç§’
        """
        if not self.script:
            raise ValueError("è¯·å…ˆåˆ›å»ºè‰ç¨¿")
        
        # ä¿å­˜åŸå§‹URLç”¨äºASRå¤„ç†
        original_audio_url = audio_url
        print(f"[DEBUG] åŸå§‹éŸ³é¢‘URL: {original_audio_url}")
        
        # æ–°çš„é›†æˆæ–¹æ¡ˆï¼šå…ˆè¿›è¡ŒASRè¯†åˆ«ï¼Œå†å¤„ç†åœé¡¿
        asr_result = None
        pause_segments = []
        subtitle_objects = []
        
        print(f"[DEBUG] remove_pauseså‚æ•°: {remove_pauses}")
        print(f"[DEBUG] self.volcengine_asræ˜¯å¦å­˜åœ¨: {self.volcengine_asr is not None}")
        
        if remove_pauses and self.volcengine_asr:
            print(f"[DEBUG] å¼€å§‹é›†æˆæ–¹æ¡ˆï¼šå…ˆASRè¯†åˆ«ï¼Œå†å¤„ç†åœé¡¿")
            
            # 1. å…ˆç”¨åŸå§‹URLè¿›è¡ŒASRè¯†åˆ«
            print(f"[DEBUG] æ­¥éª¤1ï¼šä½¿ç”¨åŸå§‹URLè¿›è¡ŒASRè¯†åˆ«")
            asr_result = self.volcengine_asr.transcribe_audio_for_silence_detection(original_audio_url)
            
            if asr_result:
                print(f"[DEBUG] ASRè¯†åˆ«æˆåŠŸï¼Œå¼€å§‹åˆ†æåœé¡¿")
                
                # 2. åˆ†æåœé¡¿æ®µè½
                pause_detector = ASRSilenceDetector(min_pause_duration, max_word_gap)
                pause_segments = pause_detector.detect_pauses_from_asr(asr_result)
                
                # 3. ç”ŸæˆåŸå§‹å­—å¹•
                subtitle_objects = self.volcengine_asr.parse_result_to_subtitles(asr_result)
                
                print(f"[DEBUG] æ£€æµ‹åˆ° {len(pause_segments)} ä¸ªåœé¡¿æ®µè½")
                print(f"[DEBUG] ç”Ÿæˆ {len(subtitle_objects)} æ®µåŸå§‹å­—å¹•")
                
                # 4. å¦‚æœæœ‰åœé¡¿ï¼Œä¸‹è½½éŸ³é¢‘å¹¶è¿›è¡Œå¤„ç†
                if pause_segments:
                    print(f"[DEBUG] æ­¥éª¤2ï¼šä¸‹è½½éŸ³é¢‘å¹¶ç§»é™¤åœé¡¿")
                    
                    # ä¸‹è½½éŸ³é¢‘åˆ°æœ¬åœ°ï¼ˆä½¿ç”¨å”¯ä¸€æ–‡ä»¶åï¼‰
                    audio_local_path = self._generate_unique_filename("audio", ".mp3")
                    local_path = self.download_material(
                        audio_url,
                        audio_local_path
                    )
                    
                    if local_path != original_audio_url:
                        # ä¸‹è½½æˆåŠŸï¼Œå¤„ç†åœé¡¿
                        if not os.path.isabs(local_path):
                            local_path = os.path.abspath(local_path)
                        
                        print(f"[DEBUG] éŸ³é¢‘ä¸‹è½½æˆåŠŸ: {local_path}")
                        
                        # å¤„ç†éŸ³é¢‘åœé¡¿
                        processed_audio_path = self._process_audio_pauses_with_asr_result(
                            local_path, asr_result, pause_segments, min_pause_duration, max_word_gap
                        )
                        
                        if processed_audio_path:
                            local_path = processed_audio_path
                            print(f"[DEBUG] éŸ³é¢‘åœé¡¿å¤„ç†å®Œæˆ: {local_path}")
                            
                            # 5. é‡æ–°è®¡ç®—å­—å¹•æ—¶é—´è½´
                            adjusted_subtitles = self._adjust_subtitle_timings(
                                subtitle_objects, pause_segments
                            )
                            print(f"[DEBUG] å­—å¹•æ—¶é—´è½´è°ƒæ•´å®Œæˆï¼Œ{len(adjusted_subtitles)} æ®µå­—å¹•")
                            
                            # ä¿å­˜è°ƒæ•´åçš„å­—å¹•ä¾›åç»­ä½¿ç”¨
                            self.adjusted_subtitles = adjusted_subtitles
                            self.original_subtitles = subtitle_objects
                        else:
                            print("[DEBUG] éŸ³é¢‘åœé¡¿å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘")
                    else:
                        print("[DEBUG] éŸ³é¢‘ä¸‹è½½å¤±è´¥ï¼Œè·³è¿‡åœé¡¿ç§»é™¤")
                        local_path = original_audio_url
                else:
                    print("[DEBUG] æœªæ£€æµ‹åˆ°åœé¡¿ï¼Œè·³è¿‡åœé¡¿ç§»é™¤")
                    # ä¸‹è½½éŸ³é¢‘ä½†ä¸å¤„ç†åœé¡¿ï¼ˆä½¿ç”¨å”¯ä¸€æ–‡ä»¶åï¼‰
                    audio_local_path = self._generate_unique_filename("audio", ".mp3")
                    local_path = self.download_material(audio_url, audio_local_path)
                    self.adjusted_subtitles = subtitle_objects
                    self.original_subtitles = subtitle_objects
            else:
                print("[DEBUG] ASRè¯†åˆ«å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æ–¹æ¡ˆ")
                remove_pauses = False  # ç¦ç”¨åœé¡¿ç§»é™¤ï¼Œä½¿ç”¨åŸå§‹æµç¨‹
                audio_local_path = self._generate_unique_filename("audio", ".mp3")
                local_path = self.download_material(audio_url, audio_local_path)
        else:
            # ä¸éœ€è¦ç§»é™¤åœé¡¿æˆ–ASRæœªåˆå§‹åŒ–ï¼Œä½¿ç”¨åŸå§‹æµç¨‹
            if not self.volcengine_asr:
                print(f"[DEBUG] ASRæœªåˆå§‹åŒ–ï¼Œä½¿ç”¨åŸå§‹æµç¨‹")
            if not remove_pauses:
                print(f"[DEBUG] remove_pauses=Falseï¼Œä½¿ç”¨åŸå§‹æµç¨‹")
            print(f"[DEBUG] ä½¿ç”¨åŸå§‹æµç¨‹ï¼šä¸‹è½½éŸ³é¢‘")
            audio_local_path = self._generate_unique_filename("audio", ".mp3")
            local_path = self.download_material(audio_url, audio_local_path)
        
        # å¤„ç†æœ¬åœ°è·¯å¾„
        if local_path != original_audio_url:
            if not os.path.isabs(local_path):
                local_path = os.path.abspath(local_path)
            
            if os.path.exists(local_path):
                print(f"[DEBUG] æœ¬åœ°éŸ³é¢‘æ–‡ä»¶å¤§å°: {os.path.getsize(local_path)} bytes")
            else:
                print(f"[ERROR] éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {local_path}")
                raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {local_path}")
        
        print(f"[DEBUG] æœ€ç»ˆéŸ³é¢‘è·¯å¾„: {local_path}")
        
        # è·å–éŸ³é¢‘ç´ æä¿¡æ¯
        audio_material = draft.AudioMaterial(local_path)
        actual_audio_duration = audio_material.duration / 1000000  # è½¬æ¢ä¸ºç§’
        
        print(f"[DEBUG] å®é™…éŸ³é¢‘æ—¶é•¿: {actual_audio_duration:.1f} ç§’")
        
        # å¦‚æœè¿›è¡Œäº†åœé¡¿ç§»é™¤ï¼Œæ›´æ–°éŸ³é¢‘æ—¶é•¿
        if hasattr(self, 'adjusted_subtitles') and self.adjusted_subtitles and remove_pauses:
            print(f"[DEBUG] æ£€æµ‹åˆ°åœé¡¿ç§»é™¤ï¼Œä½¿ç”¨å¤„ç†åçš„éŸ³é¢‘æ—¶é•¿: {actual_audio_duration:.1f} ç§’")
            original_audio_duration = actual_audio_duration
        else:
            original_audio_duration = actual_audio_duration
        
        # ç¡®å®šå®é™…éŸ³é¢‘æ—¶é•¿
        if duration is None:
            # å¦‚æœæœ‰è§†é¢‘ï¼ŒéŸ³é¢‘æ—¶é•¿ä¸åº”è¶…è¿‡è§†é¢‘æ—¶é•¿
            if self.video_duration > 0:
                actual_duration = min(original_audio_duration, self.video_duration)
                if original_audio_duration > self.video_duration:
                    print(f"[WARN] éŸ³é¢‘æ—¶é•¿({original_audio_duration:.1f}s)è¶…è¿‡è§†é¢‘æ—¶é•¿({self.video_duration:.1f}s)ï¼Œå°†æˆªå–è‡³è§†é¢‘æ—¶é•¿")
            else:
                actual_duration = original_audio_duration
        else:
            # å¦‚æœæœ‰è§†é¢‘ï¼Œæ£€æŸ¥æŒ‡å®šæ—¶é•¿æ˜¯å¦è¶…è¿‡è§†é¢‘æ—¶é•¿
            if self.video_duration > 0 and duration > self.video_duration:
                actual_duration = self.video_duration
                print(f"[WARN] æŒ‡å®šéŸ³é¢‘æ—¶é•¿({duration:.1f}s)è¶…è¿‡è§†é¢‘æ—¶é•¿({self.video_duration:.1f}s)ï¼Œå°†æˆªå–è‡³è§†é¢‘æ—¶é•¿")
            else:
                actual_duration = duration
        
        duration_microseconds = tim(f"{actual_duration}s")
        self.audio_duration = actual_duration
        
        # åˆ›å»ºéŸ³é¢‘ç‰‡æ®µ
        audio_segment = draft.AudioSegment(
            audio_material,
            trange(tim("0s"), duration_microseconds),
            volume=volume
        )
        
          
        # æ¸…é™¤ç°æœ‰éŸ³é¢‘æ®µä»¥é¿å…é‡å 
        try:
            audio_tracks = [track for track in self.script.main_track.tracks if track.track_type == TrackType.AUDIO]
            for track in audio_tracks:
                if track.segments:
                    track.segments.clear()
                    print("[DEBUG] å·²æ¸…é™¤ç°æœ‰éŸ³é¢‘æ®µ")
        except Exception as e:
            print(f"[WARN] æ¸…é™¤éŸ³é¢‘æ®µå¤±è´¥: {e}")
        
        # æ·»åŠ åˆ°éŸ³é¢‘è½¨é“
        self.script.add_segment(audio_segment, track_name="éŸ³é¢‘è½¨é“")
        
        # æ›´æ–°é¡¹ç›®æ—¶é•¿
        self._update_project_duration()
        print(f"[INFO] éŸ³é¢‘æ—¶é•¿: {self.audio_duration:.1f} ç§’")
        
        return audio_segment
    
    def add_background_music(self, music_path: str, target_duration: float = None, volume: float = 0.3):
        """æ·»åŠ èƒŒæ™¯éŸ³ä¹
        
        Args:
            music_path: èƒŒæ™¯éŸ³ä¹æ–‡ä»¶è·¯å¾„ï¼ˆæœ¬åœ°è·¯å¾„ï¼‰
            target_duration: ç›®æ ‡æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œå¦‚æœNoneåˆ™ä½¿ç”¨é¡¹ç›®æ€»æ—¶é•¿ï¼ˆéŸ³è§†é¢‘ä¸­æœ€é•¿è€…ï¼‰
            volume: éŸ³é‡(0-1)ï¼Œé»˜è®¤0.3æ¯”è¾ƒé€‚åˆèƒŒæ™¯éŸ³ä¹
        """
        if not self.script:
            raise ValueError("è¯·å…ˆåˆ›å»ºè‰ç¨¿")
            
        if not os.path.exists(music_path):
            raise ValueError(f"èƒŒæ™¯éŸ³ä¹æ–‡ä»¶ä¸å­˜åœ¨: {music_path}")
        
        # è·å–èƒŒæ™¯éŸ³ä¹ç´ æä¿¡æ¯
        bg_music_material = draft.AudioMaterial(music_path)
        
        # ç¡®å®šç›®æ ‡æ—¶é•¿ - ä¼˜å…ˆä½¿ç”¨é¡¹ç›®æ€»æ—¶é•¿ç¡®ä¿éŸ³è§†é¢‘åŒæ­¥
        if target_duration is None:
            if self.project_duration > 0:
                target_duration = self.project_duration
                print(f"[INFO] èƒŒæ™¯éŸ³ä¹å°†ä½¿ç”¨é¡¹ç›®æ€»æ—¶é•¿: {target_duration:.1f}s (ç¡®ä¿ä¸éŸ³è§†é¢‘åŒæ­¥)")
            elif self.video_duration > 0:
                target_duration = self.video_duration
                print(f"[INFO] èƒŒæ™¯éŸ³ä¹å°†ä½¿ç”¨è§†é¢‘æ—¶é•¿: {target_duration:.1f}s")
            elif self.audio_duration > 0:
                target_duration = self.audio_duration
                print(f"[INFO] èƒŒæ™¯éŸ³ä¹å°†ä½¿ç”¨éŸ³é¢‘æ—¶é•¿: {target_duration:.1f}s")
            else:
                raise ValueError("æ— æ³•ç¡®å®šç›®æ ‡æ—¶é•¿ï¼Œè¯·å…ˆæ·»åŠ éŸ³é¢‘æˆ–è§†é¢‘ï¼Œæˆ–æŒ‡å®štarget_duration")
        
        target_duration_microseconds = tim(f"{target_duration}s")
        bg_music_duration_microseconds = bg_music_material.duration
        
        # è®¡ç®—æ˜¯å¦éœ€è¦å¾ªç¯æ’­æ”¾
        bg_music_duration_seconds = bg_music_duration_microseconds / 1000000
        
        if bg_music_duration_seconds >= target_duration:
            # èƒŒæ™¯éŸ³ä¹å¤Ÿé•¿ï¼Œç›´æ¥æˆªå–
            bg_music_segment = draft.AudioSegment(
                bg_music_material,
                trange(tim("0s"), target_duration_microseconds),
                volume=volume
            )
            # æ·»åŠ æ·¡å…¥æ·¡å‡ºå·²ç§»é™¤
            # æ·»åŠ åˆ°èƒŒæ™¯éŸ³ä¹è½¨é“
            self.script.add_segment(bg_music_segment, track_name="èƒŒæ™¯éŸ³ä¹è½¨é“")
            print(f"[INFO] èƒŒæ™¯éŸ³ä¹å·²æ·»åŠ : {os.path.basename(music_path)}ï¼Œæˆªå–æ—¶é•¿: {target_duration:.1f}sï¼ŒéŸ³é‡: {volume}")
        else:
            # èƒŒæ™¯éŸ³ä¹å¤ªçŸ­ï¼Œéœ€è¦å¾ªç¯
            print(f"[INFO] èƒŒæ™¯éŸ³ä¹æ—¶é•¿ {bg_music_duration_seconds:.1f}sï¼Œç›®æ ‡æ—¶é•¿ {target_duration:.1f}sï¼Œå°†å¾ªç¯æ’­æ”¾")
            
            # è®¡ç®—éœ€è¦å¾ªç¯çš„æ¬¡æ•°
            loop_count = int(target_duration / bg_music_duration_seconds) + 1
            current_time = 0
            
            for i in range(loop_count):
                # è®¡ç®—å½“å‰å¾ªç¯çš„æŒç»­æ—¶é—´
                remaining_time = target_duration - current_time
                if remaining_time <= 0:
                    break
                    
                current_duration = min(bg_music_duration_seconds, remaining_time)
                
                # åˆ›å»ºå½“å‰å¾ªç¯çš„éŸ³é¢‘ç‰‡æ®µ
                loop_segment = draft.AudioSegment(
                    bg_music_material,
                    trange(tim(f"{current_time}s"), tim(f"{current_duration}s")),
                    volume=volume
                )
                
                # ä¸ºç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªç‰‡æ®µæ·»åŠ æ·¡å…¥æ·¡å‡º
                # ç¬¬ä¸€ä¸ªç‰‡æ®µæ·¡å…¥å·²ç§»é™¤
                # æœ€åä¸€ä¸ªç‰‡æ®µæ·¡å‡ºå·²ç§»é™¤
                
                # æ·»åŠ åˆ°èƒŒæ™¯éŸ³ä¹è½¨é“
                self.script.add_segment(loop_segment, track_name="èƒŒæ™¯éŸ³ä¹è½¨é“")
                
                current_time += current_duration
            
            print(f"[INFO] èƒŒæ™¯éŸ³ä¹å¾ªç¯å·²æ·»åŠ : {os.path.basename(music_path)}ï¼Œ{loop_count}æ¬¡å¾ªç¯ï¼Œæ€»æ—¶é•¿: {target_duration:.1f}sï¼ŒéŸ³é‡: {volume}")
        
        return
    
    def add_styled_text_with_background(self, text_content: str, timerange_start: float, timerange_duration: float,
                                       track_name: str = "æ ‡é¢˜å­—å¹•è½¨é“", position: str = "center",
                                       background_style: Dict[str, Any] = None,
                                       text_transform_y: Optional[float] = None,
                                       line_spacing: int = 0,
                                       bg_height: Optional[float] = None) -> draft.TextSegment:
        """æ·»åŠ å¸¦èƒŒæ™¯çš„æ ·å¼åŒ–æ–‡æœ¬
        
        Args:
            text_content: æ–‡æœ¬å†…å®¹ï¼ˆæ”¯æŒæ¢è¡Œç¬¦\\nï¼‰
            timerange_start: å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
            timerange_duration: æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
            track_name: è½¨é“åç§°
            position: æ–‡æœ¬ä½ç½® ("top"é¡¶éƒ¨, "center"ä¸­é—´, "bottom"åº•éƒ¨)
            background_style: èƒŒæ™¯æ ·å¼å‚æ•°å­—å…¸
            text_transform_y: æ–‡æœ¬ç‰‡æ®µçš„transform_yï¼ˆ-1.0~1.0ï¼‰ã€‚ä¼ å…¥åˆ™è¦†ç›–positionæ˜ å°„ã€‚
            line_spacing: è¡Œé—´è·ï¼ˆä¸å‰ªæ˜ ä¸€è‡´çš„æ•´æ•°å•ä½ï¼Œé»˜è®¤0ï¼‰ã€‚
            bg_height: èƒŒæ™¯é«˜åº¦æ¯”ä¾‹ï¼ˆ0.0-1.0ï¼‰ã€‚ä¼ å…¥åˆ™è¦†ç›– background_style["height"]ã€‚
            
        Returns:
            åˆ›å»ºçš„æ–‡æœ¬ç‰‡æ®µ
        """
        if not self.script:
            raise ValueError("è¯·å…ˆåˆ›å»ºè‰ç¨¿")
        
        # é»˜è®¤èƒŒæ™¯æ ·å¼ï¼ˆæ ¹æ®æ‚¨æä¾›çš„æˆªå›¾å‚æ•°ï¼‰
        if background_style is None:
            background_style = {
                "color": "#000000",      # é»‘è‰²
                "alpha": 0.67,           # 67% ä¸é€æ˜åº¦
                "height": 0.31,          # 31% é«˜åº¦
                "width": 0.14,           # 14% å®½åº¦  
                "horizontal_offset": 0.5, # 50% å·¦å³é—´éš™
                "vertical_offset": 0.5,   # 50% ä¸Šä¸‹é—´éš™
                "round_radius": 0.0,     # åœ†è§’åŠå¾„
                "style": 1               # èƒŒæ™¯æ ·å¼
            }
        
        # æ ¹æ®ä½ç½®è®¾ç½®å‚ç›´åç§»ï¼ˆtransform_yï¼‰ï¼Œå¯è¢«text_transform_yè¦†ç›–
        if position == "top":
            transform_y = 0.4
        elif position == "center":
            transform_y = 0.0
        else:  # bottom
            transform_y = -0.4
        if text_transform_y is not None:
            # æ”¯æŒæ•´æ•°è¾“å…¥ï¼šè‹¥ä¸º-100~100æŒ‰ç™¾åˆ†æ¯”æ˜ å°„åˆ°-1~1ï¼›è‹¥å·²åœ¨-1~1å†…åˆ™ç›´æ¥ä½¿ç”¨
            ty = float(text_transform_y)
            if isinstance(text_transform_y, int) and abs(ty) > 1:
                ty = ty / 100.0
            transform_y = max(-1.0, min(1.0, ty))
        
        # è¦†ç›–èƒŒæ™¯é«˜åº¦ï¼ˆè‹¥æä¾›ï¼‰
        if bg_height is not None:
            background_style["height"] = float(bg_height)

        # åˆ›å»ºæ–‡æœ¬èƒŒæ™¯
        text_background = draft.TextBackground(
            color=background_style["color"],
            alpha=background_style["alpha"],
            height=background_style["height"],
            width=background_style["width"],
            horizontal_offset=background_style["horizontal_offset"],
            vertical_offset=background_style["vertical_offset"],
            round_radius=background_style.get("round_radius", 0.0),
            style=background_style.get("style", 1)
        )
        
        # åˆ›å»ºæ–‡æœ¬æ ·å¼
        text_style = draft.TextStyle(
            size=15.0,
            color=(1.0, 1.0, 1.0),  # ç™½è‰²æ–‡å­—
            bold=True,
            align=0,  # å±…ä¸­å¯¹é½
            line_spacing=line_spacing
        )
        
        # åˆ›å»ºæ–‡æœ¬ç‰‡æ®µ
        text_segment = draft.TextSegment(
            text_content,
            trange(tim(f"{timerange_start}s"), tim(f"{timerange_duration}s")),
            font=draft.FontType.æ–‡è½©ä½“,
            style=text_style,
            clip_settings=draft.ClipSettings(transform_y=transform_y),
            background=text_background,
            shadow=draft.TextShadow(
                alpha=0.8,
                color=(0.0, 0.0, 0.0),
                diffuse=20.0,
                distance=10.0,
                angle=-45.0
            )
        )
        
        # ç¡®ä¿ç›®æ ‡è½¨é“å­˜åœ¨ï¼ˆè‹¥ä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»ºä¸ºæ–‡æœ¬è½¨é“ï¼ŒæŒ‰è°ƒç”¨é¡ºåºè®¾ç½®å±‚çº§ï¼‰
        try:
            _ = self.script.tracks[track_name]
        except KeyError:
            # è®¡ç®—ä¸‹ä¸€ä¸ªå¯ç”¨çš„ç›¸å¯¹ç´¢å¼•ï¼ˆåŸºäºç°æœ‰è½¨é“æ•°é‡ï¼‰
            existing_text_tracks = [name for name in self.script.tracks.keys() 
                                  if self.script.tracks[name].track_type == TrackType.text]
            next_index = len(existing_text_tracks) + 1
            self.script.add_track(TrackType.text, track_name, relative_index=next_index)

        # æ·»åŠ åˆ°è½¨é“
        self.script.add_segment(text_segment, track_name=track_name)
        
        print(f"[OK] å¸¦èƒŒæ™¯çš„æ–‡æœ¬å·²æ·»åŠ : '{text_content[:20]}...' åˆ° {track_name}")
        print(f"   èƒŒæ™¯: {background_style['color']} {background_style['alpha']*100:.0f}% é€æ˜åº¦")
        print(f"   ä½ç½®: {position}, æ—¶é•¿: {timerange_duration:.1f}ç§’")
        
        return text_segment
    
    def transcribe_audio_and_generate_subtitles(self, audio_url: str) -> List[Dict[str, Any]]:
        """ä½¿ç”¨ç«å±±å¼•æ“ASRè¿›è¡ŒéŸ³é¢‘è½¬å½•ç”Ÿæˆå­—å¹•
        
        Args:
            audio_url: éŸ³é¢‘URLï¼ˆæœ¬åœ°è·¯å¾„æˆ–ç½‘ç»œURLï¼‰
            
        Returns:
            å­—å¹•å¯¹è±¡æ•°ç»„ [{'text': str, 'start': float, 'end': float}, ...]
        """
        
        print(f"ğŸ¤ å¼€å§‹éŸ³é¢‘è½¬å½•: {audio_url}")
        print(f"ğŸ”¥ ä½¿ç”¨ç«å±±å¼•æ“ASRè¿›è¡Œè½¬å½•")
        
        try:
            if not self.volcengine_asr:
                print("[ERROR] ç«å±±å¼•æ“ASRæœªåˆå§‹åŒ–ï¼Œæ— æ³•è¿›è¡Œè½¬å½•")
                return []
            
            # ä½¿ç”¨ç«å±±å¼•æ“ASRè¿›è¡Œè½¬å½•
            subtitle_objects = self.volcengine_asr.process_audio_file(audio_url)
            
            if subtitle_objects:
                print(f"[OK] ç«å±±å¼•æ“è½¬å½•å®Œæˆï¼Œç”Ÿæˆ {len(subtitle_objects)} æ®µå­—å¹•")
                
                # æ˜¾ç¤ºæœ€ç»ˆçš„å¥å­å’Œæ—¶é—´æˆ³
                print(f"\nğŸ“‹ ç«å±±å¼•æ“ASRè½¬å½•ç»“æœ:")
                print("-" * 60)
                
                total_duration = 0
                for i, subtitle in enumerate(subtitle_objects, 1):
                    start = subtitle['start']
                    end = subtitle['end']
                    text = subtitle['text']
                    duration = end - start
                    total_duration += duration
                    
                    print(f"{i:2d}. [{start:7.3f}s-{end:7.3f}s] ({duration:5.2f}s) {text}")
                
                # æå–è½¬å½•çš„å®Œæ•´æ–‡æœ¬
                transcribed_text = " ".join([sub['text'] for sub in subtitle_objects])
                print(f"\nğŸ“ å®Œæ•´è½¬å½•æ–‡æœ¬: {transcribed_text}")
                print(f"[INFO] ç»Ÿè®¡: {len(subtitle_objects)}æ®µ, æ€»æ—¶é•¿{total_duration:.1f}ç§’, å¹³å‡{total_duration/len(subtitle_objects):.1f}ç§’/æ®µ")
                
                return subtitle_objects
            else:
                print("[ERROR] ç«å±±å¼•æ“è½¬å½•å¤±è´¥")
                return []
                
        except Exception as e:
            print(f"[ERROR] éŸ³é¢‘è½¬å½•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return []
    
    def adjust_subtitle_timing(self, subtitle_objects: List[Dict[str, Any]],
                             delay_seconds: float = 0.0, 
                             speed_factor: float = 1.0) -> List[Dict[str, Any]]:
        """è°ƒæ•´å­—å¹•æ—¶é—´ - æ·»åŠ å»¶è¿Ÿå’Œè°ƒæ•´è¯­é€Ÿ
        
        Args:
            subtitle_objects: å­—å¹•å¯¹è±¡åˆ—è¡¨
            delay_seconds: å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œæ­£å€¼è¡¨ç¤ºå­—å¹•å»¶åï¼Œè´Ÿå€¼è¡¨ç¤ºå­—å¹•æå‰
            speed_factor: é€Ÿåº¦ç³»æ•°ï¼Œ>1è¡¨ç¤ºåŠ å¿«ï¼Œ<1è¡¨ç¤ºå‡æ…¢
            
        Returns:
            è°ƒæ•´åçš„å­—å¹•å¯¹è±¡åˆ—è¡¨
        """
        if not subtitle_objects:
            return []
        
        print(f"â° è°ƒæ•´å­—å¹•æ—¶é—´: å»¶è¿Ÿ={delay_seconds:.1f}s, é€Ÿåº¦ç³»æ•°={speed_factor:.2f}")
        
        adjusted_subtitles = []
        
        for i, subtitle in enumerate(subtitle_objects):
            # åº”ç”¨é€Ÿåº¦ç³»æ•°
            original_start = subtitle['start']
            original_end = subtitle['end']
            original_duration = original_end - original_start
            
            # è°ƒæ•´æ—¶é—´
            new_start = original_start / speed_factor + delay_seconds
            new_duration = original_duration / speed_factor
            new_end = new_start + new_duration
            
            # ç¡®ä¿æ—¶é—´ä¸ä¸ºè´Ÿ
            new_start = max(0, new_start)
            new_end = max(new_start + 0.5, new_end)  # æœ€å°‘0.5ç§’æ˜¾ç¤ºæ—¶é—´
            
            adjusted_subtitle = {
                'text': subtitle['text'],
                'start': new_start,
                'end': new_end
            }
            adjusted_subtitles.append(adjusted_subtitle)
            
            print(f"   ç¬¬{i+1}æ®µ: {original_start:.1f}s-{original_end:.1f}s â†’ {new_start:.1f}s-{new_end:.1f}s")
        
        print(f"[OK] å­—å¹•æ—¶é—´è°ƒæ•´å®Œæˆ")
        return adjusted_subtitles
    
    def _clear_caption_tracks(self):
        """æ¸…ç†ç°æœ‰çš„å­—å¹•è½¨é“ä»¥é¿å…é‡å """
        try:
            # æŸ¥æ‰¾æ‰€æœ‰å­—å¹•è½¨é“
            caption_track_names = []
            for track_name, track in self.script.tracks.items():
                if hasattr(track, 'track_type') and track.track_type == TrackType.text:
                    caption_track_names.append(track_name)
            
            print(f"[DEBUG] æ‰¾åˆ° {len(caption_track_names)} ä¸ªå­—å¹•è½¨é“éœ€è¦æ¸…ç†: {caption_track_names}")
            
            # æ¸…ç†æ¯ä¸ªå­—å¹•è½¨é“ä¸­çš„æ®µ
            for track_name in caption_track_names:
                track = self.script.tracks[track_name]
                if hasattr(track, 'segments') and track.segments:
                    print(f"[DEBUG] æ¸…ç†å­—å¹•è½¨é“ '{track_name}' ä¸­çš„ {len(track.segments)} ä¸ªæ®µ")
                    track.segments.clear()
                    print(f"[OK] å­—å¹•è½¨é“ '{track_name}' å·²æ¸…ç†")
            
        except Exception as e:
            print(f"[WARN] æ¸…ç†å­—å¹•è½¨é“æ—¶å‡ºé”™: {e}")
    
    
    def add_captions(self, caption_data: List[Dict[str, Any]] = None,
                    track_name: str = "å†…å®¹å­—å¹•è½¨é“", position: str = "bottom",
                    keywords: List[str] = None,
                    base_font_size: float = 8.0,
                    base_color: Tuple[float, float, float] = (1.0, 1.0, 1.0),
                    font_type: Optional[draft.FontType] = None,
                    highlight_color: Tuple[float, float, float] = (1.0, 0.7529411765, 0.2470588235),
                    highlight_size: float = 10.0,
                    bottom_transform_y: float = -0.3,
                    scale: float = 1.39):
        """æ·»åŠ å­—å¹•ï¼Œæ”¯æŒå…³é”®è¯é«˜äº®
        
        Args:
            caption_data: å­—å¹•æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«text, start, endç­‰ä¿¡æ¯ã€‚
                       å¦‚æœä¸ºNoneï¼Œä¼šä½¿ç”¨åœé¡¿ç§»é™¤æ—¶ç”Ÿæˆçš„è°ƒæ•´åå­—å¹•
            font_size: å­—ä½“å¤§å°
            track_name: è½¨é“åç§°
            position: å­—å¹•ä½ç½® ("top"é¡¶éƒ¨, "bottom"åº•éƒ¨)
            keywords: éœ€è¦é«˜äº®çš„å…³é”®è¯åˆ—è¡¨
            keyword_color: å…³é”®è¯é«˜äº®é¢œè‰²ï¼Œé»˜è®¤ä¸ºé»„è‰²
        """
        if not self.script:
            raise ValueError("è¯·å…ˆåˆ›å»ºè‰ç¨¿")
        
        # å¦‚æœæ²¡æœ‰æä¾›å­—å¹•æ•°æ®ï¼Œå°è¯•ä½¿ç”¨è°ƒæ•´åçš„å­—å¹•
        if caption_data is None:
            if hasattr(self, 'adjusted_subtitles') and self.adjusted_subtitles:
                caption_data = self.adjusted_subtitles
                print(f"[DEBUG] ä½¿ç”¨è°ƒæ•´åçš„å­—å¹•: {len(caption_data)} æ®µ")
            else:
                print("[DEBUG] æ²¡æœ‰å¯ç”¨çš„å­—å¹•æ•°æ®")
                return
        
        # æ¸…ç†ç°æœ‰çš„å­—å¹•è½¨é“ä»¥é¿å…é‡å 
        self._clear_caption_tracks()
            
        text_segments = []
        
        for caption in caption_data:
            text = caption.get('text', '')
            start_time = caption.get('start', 0)  # ç§’
            end_time = caption.get('end', start_time + 2)  # ç§’
            
            if not text:
                continue
                
            # æ ¹æ®ä½ç½®è®¾ç½®ä¸åŒçš„å‚ç›´ä½ç½®
            if position == "top":
                transform_y = 0.4
                text_color = base_color
            else:
                transform_y = bottom_transform_y
                text_color = base_color
                
            # è¿‡æ»¤å‡ºåœ¨å½“å‰æ–‡æœ¬ä¸­å®é™…å­˜åœ¨çš„å…³é”®è¯
            current_keywords = []
            if keywords:
                for keyword in keywords:
                    if keyword and keyword.strip() and keyword in text:
                        current_keywords.append(keyword)
                        
            # åˆ›å»ºæ–‡æœ¬ç‰‡æ®µï¼Œåªä¼ å…¥å½“å‰æ–‡æœ¬ä¸­å­˜åœ¨çš„å…³é”®è¯
            text_segment = draft.TextSegment(
                text,
                trange(tim(f"{start_time}s"), tim(f"{end_time - start_time}s")),
                font=(font_type if font_type is not None else draft.FontType.ä¿ªé‡‘é»‘),
                style=draft.TextStyle(
                    color=text_color,
                    size=base_font_size,
                    auto_wrapping=True,
                    bold=True,
                    align=0,
                    max_line_width=0.82
                ),
                clip_settings=draft.ClipSettings(transform_y=transform_y, scale_x=scale, scale_y=scale)
            )

            # å¤–éƒ¨ä¼ å…¥çš„å…³é”®è¯é«˜äº®ï¼šæŒ‰ç»™å®šé¢œè‰²ä¸å­—å·
            if current_keywords:
                for kw in current_keywords:
                    start_idx = 0
                    while True:
                        pos = text.find(kw, start_idx)
                        if pos == -1:
                            break
                        end_idx = pos + len(kw)
                        try:
                            text_segment.add_highlight(pos, end_idx, color=highlight_color, size=highlight_size, bold=True)
                        except Exception:
                            pass
                        start_idx = pos + 1
            
            # å¦‚æœæœ‰å…³é”®è¯è¢«é«˜äº®ï¼Œæ‰“å°è°ƒè¯•ä¿¡æ¯
            if current_keywords:
                print(f"   [INFO] '{text}' ä¸­é«˜äº®å…³é”®è¯: {current_keywords}")
            
            text_segments.append(text_segment)
            self.script.add_segment(text_segment, track_name=track_name)
            
        return text_segments
    
    def add_caption_backgrounds(self, caption_data: List[Dict[str, Any]], 
                               position: str = "bottom",
                               bottom_transform_y: float = -0.3,
                               scale: float = 1.39,
                               background_style: Dict[str, Any] = None):
        """ä¸ºå­—å¹•æ·»åŠ èƒŒæ™¯è‰²å—ï¼ˆç‹¬ç«‹åŠŸèƒ½ï¼Œå…¨ç¨‹æ˜¾ç¤ºä¸€ä¸ªèƒŒæ™¯ï¼Œå¤ç”¨æ ‡é¢˜èƒŒæ™¯æ–¹æ³•ï¼‰
        
        Args:
            caption_data: å­—å¹•æ•°æ®åˆ—è¡¨ï¼Œç”¨äºè®¡ç®—æ€»æ—¶é•¿
            position: å­—å¹•ä½ç½® ("top"é¡¶éƒ¨, "bottom"åº•éƒ¨)
            bottom_transform_y: åº•éƒ¨ä½ç½®çš„transform_y
            scale: ç¼©æ”¾æ¯”ä¾‹
            background_style: èƒŒæ™¯æ ·å¼å‚æ•°
        """
        if not self.script:
            raise ValueError("è¯·å…ˆåˆ›å»ºè‰ç¨¿")
        
        if not caption_data:
            return None
        
        # é»˜è®¤èƒŒæ™¯æ ·å¼ï¼ˆå‚è€ƒæ ‡é¢˜èƒŒæ™¯æ ·å¼ï¼Œä½†é«˜åº¦è°ƒæ•´ä¸ºé€‚åˆå­—å¹•ï¼‰
        if background_style is None:
            background_style = {
                "color": "#000000",      # é»‘è‰²
                "alpha": 0.67,           # 67% ä¸é€æ˜åº¦
                "height": 0.25,          # 25% é«˜åº¦ï¼ˆæ¯”æ ‡é¢˜èƒŒæ™¯ç¨å°ï¼‰
                "width": 0.14,           # 14% å®½åº¦  
                "horizontal_offset": 0.5, # 50% å·¦å³é—´éš™
                "vertical_offset": 0.5,   # 50% ä¸Šä¸‹é—´éš™
                "round_radius": 0.0,     # åœ†è§’åŠå¾„
                "style": 1               # èƒŒæ™¯æ ·å¼
            }
        
        # è®¡ç®—å­—å¹•çš„æ€»æ—¶é•¿ï¼ˆä»ç¬¬ä¸€ä¸ªå­—å¹•å¼€å§‹åˆ°æœ€åä¸€ä¸ªå­—å¹•ç»“æŸï¼‰
        start_time = min(caption.get('start', 0) for caption in caption_data)
        end_time = max(caption.get('end', 0) for caption in caption_data)
        total_duration = end_time - start_time
        
        # æ ¹æ®ä½ç½®è®¾ç½®ä¸åŒçš„å‚ç›´ä½ç½®
        if position == "top":
            transform_y = 0.4
        else:
            transform_y = bottom_transform_y
        
        # åˆ›å»ºèƒŒæ™¯æ–‡æœ¬ç‰‡æ®µï¼ˆä½¿ç”¨å ä½ç¬¦ç¡®ä¿èƒŒæ™¯æ˜¾ç¤ºï¼‰
        placeholder_text = " " * 50  # ä½¿ç”¨å›ºå®šé•¿åº¦çš„å ä½ç¬¦
        
        # å¤ç”¨ add_styled_text_with_background æ–¹æ³•ï¼Œåˆ›å»ºå…¨ç¨‹æ˜¾ç¤ºçš„èƒŒæ™¯
        bg_segment = self.add_styled_text_with_background(
            text_content=placeholder_text,
            timerange_start=start_time,
            timerange_duration=total_duration,
            track_name="å†…å®¹å­—å¹•èƒŒæ™¯",
            position=position,
            background_style=background_style,
            text_transform_y=transform_y,
            line_spacing=0,
            bg_height=background_style["height"]
        )
        
        return bg_segment
    
    def add_transitions_and_effects(self, video_segments: List[draft.VideoSegment]):
        """ä¸ºè§†é¢‘ç‰‡æ®µæ·»åŠ è½¬åœºå’Œç‰¹æ•ˆ
        
        Args:
            video_segments: è§†é¢‘ç‰‡æ®µåˆ—è¡¨
        """
        for i, segment in enumerate(video_segments):
            # ä¸ºæ¯ä¸ªç‰‡æ®µæ·»åŠ å…¥åœºåŠ¨ç”»
            if i < len(video_segments) - 1:  # é™¤æœ€åä¸€ä¸ªç‰‡æ®µå¤–éƒ½æ·»åŠ è½¬åœº
                segment.add_transition(TransitionType.æ·¡åŒ–)
                
            # æ·»åŠ å…¥åœºåŠ¨ç”»
            segment.add_animation(IntroType.æ·¡å…¥)
    
    def process_workflow(self, inputs: Dict[str, Any]) -> str:
        """å¤„ç†å®Œæ•´çš„å·¥ä½œæµ - ä¸“æ³¨éŸ³é¢‘è½¬å½•ç”Ÿæˆå­—å¹•
        
        Args:
            inputs: è¾“å…¥å‚æ•°ï¼ŒåŒ…å«ï¼š
                - digital_video_url: æ•°å­—äººè§†é¢‘URL
                - material_video_url: ç´ æè§†é¢‘URL (å¯é€‰)
                - audio_url: éŸ³é¢‘URL (å¿…éœ€ï¼Œç”¨äºè½¬å½•)
                - title: è§†é¢‘æ ‡é¢˜ (å¯é€‰)
                - volcengine_appid: ç«å±±å¼•æ“AppID (å¿…éœ€)
                - volcengine_access_token: ç«å±±å¼•æ“è®¿é—®ä»¤ç‰Œ (å¿…éœ€)
                - subtitle_delay: å­—å¹•å»¶è¿Ÿï¼ˆç§’ï¼‰ï¼Œæ­£å€¼å»¶åï¼Œè´Ÿå€¼æå‰ (é»˜è®¤0)
                - subtitle_speed: å­—å¹•é€Ÿåº¦ç³»æ•°ï¼Œ>1åŠ å¿«ï¼Œ<1å‡æ…¢ (é»˜è®¤1.0)
                - background_music_path: èƒŒæ™¯éŸ³ä¹æ–‡ä»¶è·¯å¾„ (å¯é€‰)
                - background_music_volume: èƒŒæ™¯éŸ³ä¹éŸ³é‡ (é»˜è®¤0.3)
                
        Returns:
            è‰ç¨¿ä¿å­˜è·¯å¾„
        """
        # 0. è·å–é…ç½®å‚æ•°
        # ç«å±±å¼•æ“ASRé…ç½®ï¼ˆç”¨äºè¯­éŸ³è¯†åˆ«ï¼‰
        volcengine_appid = inputs.get('volcengine_appid')
        volcengine_access_token = inputs.get('volcengine_access_token')
        
        # è±†åŒ…APIé…ç½®ï¼ˆç”¨äºå…³é”®è¯æå–ï¼‰
        doubao_token = inputs.get('doubao_token')
        doubao_model = inputs.get('doubao_model', 'doubao-1-5-pro-32k-250115')
        
        # å…¶ä»–å‚æ•°
        audio_url = inputs.get('audio_url')
        subtitle_delay = inputs.get('subtitle_delay', 0.0)  # å­—å¹•å»¶è¿Ÿ
        subtitle_speed = inputs.get('subtitle_speed', 1.0)  # å­—å¹•é€Ÿåº¦ç³»æ•°
        background_music_path = inputs.get('background_music_path')  # èƒŒæ™¯éŸ³ä¹è·¯å¾„
        background_music_volume = inputs.get('background_music_volume', 0.3)  # èƒŒæ™¯éŸ³ä¹éŸ³é‡
        
        # éªŒè¯å¿…éœ€å‚æ•°
        if not audio_url:
            raise ValueError("audio_url æ˜¯å¿…éœ€å‚æ•°ï¼Œç”¨äºéŸ³é¢‘è½¬å½•")
        
        print(f"[INFO] éŸ³é¢‘è½¬å½•å­—å¹•å·¥ä½œæµ + AIå…³é”®è¯é«˜äº®")
        print(f"[INFO] éŸ³é¢‘URL: {audio_url}")
        print(f"[INFO] å­—å¹•å»¶è¿Ÿ: {subtitle_delay:.1f}ç§’")
        print(f"[INFO] å­—å¹•é€Ÿåº¦: {subtitle_speed:.1f}x")
        print(f"[INFO] ç«å±±å¼•æ“ASR (è¯­éŸ³è¯†åˆ«)")
        print(f"[INFO] è±†åŒ…API (å…³é”®è¯æå–): {'å·²é…ç½®' if doubao_token else 'æœªé…ç½®ï¼Œå°†ä½¿ç”¨æœ¬åœ°ç®—æ³•'}")
        
        # åˆå§‹åŒ–ç«å±±å¼•æ“ASR
        if volcengine_appid and volcengine_access_token:
            self.volcengine_asr = VolcengineASR(
                appid=volcengine_appid, 
                access_token=volcengine_access_token,
                doubao_token=doubao_token,
                doubao_model=doubao_model
            )
            print(f"[OK] ç«å±±å¼•æ“ASRå·²åˆå§‹åŒ– (AppID: {volcengine_appid})")
            if doubao_token:
                print(f"[OK] è±†åŒ…APIå·²é…ç½® (Model: {doubao_model})")
        else:
            raise ValueError("å¿…é¡»æä¾› volcengine_appid å’Œ volcengine_access_token å‚æ•°")
        
        # 1. åˆ›å»ºè‰ç¨¿
        self.create_draft()
        
        # 2. æ·»åŠ æ•°å­—äººè§†é¢‘ï¼ˆå¦‚æœæä¾›äº†éŸ³é¢‘URLï¼Œåˆ™ç›´æ¥å¤„ç†è§†é¢‘ä¸­çš„éŸ³é¢‘ï¼‰
        digital_video_url = inputs.get('digital_video_url')
        if digital_video_url:
            # å¦‚æœæä¾›äº†éŸ³é¢‘URLï¼Œä½¿ç”¨è§†é¢‘URLä½œä¸ºéŸ³é¢‘æºè¿›è¡Œå¤„ç†
            if audio_url:
                print(f"[INFO] ä½¿ç”¨è§†é¢‘éŸ³é¢‘è¿›è¡Œåœé¡¿ç§»é™¤å’Œå­—å¹•è¯†åˆ«")
                # ç›´æ¥ä½¿ç”¨è§†é¢‘URLè¿›è¡ŒéŸ³é¢‘å¤„ç†ï¼Œä¸éœ€è¦å•ç‹¬çš„éŸ³é¢‘è½¨é“
                self.add_digital_human_video(
                    digital_video_url, 
                    remove_pauses=True, 
                    min_pause_duration=0.2, 
                    max_word_gap=0.8
                )
            else:
                # æ²¡æœ‰éŸ³é¢‘URLï¼Œæ­£å¸¸æ·»åŠ è§†é¢‘
                self.add_digital_human_video(digital_video_url)
        
        # 3. æ·»åŠ ç´ æè§†é¢‘ï¼ˆå¦‚æœæœ‰ï¼‰
        material_video_url = inputs.get('material_video_url')
        if material_video_url:
            # æ¨¡æ‹Ÿæ—¶é—´è½´æ•°æ®
            timelines = [{'start': 0, 'end': 10}]  # å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´
            self.add_videos([material_video_url], timelines, volume=0.3)
        
        # 4.1. è§†é¢‘éŸ³é¢‘åœé¡¿å¤„ç†å·²å®Œæˆï¼Œå­—å¹•å·²åŒæ­¥
        video_subtitles_added = False
        if hasattr(self, 'adjusted_subtitles') and self.adjusted_subtitles:
            print(f"[INFO] è§†é¢‘éŸ³é¢‘åœé¡¿å¤„ç†å®Œæˆï¼Œå­—å¹•å·²åŒæ­¥")
            video_subtitles_added = True
        
        # 4.3. æ·»åŠ èƒŒæ™¯éŸ³ä¹ï¼ˆå¦‚æœæä¾›ï¼‰
        if background_music_path:
            print(f"[INFO] å‡†å¤‡æ·»åŠ èƒŒæ™¯éŸ³ä¹: {background_music_path}")
            try:
                self.add_background_music(background_music_path, volume=background_music_volume)
                print(f"[OK] èƒŒæ™¯éŸ³ä¹å·²æˆåŠŸæ·»åŠ : {background_music_path}")
            except Exception as e:
                print(f"[ERROR] èƒŒæ™¯éŸ³ä¹æ·»åŠ å¤±è´¥: {e}")
                import traceback
                print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        else:
            print("ğŸ“‹ æœªæä¾›èƒŒæ™¯éŸ³ä¹è·¯å¾„ï¼Œè·³è¿‡èƒŒæ™¯éŸ³ä¹æ·»åŠ ")

        # 4.8 æ·»åŠ ä¸€ä¸ªä¸‰è¡Œæ–‡æœ¬å¹¶åº”ç”¨èƒŒæ™¯æ ·å¼ï¼ˆä½äºç”»é¢ä¸­éƒ¨ï¼‰
        try:
            multiline_text = "                                                           \n\n "
            # ä½¿ç”¨ä¸æˆªå›¾ä¸€è‡´çš„èƒŒæ™¯å‚æ•°
            background_style = {
                "color": "#000000",      # é»‘è‰²
                "alpha": 0.67,           # ä¸é€æ˜åº¦ 67%
                "height": 1,          # é«˜åº¦ 31%
                "width": 1,           # å®½åº¦ 14%
                "horizontal_offset": 0.5, # å·¦å³é—´éš™ 50%
                "vertical_offset": 0.5,   # ä¸Šä¸‹é—´éš™ 50%
                "round_radius": 0.0,
                "style": 1
            }
            # èƒŒæ™¯æ—¶é•¿ä¸æ ‡é¢˜ä¸€è‡´ï¼šä½¿ç”¨é¡¹ç›®æ€»æ—¶é•¿ï¼ˆæˆ–éŸ³é¢‘æ—¶é•¿ï¼‰
            display_duration = self.project_duration if self.project_duration > 0 else (self.audio_duration if self.audio_duration > 0 else 5.0)
            self.add_styled_text_with_background(
                text_content=multiline_text,
                timerange_start=0,
                timerange_duration=display_duration,
                track_name="æ ‡é¢˜å­—å¹•èƒŒæ™¯",
                position="center",
                background_style=background_style,
                text_transform_y=0.73,
                line_spacing=4,
                bg_height=0.48
            )
        except Exception as e:
            print(f"[ERROR] æ·»åŠ ä¸‰è¡ŒèƒŒæ™¯æ–‡å­—å¤±è´¥: {e}")
        
        # 5. ç”ŸæˆéŸ³é¢‘è½¬å½•å­—å¹•
        title = inputs.get('title', '')
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»é€šè¿‡è§†é¢‘å¤„ç†æ·»åŠ äº†å­—å¹•
        if video_subtitles_added and hasattr(self, 'adjusted_subtitles') and self.adjusted_subtitles:
            print(f"[INFO] è§†é¢‘å¤„ç†å·²æ·»åŠ å­—å¹•ï¼Œè·³è¿‡éŸ³é¢‘è½¬å½•å­—å¹•æ·»åŠ ")
            final_subtitles = self.adjusted_subtitles
        else:
            # éŸ³é¢‘è½¬å½•ç”Ÿæˆå­—å¹•
            print("ğŸ¤ å¼€å§‹éŸ³é¢‘è½¬å½•ç”Ÿæˆå­—å¹•")
            subtitle_objects = self.transcribe_audio_and_generate_subtitles(audio_url)
            print(f"ğŸ” éŸ³é¢‘è½¬å½•å­—å¹•: {subtitle_objects}")
            
            if subtitle_objects:
                print(f"[OK] éŸ³é¢‘è½¬å½•æˆåŠŸï¼Œç”Ÿæˆ {len(subtitle_objects)} æ®µå­—å¹•")
                
                # ğŸ”¥ ä½¿ç”¨ç«å±±å¼•æ“ASRç»“æœï¼Œç›´æ¥ä½¿ç”¨
                print(f"ğŸš€ ä½¿ç”¨ç«å±±å¼•æ“ASRç»“æœ")
                final_subtitles = subtitle_objects
                
                # åªåœ¨éœ€è¦æ—¶åº”ç”¨æ—¶é—´è°ƒæ•´
                if subtitle_delay != 0.0 or subtitle_speed != 1.0:
                    print(f"â° åº”ç”¨æ—¶é—´è°ƒæ•´: å»¶è¿Ÿ{subtitle_delay:.1f}s, é€Ÿåº¦{subtitle_speed:.1f}x")
                    final_subtitles = self.adjust_subtitle_timing(final_subtitles, subtitle_delay, subtitle_speed)
                
                # ğŸ¤– ä½¿ç”¨AIæå–å…³é”®è¯ç”¨äºé«˜äº®
                print("\nğŸ¤– å¼€å§‹AIå…³é”®è¯æå–...")
                all_text = " ".join([sub['text'] for sub in final_subtitles])
                keywords = self.volcengine_asr.extract_keywords_with_ai(all_text, max_keywords=8)
                
                if keywords:
                    print(f"[OK] AIæå–åˆ° {len(keywords)} ä¸ªå…³é”®è¯: {keywords}")
                    keyword_color = (1.0, 0.984313725490196, 0.7254901960784313)  # é»„è‰²é«˜äº®
                else:
                    print("âš ï¸ æœªæå–åˆ°å…³é”®è¯ï¼Œä½¿ç”¨æ™®é€šå­—å¹•")
                    keyword_color = None
                
                # æ·»åŠ å­—å¹•åˆ°è§†é¢‘é¡¹ç›®ï¼ˆå¸¦å…³é”®è¯é«˜äº®ï¼‰
                self.add_captions(final_subtitles, track_name="å†…å®¹å­—å¹•è½¨é“", position="bottom",
                                keywords=keywords, 
                                base_color=(1.0, 1.0, 1.0),  # ç™½è‰²
                                base_font_size=8.0,  # 8å·
                                font_type=draft.FontType.ä¿ªé‡‘é»‘,  # ä¿ªé‡‘é»‘
                                highlight_size=10.0,  # é«˜äº®10å·
                                highlight_color=(1.0, 0.7529411765, 0.2470588235),  # #ffc03f
                                scale=1.39)  # ç¼©æ”¾1.39
                
                # ä¸ºå­—å¹•æ·»åŠ èƒŒæ™¯è‰²å—ï¼ˆç‹¬ç«‹åŠŸèƒ½ï¼‰
                self.add_caption_backgrounds(final_subtitles, position="bottom", 
                                           bottom_transform_y=-0.3, scale=1.39)
            else:
                print("[WARN] éŸ³é¢‘è½¬å½•å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆå­—å¹•")
                final_subtitles = []
        
        # æ˜¾ç¤ºå­—å¹•æ·»åŠ ç»“æœ
        if final_subtitles:
            print(f"\nå·²æ·»åŠ  {len(final_subtitles)} æ®µå­—å¹•åˆ°å‰ªæ˜ é¡¹ç›®")
            print("å‰3æ®µé¢„è§ˆ:")
            for i, subtitle in enumerate(final_subtitles[:3], 1):
                start = subtitle['start']
                end = subtitle['end']
                text = subtitle['text']
                print(f"   {i}. [{start:.3f}s-{end:.3f}s] {text}")
            
            # æ·»åŠ æ ‡é¢˜å­—å¹•ï¼ˆä¸‰è¡Œæ ‡é¢˜ï¼Œç¬¬äºŒè¡Œé«˜äº®ï¼‰
            if title:
                title_duration = self.project_duration if self.project_duration > 0 else self.audio_duration
                print(f"æ·»åŠ ä¸‰è¡Œæ ‡é¢˜: {title} (0s - {title_duration:.1f}s)")
                self.add_three_line_title(
                    title=title,
                    start=0.0,
                    duration=title_duration,
                    transform_y=0.72,
                    line_spacing=4,
                    highlight_color=(1.0, 0.7529411765, 0.2470588235),  # #ffc03f
                    track_name="æ ‡é¢˜å­—å¹•è½¨é“"
                )
        else:
            print("[ERROR] éŸ³é¢‘è½¬å½•å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆå­—å¹•")
            raise ValueError("éŸ³é¢‘è½¬å½•å¤±è´¥ï¼Œè¯·æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶å’ŒAPIé…ç½®")
        
        # 6. ä¿å­˜è‰ç¨¿
        self.script.save()
        
        return self.script.save_path
    
    def _remove_audio_pauses(self, original_audio_url: str, local_audio_path: str, min_pause_duration: float = 0.8, 
                           max_word_gap: float = 1.5) -> Optional[str]:
        """
        ç§»é™¤éŸ³é¢‘ä¸­çš„åœé¡¿
        
        Args:
            original_audio_url: åŸå§‹éŸ³é¢‘URLï¼ˆç”¨äºASRï¼‰
            local_audio_path: æœ¬åœ°éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºå¤„ç†ï¼‰
            min_pause_duration: æœ€å°åœé¡¿æ—¶é•¿(ç§’)
            max_word_gap: å•è¯é—´æœ€å¤§é—´éš”(ç§’)
            
        Returns:
            Optional[str]: å¤„ç†åçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        if not self.volcengine_asr:
            print("âš ï¸  ASRæœªåˆå§‹åŒ–ï¼Œè·³è¿‡åœé¡¿ç§»é™¤")
            return None
        
        try:
            print("ğŸ” å¼€å§‹éŸ³é¢‘åœé¡¿æ£€æµ‹å’Œç§»é™¤...")
            
            # åˆå§‹åŒ–åœé¡¿ç§»é™¤å™¨
            if not self.silence_remover:
                self.silence_remover = ASRBasedSilenceRemover(min_pause_duration, max_word_gap)
            
            # ä½¿ç”¨ASRè½¬å½•éŸ³é¢‘ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹URL
            print(f"[DEBUG] ä½¿ç”¨åŸå§‹éŸ³é¢‘URLè¿›è¡ŒASR: {original_audio_url}")
            print(f"[DEBUG] original_audio_url type: {type(original_audio_url)}")
            print(f"[DEBUG] original_audio_url.startswith http: {original_audio_url.startswith('http')}")
            
            asr_result = self.volcengine_asr.transcribe_audio_for_silence_detection(original_audio_url)
            
            if not asr_result:
                print("âš ï¸  ASRè½¬å½•å¤±è´¥ï¼Œè·³è¿‡åœé¡¿ç§»é™¤")
                return None
            
            # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as temp_file:
                output_path = temp_file.name
            
            # ç§»é™¤åœé¡¿
            result = self.silence_remover.remove_pauses_from_audio(
                local_audio_path, asr_result, output_path
            )
            
            if result['success']:
                pause_stats = result['pause_statistics']
                print(f"[OK] åœé¡¿ç§»é™¤å®Œæˆ:")
                print(f"   - ç§»é™¤åœé¡¿æ—¶é•¿: {result['removed_duration']:.2f} ç§’")
                print(f"   - åœé¡¿æ¬¡æ•°: {pause_stats['pause_count']}")
                print(f"   - å¹³å‡åœé¡¿æ—¶é•¿: {pause_stats['average_pause_duration']:.2f} ç§’")
                print(f"   - å¤„ç†åéŸ³é¢‘æ—¶é•¿: {result['processed_duration']:.2f} ç§’")
                
                return output_path
            else:
                print("[ERROR] åœé¡¿ç§»é™¤å¤±è´¥")
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(output_path):
                    os.unlink(output_path)
                return None
                
        except Exception as e:
            print(f"[ERROR] åœé¡¿ç§»é™¤å¤„ç†å¤±è´¥: {e}")
            return None
    
    def _remove_audio_video_pauses(self, original_audio_url: str, local_audio_path: str, video_path: str, 
                                 min_pause_duration: float = 0.8, max_word_gap: float = 1.5) -> Tuple[Optional[str], Optional[str]]:
        """
        åŒæ—¶ç§»é™¤éŸ³é¢‘å’Œè§†é¢‘ä¸­çš„åœé¡¿
        
        Args:
            original_audio_url: åŸå§‹éŸ³é¢‘URLï¼ˆç”¨äºASRï¼‰
            local_audio_path: æœ¬åœ°éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºå¤„ç†ï¼‰
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            min_pause_duration: æœ€å°åœé¡¿æ—¶é•¿(ç§’)
            max_word_gap: å•è¯é—´æœ€å¤§é—´éš”(ç§’)
            
        Returns:
            Tuple[Optional[str], Optional[str]]: (å¤„ç†åçš„éŸ³é¢‘è·¯å¾„, å¤„ç†åçš„è§†é¢‘è·¯å¾„)
        """
        if not self.volcengine_asr:
            print("âš ï¸  ASRæœªåˆå§‹åŒ–ï¼Œè·³è¿‡éŸ³è§†é¢‘åœé¡¿ç§»é™¤")
            return None, None
        
        try:
            print("ğŸ” å¼€å§‹éŸ³è§†é¢‘åœé¡¿æ£€æµ‹å’Œç§»é™¤...")
            
            # åˆå§‹åŒ–åœé¡¿ç§»é™¤å™¨
            if not self.silence_remover:
                self.silence_remover = ASRBasedSilenceRemover(min_pause_duration, max_word_gap)
            
            # ä½¿ç”¨ASRè½¬å½•éŸ³é¢‘ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹URL
            print(f"[DEBUG] ä½¿ç”¨åŸå§‹éŸ³é¢‘URLè¿›è¡ŒASR: {original_audio_url}")
            print(f"[DEBUG] original_audio_url type: {type(original_audio_url)}")
            print(f"[DEBUG] original_audio_url.startswith http: {original_audio_url.startswith('http')}")
            
            asr_result = self.volcengine_asr.transcribe_audio_for_silence_detection(original_audio_url)
            
            if not asr_result:
                print("âš ï¸  ASRè½¬å½•å¤±è´¥ï¼Œè·³è¿‡éŸ³è§†é¢‘åœé¡¿ç§»é™¤")
                return None, None
            
            # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as temp_audio:
                output_audio_path = temp_audio.name
            
            with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_video:
                output_video_path = temp_video.name
            
            # åŒæ—¶ç§»é™¤éŸ³é¢‘å’Œè§†é¢‘çš„åœé¡¿
            result = self.silence_remover.remove_pauses_from_audio_and_video(
                local_audio_path, video_path, asr_result, output_audio_path, output_video_path
            )
            
            if result['success']:
                pause_stats = result['pause_statistics']
                print(f"[OK] éŸ³è§†é¢‘åœé¡¿ç§»é™¤å®Œæˆ:")
                print(f"   - ç§»é™¤åœé¡¿æ—¶é•¿: {result['removed_duration']:.2f} ç§’")
                print(f"   - åœé¡¿æ¬¡æ•°: {pause_stats['pause_count']}")
                print(f"   - å¹³å‡åœé¡¿æ—¶é•¿: {pause_stats['average_pause_duration']:.2f} ç§’")
                print(f"   - å¤„ç†åéŸ³é¢‘æ—¶é•¿: {result['processed_duration']:.2f} ç§’")
                
                return output_audio_path, output_video_path
            else:
                print("[ERROR] éŸ³è§†é¢‘åœé¡¿ç§»é™¤å¤±è´¥")
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                for path in [output_audio_path, output_video_path]:
                    if os.path.exists(path):
                        os.unlink(path)
                return None, None
                
        except Exception as e:
            print(f"[ERROR] éŸ³è§†é¢‘åœé¡¿ç§»é™¤å¤„ç†å¤±è´¥: {e}")
            return None, None
    
    def _process_audio_pauses_with_asr_result(self, local_audio_path: str, asr_result: Dict[str, Any], 
                                           pause_segments: List[Tuple[float, float]], 
                                           min_pause_duration: float = 0.2, 
                                           max_word_gap: float = 0.8) -> Optional[str]:
        """
        åŸºäºASRç»“æœå¤„ç†éŸ³é¢‘åœé¡¿
        
        Args:
            local_audio_path: æœ¬åœ°éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            asr_result: ASRè¯†åˆ«ç»“æœ
            pause_segments: åœé¡¿æ®µè½åˆ—è¡¨
            min_pause_duration: æœ€å°åœé¡¿æ—¶é•¿
            max_word_gap: æœ€å¤§å•è¯é—´éš”
            
        Returns:
            å¤„ç†åçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        try:
            print(f"[DEBUG] å¼€å§‹åŸºäºASRç»“æœå¤„ç†éŸ³é¢‘åœé¡¿")
            print(f"[DEBUG] åœé¡¿æ®µè½æ•°é‡: {len(pause_segments)}")
            
            # è®¡ç®—æœ‰å£°æ®µè½
            total_duration = asr_result.get('duration', 0)
            speech_segments = []
            
            if pause_segments:
                # æ„å»ºæœ‰å£°æ®µè½
                current_time = 0.0
                
                for pause_start, pause_end in pause_segments:
                    if current_time < pause_start:
                        speech_segments.append((current_time, pause_start))
                    current_time = pause_end
                
                # æ·»åŠ æœ€åä¸€æ®µ
                if current_time < total_duration:
                    speech_segments.append((current_time, total_duration))
            
            if not speech_segments:
                print("[DEBUG] æ²¡æœ‰æœ‰å£°æ®µè½ï¼Œè¿”å›åŸå§‹éŸ³é¢‘")
                return local_audio_path
            
            print(f"[DEBUG] æœ‰å£°æ®µè½æ•°é‡: {len(speech_segments)}")
            
            # ä½¿ç”¨FFmpegæå–æœ‰å£°æ®µè½
            with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as temp_file:
                output_path = temp_file.name
            
            # æ„å»ºFFmpegè¿‡æ»¤å›¾
            filter_complex = []
            
            for i, (start, end) in enumerate(speech_segments):
                duration = end - start
                filter_complex.append(f'[0:a]atrim=start={start}:duration={duration},asetpts=PTS-STARTPTS[a{i}]')
            
            # æ‹¼æ¥æ‰€æœ‰æ®µè½
            inputs = ''.join(f'[a{i}]' for i in range(len(speech_segments)))
            filter_complex.append(f'{inputs}concat=n={len(speech_segments)}:v=0:a=1[out]')
            
            cmd = [
                'ffmpeg',
                '-i', local_audio_path,
                '-filter_complex', ';'.join(filter_complex),
                '-map', '[out]',
                '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                output_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            
            if result.returncode == 0:
                # è®¡ç®—ç§»é™¤çš„åœé¡¿æ—¶é•¿
                removed_duration = sum(end - start for start, end in pause_segments)
                new_duration = sum(end - start for start, end in speech_segments)
                
                print(f"[DEBUG] éŸ³é¢‘åœé¡¿å¤„ç†å®Œæˆ:")
                print(f"   - åŸå§‹æ—¶é•¿: {total_duration:.2f} ç§’")
                print(f"   - ç§»é™¤åœé¡¿: {removed_duration:.2f} ç§’")
                print(f"   - æ–°æ—¶é•¿: {new_duration:.2f} ç§’")
                
                return output_path
            else:
                print(f"[DEBUG] FFmpegå¤„ç†å¤±è´¥: {result.stderr}")
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(output_path):
                    os.unlink(output_path)
                return None
                
        except Exception as e:
            print(f"[DEBUG] éŸ³é¢‘åœé¡¿å¤„ç†å¤±è´¥: {e}")
            return None
    
    def _process_video_pauses_by_segmentation(self, input_video_path: str, output_video_path: str, pause_segments: List[Tuple[float, float]]) -> List[str]:
        """ä½¿ç”¨è§†é¢‘ç‰‡æ®µåˆ‡å‰²æ–¹å¼å¤„ç†åœé¡¿ï¼ˆä¿æŒåŸå§‹è§†é¢‘è´¨é‡ï¼‰
        
        æŒ‰ç…§ç”¨æˆ·å»ºè®®çš„é€»è¾‘ï¼šåˆ‡å‰²æ‰ä¸éœ€è¦çš„ä¸­é—´ç‰‡æ®µï¼Œç›´æ¥æ–°å¢å‰©ä¸‹çš„æœ‰æ•ˆç‰‡æ®µï¼ˆä¸æ‹¼æ¥ï¼‰
        
        Args:
            input_video_path: è¾“å…¥è§†é¢‘è·¯å¾„
            output_video_path: è¾“å‡ºè§†é¢‘è·¯å¾„ï¼ˆå¦‚æœåªæœ‰ä¸€ä¸ªç‰‡æ®µæ—¶ä½¿ç”¨ï¼‰
            pause_segments: éœ€è¦ç§»é™¤çš„åœé¡¿æ—¶é—´æ®µåˆ—è¡¨ [(start1, end1), (start2, end2), ...]
            
        Returns:
            List[str]: åˆ‡å‰²åçš„æœ‰æ•ˆè§†é¢‘ç‰‡æ®µè·¯å¾„åˆ—è¡¨
        """
        print(f"[DEBUG] å¼€å§‹ä½¿ç”¨ç‰‡æ®µåˆ‡å‰²æ–¹å¼å¤„ç†è§†é¢‘åœé¡¿")
        print(f"[DEBUG] è¾“å…¥è§†é¢‘: {input_video_path}")
        print(f"[DEBUG] éœ€è¦ç§»é™¤çš„åœé¡¿æ®µ: {len(pause_segments)} ä¸ª")
        
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(input_video_path):
            print(f"[ERROR] è¾“å…¥è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {input_video_path}")
            return []
        
        try:
            # è·å–è§†é¢‘æ€»æ—¶é•¿
            probe_cmd = [
                'ffprobe', '-v', 'quiet', '-show_entries', 'format=duration',
                '-of', 'csv=p=0', input_video_path
            ]
            result = subprocess.run(probe_cmd, capture_output=True, text=True, check=True)
            total_duration = float(result.stdout.strip())
            print(f"[DEBUG] è§†é¢‘æ€»æ—¶é•¿: {total_duration:.3f} ç§’")
            
            # å¦‚æœæ²¡æœ‰åœé¡¿æ®µï¼Œç›´æ¥è¿”å›åŸè§†é¢‘è·¯å¾„
            if not pause_segments:
                print("[DEBUG] æ²¡æœ‰åœé¡¿æ®µéœ€è¦ç§»é™¤ï¼Œè¿”å›åŸè§†é¢‘")
                return [input_video_path]
            
            # ç¬¬ä¸€æ­¥ï¼šå¤„ç†å’Œåˆå¹¶åœé¡¿ç‰‡æ®µï¼ˆéœ€è¦ä¸¢å¼ƒçš„ï¼‰
            print(f"[DEBUG] ç¬¬ä¸€æ­¥ï¼šå¤„ç†éœ€è¦ä¸¢å¼ƒçš„åœé¡¿ç‰‡æ®µ")
            sorted_pauses = sorted(pause_segments, key=lambda x: x[0])
            merged_pauses = []
            
            for pause_start, pause_end in sorted_pauses:
                if not merged_pauses:
                    merged_pauses.append([pause_start, pause_end])
                    print(f"[DEBUG] æ·»åŠ åœé¡¿ç‰‡æ®µ: [{pause_start:.3f}s-{pause_end:.3f}s]")
                else:
                    last_start, last_end = merged_pauses[-1]
                    if pause_start <= last_end:
                        # é‡å ï¼Œåˆå¹¶åœé¡¿æ®µ
                        merged_pauses[-1][1] = max(last_end, pause_end)
                        print(f"[DEBUG] åˆå¹¶é‡å åœé¡¿: [{last_start:.3f}s-{last_end:.3f}s] + [{pause_start:.3f}s-{pause_end:.3f}s] -> [{merged_pauses[-1][0]:.3f}s-{merged_pauses[-1][1]:.3f}s]")
                    else:
                        merged_pauses.append([pause_start, pause_end])
                        print(f"[DEBUG] æ·»åŠ åœé¡¿ç‰‡æ®µ: [{pause_start:.3f}s-{pause_end:.3f}s]")
            
            print(f"[DEBUG] åˆå¹¶åéœ€è¦ä¸¢å¼ƒçš„åœé¡¿ç‰‡æ®µ: {len(merged_pauses)} ä¸ª")
            for i, (start, end) in enumerate(merged_pauses):
                print(f"  åœé¡¿{i+1}: [{start:.3f}s-{end:.3f}s] (æ—¶é•¿: {end-start:.3f}s)")
            
            # ç¬¬äºŒæ­¥ï¼šè‡ªåŠ¨ç”Ÿæˆéœ€è¦ä¿ç•™çš„æœ‰æ•ˆç‰‡æ®µ
            print(f"[DEBUG] ç¬¬äºŒæ­¥ï¼šç”Ÿæˆéœ€è¦ä¿ç•™çš„æœ‰æ•ˆç‰‡æ®µ")
            valid_segments = []
            current_time = 0.0
            
            for pause_start, pause_end in merged_pauses:
                if current_time < pause_start:
                    # åœ¨åœé¡¿ç‰‡æ®µå‰çš„æœ‰æ•ˆç‰‡æ®µ
                    valid_segments.append((current_time, pause_start))
                    print(f"[DEBUG] ç”Ÿæˆæœ‰æ•ˆç‰‡æ®µ: [{current_time:.3f}s-{pause_start:.3f}s] (æ—¶é•¿: {pause_start-current_time:.3f}s)")
                # è·³è¿‡åœé¡¿ç‰‡æ®µï¼Œæ›´æ–°å½“å‰æ—¶é—´
                current_time = pause_end
            
            # æ·»åŠ æœ€åä¸€æ®µæœ‰æ•ˆç‰‡æ®µ
            if current_time < total_duration:
                valid_segments.append((current_time, total_duration))
                print(f"[DEBUG] ç”Ÿæˆæœ€åæœ‰æ•ˆç‰‡æ®µ: [{current_time:.3f}s-{total_duration:.3f}s] (æ—¶é•¿: {total_duration-current_time:.3f}s)")
            
            print(f"[DEBUG] æ€»å…±ç”Ÿæˆ {len(valid_segments)} ä¸ªæœ‰æ•ˆç‰‡æ®µ")
            
            # ç¬¬ä¸‰æ­¥ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†
            if len(valid_segments) == 1 and valid_segments[0] == (0.0, total_duration):
                print("[DEBUG] æ²¡æœ‰å®é™…éœ€è¦ç§»é™¤çš„å†…å®¹ï¼Œè¿”å›åŸè§†é¢‘")
                return [input_video_path]
            
            # ç¬¬å››æ­¥ï¼šåˆ‡å‰²æœ‰æ•ˆç‰‡æ®µï¼ˆä¸æ‹¼æ¥ï¼Œç›´æ¥è¿”å›å¤šä¸ªç‰‡æ®µï¼‰
            print(f"[DEBUG] ç¬¬ä¸‰æ­¥ï¼šåˆ‡å‰²æœ‰æ•ˆç‰‡æ®µï¼ˆä¸æ‹¼æ¥ï¼‰")
            
            segment_files = []
            import uuid
            segment_id = str(uuid.uuid4())[:8]
            
            # ç¡®ä¿temp_materialsç›®å½•å­˜åœ¨
            temp_dir = "temp_materials"
            if not os.path.exists(temp_dir):
                os.makedirs(temp_dir)
            
            # åˆ‡å‰²æ¯ä¸ªæœ‰æ•ˆç‰‡æ®µ
            for i, (start, end) in enumerate(valid_segments):
                duration = end - start
                segment_file = f"temp_materials/segment_{segment_id}_{i:03d}.mp4"
                
                print(f"[DEBUG] åˆ‡å‰²æœ‰æ•ˆç‰‡æ®µ {i+1}: [{start:.3f}s-{end:.3f}s] (æ—¶é•¿: {duration:.3f}s)")
                
                # ä½¿ç”¨ç²¾ç¡®çš„æ—¶é—´åˆ‡å‰²ï¼Œä¿æŒåŸå§‹ç¼–ç 
                # ä¿®å¤ï¼šå°†-sså‚æ•°æ”¾åœ¨-iä¹‹åä»¥è·å¾—ç²¾ç¡®åˆ‡å‰²ï¼Œè™½ç„¶é€Ÿåº¦è¾ƒæ…¢ä½†ç²¾åº¦æ›´é«˜
                print(f"[DEBUG] FFmpegåˆ‡å‰²å‘½ä»¤:")
                print(f"[DEBUG]   è¾“å…¥è§†é¢‘: {input_video_path}")
                print(f"[DEBUG]   å¼€å§‹æ—¶é—´: {start:.6f}s")
                print(f"[DEBUG]   æŒç»­æ—¶é•¿: {duration:.6f}s")
                print(f"[DEBUG]   è¾“å‡ºæ–‡ä»¶: {segment_file}")
                
                try:
                    # æ ¹æ®ä¸“ä¸šåˆ†æï¼šç›´æ¥ä½¿ç”¨é‡æ–°ç¼–ç ç¡®ä¿ç²¾ç¡®åˆ‡å‰²
                    # é¿å…å…³é”®å¸§åˆ‡å‰²é—®é¢˜ï¼Œä½¿ç”¨-ssåœ¨-iä¹‹åè¿›è¡Œç²¾ç¡®åˆ‡å‰²
                    cmd = [
                        'ffmpeg', '-ss', f"{start:.6f}", '-to', f"{start + duration:.6f}",
                        '-i', input_video_path,
                        '-c:v', 'libx264', '-preset', 'fast', '-crf', '23',
                        '-c:a', 'aac', '-b:a', '128k',
                        '-map', '0',  # ç¡®ä¿æ˜ å°„æ‰€æœ‰æµ
                        '-avoid_negative_ts', 'make_zero',
                        '-fflags', '+genpts',  # é‡æ–°ç”Ÿæˆæ—¶é—´æˆ³
                        '-g', '30',  # è®¾ç½®åˆç†çš„å…³é”®å¸§é—´éš”
                        '-keyint_min', '15',  # æœ€å°å…³é”®å¸§é—´éš”
                        '-sc_threshold', '0',  # ç¦ç”¨åœºæ™¯åˆ‡å‰²
                        '-pix_fmt', 'yuv420p',  # ç¡®ä¿åƒç´ æ ¼å¼å…¼å®¹
                        segment_file, '-y'
                    ]
                    print(f"[DEBUG] æ‰§è¡Œç²¾ç¡®åˆ‡å‰²å‘½ä»¤: {' '.join(cmd)}")
                    
                    result = subprocess.run(cmd, check=True, capture_output=True, text=True)
                    if result.stderr:
                        print(f"[DEBUG] FFmpeg stderr: {result.stderr}")
                    print(f"[DEBUG] ç²¾ç¡®åˆ‡å‰²å®Œæˆ")
                    
                    # éªŒè¯åˆ‡å‰²ç»“æœ
                    verify_cmd = [
                        'ffprobe', '-v', 'quiet', '-show_entries', 'format=duration',
                        '-of', 'csv=p=0', segment_file
                    ]
                    verify_result = subprocess.run(verify_cmd, capture_output=True, text=True, check=True)
                    actual_duration = float(verify_result.stdout.strip())
                    
                    print(f"[DEBUG] æœ‰æ•ˆç‰‡æ®µ {i+1}åˆ‡å‰²å®Œæˆ: {segment_file}")
                    print(f"[DEBUG]   è®¡åˆ’æ—¶é•¿: {duration:.3f}s")
                    print(f"[DEBUG]   å®é™…æ—¶é•¿: {actual_duration:.3f}s")
                    
                    # æ£€æŸ¥æ—¶é•¿æ˜¯å¦æ­£ç¡®ï¼ˆä½¿ç”¨åŠ¨æ€å®¹å·®ï¼‰
                    duration_diff = abs(actual_duration - duration)
                    tolerance = min(0.1, duration * 0.05)  # åŠ¨æ€å®¹å·®ï¼šæœ€å°0.1ç§’æˆ–5%
                    
                    if duration_diff > tolerance:
                        print(f"[WARN] ç‰‡æ®µ {i+1} æ—¶é•¿åå·®è¾ƒå¤§: {duration_diff:.3f}s (å®¹å·®: {tolerance:.3f}s)")
                    else:
                        print(f"[DEBUG] ç‰‡æ®µ {i+1} æ—¶é•¿æ­£ç¡® (åå·®: {duration_diff:.3f}s)")
                    
                    # ç®€å•éªŒè¯è§†é¢‘æ–‡ä»¶æœ‰æ•ˆæ€§
                    try:
                        # æ£€æŸ¥è§†é¢‘æµæ˜¯å¦å­˜åœ¨
                        video_check_cmd = [
                            'ffprobe', '-v', 'quiet', '-select_streams', 'v:0',
                            '-show_entries', 'stream=codec_type',
                            '-of', 'csv=p=0', segment_file
                        ]
                        video_check_result = subprocess.run(video_check_cmd, capture_output=True, text=True, check=True)
                        if not video_check_result.stdout.strip():
                            raise Exception("åˆ‡å‰²åçš„æ–‡ä»¶æ²¡æœ‰è§†é¢‘æµ")
                        
                        print(f"[OK] è§†é¢‘æ–‡ä»¶éªŒè¯é€šè¿‡: {segment_file}")
                        segment_files.append(segment_file)
                        
                    except Exception as validation_error:
                        print(f"[ERROR] è§†é¢‘æ–‡ä»¶éªŒè¯å¤±è´¥: {validation_error}")
                        continue
                    
                except subprocess.CalledProcessError as e:
                    print(f"[ERROR] åˆ‡å‰²ç‰‡æ®µ {i+1} å¤±è´¥: {e}")
                    # å¦‚æœæŸä¸ªç‰‡æ®µåˆ‡å‰²å¤±è´¥ï¼Œå°è¯•å¤åˆ¶åŸè§†é¢‘
                    if i == 0 and len(valid_segments) == 1:
                        subprocess.run([
                            'ffmpeg', '-i', input_video_path, '-c', 'copy', segment_file, '-y'
                        ], check=True, capture_output=True)
                        segment_files.append(segment_file)
                        print(f"[DEBUG] å›é€€å®Œæˆï¼Œä½¿ç”¨åŸè§†é¢‘: {segment_file}")
            
            print(f"[OK] è§†é¢‘æœ‰æ•ˆç‰‡æ®µåˆ‡å‰²å®Œæˆï¼Œå…±ç”Ÿæˆ {len(segment_files)} ä¸ªç‰‡æ®µ")
            
            # è¿”å›åˆ‡å‰²åçš„ç‰‡æ®µåˆ—è¡¨
            return segment_files
            
        except Exception as e:
            print(f"[ERROR] è§†é¢‘ç‰‡æ®µåˆ‡å‰²å¤„ç†å¤±è´¥: {e}")
            import traceback
            print(f"[ERROR] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            # å¦‚æœå¤±è´¥ï¼Œè¿”å›åŸè§†é¢‘è·¯å¾„
            return [input_video_path]
    
    def _adjust_subtitle_timings(self, original_subtitles: List[Dict[str, Any]], 
                                pause_segments: List[Tuple[float, float]]) -> List[Dict[str, Any]]:
        """
        æ ¹æ®ç§»é™¤çš„åœé¡¿è°ƒæ•´å­—å¹•æ—¶é—´è½´
        
        Args:
            original_subtitles: åŸå§‹å­—å¹•åˆ—è¡¨
            pause_segments: è¢«ç§»é™¤çš„åœé¡¿æ®µè½åˆ—è¡¨
            
        Returns:
            è°ƒæ•´åçš„å­—å¹•åˆ—è¡¨
        """
        try:
            print(f"[DEBUG] å¼€å§‹è°ƒæ•´å­—å¹•æ—¶é—´è½´")
            print(f"[DEBUG] åŸå§‹å­—å¹•æ•°é‡: {len(original_subtitles)}")
            print(f"[DEBUG] åœé¡¿æ®µè½æ•°é‡: {len(pause_segments)}")
            
            adjusted_subtitles = []
            
            for subtitle in original_subtitles:
                original_start = subtitle['start']
                original_end = subtitle['end']
                
                # è®¡ç®—åœ¨è¿™ä¸ªå­—å¹•ä¹‹å‰è¢«ç§»é™¤çš„åœé¡¿æ—¶é•¿
                removed_time_before = 0.0
                
                for pause_start, pause_end in pause_segments:
                    if pause_end <= original_start:
                        # å®Œå…¨åœ¨å­—å¹•ä¹‹å‰çš„åœé¡¿
                        removed_time_before += (pause_end - pause_start)
                    elif pause_start < original_start and pause_end > original_start:
                        # ä¸å­—å¹•å¼€å§‹æ—¶é—´é‡å çš„åœé¡¿
                        removed_time_before += (original_start - pause_start)
                
                # è°ƒæ•´æ—¶é—´
                new_start = original_start - removed_time_before
                new_end = original_end - removed_time_before
                
                # ç¡®ä¿æ—¶é—´ä¸ä¸ºè´Ÿ
                new_start = max(0, new_start)
                new_end = max(new_start, new_end)
                
                adjusted_subtitle = {
                    'text': subtitle['text'],
                    'start': new_start,
                    'end': new_end
                }
                
                adjusted_subtitles.append(adjusted_subtitle)
                
                print(f"[DEBUG] å­—å¹•è°ƒæ•´: {subtitle['text']}")
                print(f"   åŸå§‹æ—¶é—´: {original_start:.3f}s - {original_end:.3f}s")
                print(f"   è°ƒæ•´æ—¶é—´: {new_start:.3f}s - {new_end:.3f}s")
            
            print(f"[DEBUG] å­—å¹•æ—¶é—´è½´è°ƒæ•´å®Œæˆï¼Œå…± {len(adjusted_subtitles)} æ®µå­—å¹•")
            return adjusted_subtitles
            
        except Exception as e:
            print(f"[DEBUG] å­—å¹•æ—¶é—´è½´è°ƒæ•´å¤±è´¥: {e}")
            return original_subtitles  # å¤±è´¥æ—¶è¿”å›åŸå§‹å­—å¹•


def main():
    """ä¸»å‡½æ•° - éŸ³é¢‘è½¬å½•æ™ºèƒ½å­—å¹•å·¥ä½œæµ"""
    # é…ç½®å‰ªæ˜ è‰ç¨¿æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆéœ€è¦æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰
    draft_folder_path = r"C:\Users\nrgc\AppData\Local\JianyingPro\User Data\Projects\com.lveditor.draft"
    
    print("[INFO] éŸ³é¢‘è½¬å½•æ™ºèƒ½å­—å¹•å·¥ä½œæµ + AIå…³é”®è¯é«˜äº® + èƒŒæ™¯éŸ³ä¹")
    print("=" * 60)
    print("è‡ªåŠ¨è½¬å½•éŸ³é¢‘å¹¶ç”Ÿæˆæ™ºèƒ½å­—å¹•ï¼Œä½¿ç”¨AIè¯†åˆ«å…³é”®è¯è¿›è¡Œé«˜äº®æ˜¾ç¤ºï¼Œå¹¶æ·»åŠ åå°”å…¹èƒŒæ™¯éŸ³ä¹")
    
    # åˆ›å»ºå·¥ä½œæµå®ä¾‹
    workflow = VideoEditingWorkflow(draft_folder_path, "audio_transcription_demo")
    
    # é…ç½®åå°”å…¹èƒŒæ™¯éŸ³ä¹è·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.join(current_dir, '..', '..')
    background_music_path = os.path.join(project_root, 'åå°”å…¹.mp3')
    
    # é…ç½®è¾“å…¥å‚æ•°
    inputs = {
        # 'digital_video_url': 'https://oss.oemi.jdword.com/prod/order/video/202509/V20250901153106001.mp4',
        # 'audio_url': 'https://oss.oemi.jdword.com/prod/temp/srt/V20250901152556001.wav',
        # 'title': 'ç«å±±å¼•æ“ASRæ™ºèƒ½å­—å¹•æ¼”ç¤º',
        
        "audio_url": "https://oss.oemi.jdword.com/prod/temp/srt/V20250903210905001.wav",
        "content": "ä¸ºä»€ä¹ˆå¥³å­©è¶Šæ¼‚äº®è¶Šåº”è¯¥å¥½å¥½è¯»ä¹¦ï¼Œæœ‰ä¸ªä½œå®¶è¯´æˆ‘ç¾è²Œå¯¹äºå¯Œäººæ¥è¯´æ˜¯é”¦ä¸Šæ·»èŠ±ï¼Œå¯¹äºä¸­äº§æ¥è¯´æ˜¯ä¸€ç¬”è´¢å¯Œï¼Œä½†å¯¹äºç©·äººæ¥è¯´å°±æ˜¯ç¾éš¾ã€‚",
        "recordId": "",
        "tableId": "",
        "title": "æ¼‚äº®å¥³å­©ä¸è¯»ä¹¦ç¾è²ŒçœŸæ˜¯ç¾éš¾å—",
        "digital_video_url": "https://oss.oemi.jdword.com/prod/order/video/202509/V20250903211536001.mp4",      

        
        # ğŸ”¥ ç«å±±å¼•æ“ASRé…ç½®ï¼ˆç”¨äºè¯­éŸ³è¯†åˆ«ï¼‰
        'volcengine_appid': '6046310832',                # ç«å±±å¼•æ“ASR AppID
        'volcengine_access_token': 'fMotJVOsyk6K_dDRoqM14kGdMJYBrcJY',  # ç«å±±å¼•æ“ASR AccessToken
        
        # ğŸ¤– è±†åŒ…APIé…ç½®ï¼ˆç”¨äºå…³é”®è¯æå–ï¼‰
        'doubao_token': 'adac0afb-5fd4-4c66-badb-370a7ff42df5',  # è¯·æ›¿æ¢ä¸ºæ‚¨çš„è±†åŒ…API token
        'doubao_model': 'doubao-1-5-pro-32k-250115',  # è±†åŒ…æ¨¡å‹åç§°
        
        # [INFO] èƒŒæ™¯éŸ³ä¹é…ç½®
        'background_music_path': background_music_path,  # åå°”å…¹.mp3è·¯å¾„
        'background_music_volume': 0.25,  # èƒŒæ™¯éŸ³ä¹éŸ³é‡
    }
    
    try:
        print(f"\n[INFO] å¼€å§‹å¤„ç†å·¥ä½œæµ...")
        save_path = workflow.process_workflow(inputs)
        print(f"\n[OK] éŸ³é¢‘è½¬å½•å·¥ä½œæµå®Œæˆ!")
        print(f"å‰ªæ˜ é¡¹ç›®å·²ä¿å­˜åˆ°: {save_path}")
        print("[INFO] è¯·æ‰“å¼€å‰ªæ˜ æŸ¥çœ‹ç”Ÿæˆçš„æ™ºèƒ½å­—å¹•è§†é¢‘é¡¹ç›®")
        
    except Exception as e:
        print(f"[ERROR] å·¥ä½œæµå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()