"""
åŸºäºflow.jsonçš„Pythonå®ç° - ç®€åŒ–ç‰ˆï¼ˆåªä½¿ç”¨ç«å±±å¼•æ“ASRï¼‰
ä½¿ç”¨pyJianYingDraftåŒ…é‡æ–°å®ç°è§†é¢‘ç¼–è¾‘å·¥ä½œæµé€»è¾‘
"""

import os
import json
import sys

# æ·»åŠ æœ¬åœ° pyJianYingDraft æ¨¡å—è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.join(current_dir, '..', '..')
sys.path.insert(0, project_root)

import pyJianYingDraft as draft
from pyJianYingDraft import TrackType, trange, tim, TextShadow, IntroType, TransitionType
from typing import List, Dict, Any, Optional, Tuple
import requests
from datetime import datetime
from urllib.parse import urlparse
import re
import math

# ç«å±±å¼•æ“ASR - å”¯ä¸€å­—å¹•è¯†åˆ«æ–¹æ¡ˆ
try:
    from .volcengine_asr import VolcengineASR
except ImportError:
    # å½“ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶ï¼Œä½¿ç”¨ç»å¯¹å¯¼å…¥
    from volcengine_asr import VolcengineASR


class VideoEditingWorkflow:
    """è§†é¢‘ç¼–è¾‘å·¥ä½œæµç±»ï¼ŒåŸºäºflow.jsonçš„é€»è¾‘å®ç°"""
    
    def __init__(self, draft_folder_path: str, project_name: str = "flow_project"):
        """åˆå§‹åŒ–å·¥ä½œæµ
        
        Args:
            draft_folder_path: å‰ªæ˜ è‰ç¨¿æ–‡ä»¶å¤¹è·¯å¾„
            project_name: é¡¹ç›®åç§°
        """
        self.draft_folder = draft.DraftFolder(draft_folder_path)
        self.project_name = project_name
        self.script = None
        self.audio_duration = 0  # éŸ³é¢‘æ€»æ—¶é•¿ï¼ˆç§’ï¼‰
        self.video_duration = 0  # è§†é¢‘æ€»æ—¶é•¿ï¼ˆç§’ï¼‰
        self.project_duration = 0  # é¡¹ç›®æ€»æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œå–éŸ³è§†é¢‘æœ€é•¿è€…
        self.volcengine_asr = None  # ç«å±±å¼•æ“ASRå®¢æˆ·ç«¯
        
    def _split_title_to_three_lines(self, title: str) -> List[str]:
        """ä½¿ç”¨è±†åŒ…æ¨¡å‹å°†æ ‡é¢˜æ™ºèƒ½æ‹†åˆ†ä¸º3è¡Œï¼›å¤±è´¥æ—¶ä½¿ç”¨æœ¬åœ°å›é€€è§„åˆ™ã€‚
        Returns: [line1, line2, line3]
        """
        title = (title or "").strip()
        if not title:
            return ["", "", ""]

        # ä¼˜å…ˆèµ°è±†åŒ…API
        try:
            if self.volcengine_asr and self.volcengine_asr.doubao_token:
                payload = {
                    "model": self.volcengine_asr.doubao_model,
                    "messages": [
                        {"role": "system", "content": (
                            "ä½ æ˜¯æ–‡æ¡ˆæ’ç‰ˆåŠ©æ‰‹ã€‚è¯·æŠŠç»™å®šä¸­æ–‡æ ‡é¢˜åˆç†æ–­å¥ä¸º3è¡Œï¼Œ" \
                            "æ¯è¡Œå°½é‡è¯­ä¹‰å®Œæ•´ã€é•¿åº¦å‡è¡¡ã€‚åªè¿”å›ä¸‰è¡Œå†…å®¹ï¼Œç”¨\nåˆ†éš”ï¼Œä¸è¦é¢å¤–è¯´æ˜ã€‚"
                        )},
                        {"role": "user", "content": f"æ ‡é¢˜ï¼š{title}\nè¾“å‡º3è¡Œï¼š"}
                    ],
                    "max_tokens": 200,
                    "temperature": 0.3
                }
                resp = requests.post(
                    'https://ark.cn-beijing.volces.com/api/v3/chat/completions',
                    headers={
                        'Content-Type': 'application/json',
                        'Authorization': f'Bearer {self.volcengine_asr.doubao_token}'
                    },
                    json=payload,
                    timeout=20
                )
                if resp.status_code == 200:
                    content = resp.json().get('choices', [{}])[0].get('message', {}).get('content', '')
                    lines = [ln.strip() for ln in content.split("\n") if ln.strip()]
                    if len(lines) >= 3:
                        return lines[:3]
        except Exception as _:
            pass

        # æœ¬åœ°å›é€€ï¼šæŒ‰ä¸­æ–‡æ ‡ç‚¹åˆ‡åˆ†ï¼Œå†å‡åŒ€åˆå¹¶åˆ°ä¸‰ä»½
        import re
        tokens = re.split(r'[ï¼Œã€‚ï¼ï¼Ÿã€;ï¼›\s]+', title)
        tokens = [t for t in tokens if t]
        if not tokens:
            # æœ€ç®€å•é€€åŒ–ï¼šå¹³å‡åˆ‡å­—ç¬¦
            n = len(title)
            a = max(1, n // 3)
            b = max(1, (n - a) // 2)
            return [title[:a], title[a:a+b], title[a+b:]]

        target = [[], [], []]
        lengths = [0, 0, 0]
        for tok in tokens:
            i = lengths.index(min(lengths))
            target[i].append(tok)
            lengths[i] += len(tok)
        return [''.join(x) for x in target]

    def add_three_line_title(self, title: str,
                             start: float = 0.0,
                             duration: Optional[float] = None,
                             *,
                             transform_y: float = 0.72,
                             line_spacing: int = 4,
                             highlight_color: Tuple[float, float, float] = (1.0, 0.7529411765, 0.2470588235),
                             track_name: str = "æ ‡é¢˜å­—å¹•è½¨é“") -> draft.TextSegment:
        """æ·»åŠ ä¸‰è¡Œæ ‡é¢˜ï¼šä¸­é—´ä¸€è¡Œé«˜äº®ã€‚
        - å­—ä½“ï¼šä¿ªé‡‘é»‘ï¼›å­—å·ï¼š15ï¼›å·¦å¯¹é½ï¼›max_line_width=0.6ï¼›è‡ªåŠ¨æ¢è¡Œ
        - transform_y=0.72ï¼›è¡Œé—´è·å¯é…
        """
        if not self.script:
            raise ValueError("è¯·å…ˆåˆ›å»ºè‰ç¨¿")

        lines = self._split_title_to_three_lines(title)
        # ä¿éšœä¸‰è¡Œ
        while len(lines) < 3:
            lines.append("")
        text = "\n".join(lines[:3])

        # è®¡ç®—æ—¶é—´
        if duration is None:
            base = self.project_duration or self.audio_duration or 5.0
            duration = max(1.0, min(base, base))

        style = draft.TextStyle(
            size=15.0,
            bold=True,
            align=0,  # å·¦å¯¹é½
            color=(1.0, 1.0, 1.0),
            auto_wrapping=True,
            max_line_width=0.7,
            line_spacing=line_spacing
        )

        seg = draft.TextSegment(
            text,
            trange(tim(f"{start}s"), tim(f"{duration}s")),
            font=draft.FontType.ä¿ªé‡‘é»‘,
            style=style,
            clip_settings=draft.ClipSettings(transform_y=transform_y)
        )

        # ä¸­é—´è¡Œé«˜äº®ï¼šè®¡ç®—å­—ç¬¦åŒºé—´
        line1 = lines[0]
        line2 = lines[1]
        start_idx = len(line1) + 1  # åŒ…å«æ¢è¡Œ
        end_idx = start_idx + len(line2)
        if len(line2) > 0:
            seg.add_highlight(start_idx, end_idx, color=highlight_color, bold=True)

        # ç¡®ä¿è½¨é“ï¼ˆæŒ‰è°ƒç”¨é¡ºåºè®¾ç½®å±‚çº§ï¼‰
        try:
            _ = self.script.tracks[track_name]
        except KeyError:
            # è®¡ç®—ä¸‹ä¸€ä¸ªå¯ç”¨çš„ç›¸å¯¹ç´¢å¼•ï¼ˆåŸºäºç°æœ‰è½¨é“æ•°é‡ï¼‰
            existing_text_tracks = [name for name in self.script.tracks.keys() 
                                  if self.script.tracks[name].track_type == TrackType.text]
            next_index = len(existing_text_tracks) + 1
            self.script.add_track(TrackType.text, track_name, relative_index=next_index)

        self.script.add_segment(seg, track_name=track_name)
        print(f"âœ… ä¸‰è¡Œæ ‡é¢˜å·²æ·»åŠ åˆ° {track_name}: {lines}")
        return seg

    def _update_project_duration(self):
        """æ›´æ–°é¡¹ç›®æ€»æ—¶é•¿ï¼Œå–éŸ³è§†é¢‘ä¸­çš„æœ€é•¿è€…"""
        self.project_duration = max(self.audio_duration, self.video_duration)
        if self.project_duration > 0:
            print(f"ğŸ“Š é¡¹ç›®æ€»æ—¶é•¿æ›´æ–°ä¸º: {self.project_duration:.1f} ç§’ (éŸ³é¢‘: {self.audio_duration:.1f}s, è§†é¢‘: {self.video_duration:.1f}s)")
        
    def download_material(self, url: str, local_path: str) -> str:
        """ä¸‹è½½ç½‘ç»œç´ æåˆ°æœ¬åœ°
        
        Args:
            url: ç´ æURL
            local_path: æœ¬åœ°ä¿å­˜è·¯å¾„
            
        Returns:
            æœ¬åœ°æ–‡ä»¶è·¯å¾„
        """
        if not url or url.startswith('file://') or os.path.exists(url):
            return url
            
        try:
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(local_path), exist_ok=True)
            
            with open(local_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
                    
            return local_path
        except Exception as e:
            print(f"ä¸‹è½½ç´ æå¤±è´¥: {url}, é”™è¯¯: {e}")
            return url  # è¿”å›åŸURLï¼Œè®©ç”¨æˆ·å¤„ç†
    
    def create_draft(self, width: int = 1080, height: int = 1920, fps: int = 30):
        """åˆ›å»ºå‰ªæ˜ è‰ç¨¿
        
        Args:
            width: è§†é¢‘å®½åº¦
            height: è§†é¢‘é«˜åº¦  
            fps: å¸§ç‡
        """
        try:
            self.script = self.draft_folder.create_draft(
                self.project_name, width, height, allow_replace=True
            )
        except PermissionError as e:
            # å¯èƒ½å­˜åœ¨ .locked æ–‡ä»¶æˆ–è‰ç¨¿è¢«å ç”¨ï¼›å›é€€ä¸ºæ—¶é—´æˆ³æ–°åç§°é¿å…å†²çª
            ts = datetime.now().strftime('%Y%m%d_%H%M%S')
            fallback_name = f"{self.project_name}_{ts}"
            print(f"âš ï¸  å‘ç°é”å®šæ–‡ä»¶æˆ–å ç”¨ï¼Œåˆ‡æ¢åˆ°æ–°é¡¹ç›®åç§°: {fallback_name}")
            self.project_name = fallback_name
            self.script = self.draft_folder.create_draft(
                self.project_name, width, height, allow_replace=False
            )
        except Exception as e:
            # å…¶ä»–å¼‚å¸¸ä¹Ÿå°è¯•ä½¿ç”¨æ—¶é—´æˆ³æ–°åç§°
            ts = datetime.now().strftime('%Y%m%d_%H%M%S')
            fallback_name = f"{self.project_name}_{ts}"
            print(f"âš ï¸  åˆ›å»ºè‰ç¨¿å¤±è´¥({e})ï¼Œæ”¹ç”¨æ–°é¡¹ç›®åç§°: {fallback_name}")
            self.project_name = fallback_name
            self.script = self.draft_folder.create_draft(
                self.project_name, width, height, allow_replace=False
            )
        
        # æ·»åŠ åŸºç¡€è½¨é“ï¼ˆé€šè¿‡è°ƒç”¨é¡ºåºæ§åˆ¶å±‚çº§ï¼Œç´¢å¼•é€’å¢ï¼‰
        self.script.add_track(TrackType.video, "ä¸»è§†é¢‘è½¨é“", relative_index=1)
        self.script.add_track(TrackType.video, "æ•°å­—äººè§†é¢‘è½¨é“", relative_index=2)  
        self.script.add_track(TrackType.audio, "éŸ³é¢‘è½¨é“", relative_index=3)
        self.script.add_track(TrackType.audio, "èƒŒæ™¯éŸ³ä¹è½¨é“", relative_index=4)
        # æ–‡æœ¬ç±»ï¼šæŒ‰è°ƒç”¨é¡ºåºè®¾ç½®å±‚çº§
        self.script.add_track(TrackType.text, "å†…å®¹å­—å¹•è½¨é“", relative_index=5)
        self.script.add_track(TrackType.text, "æ ‡é¢˜å­—å¹•è½¨é“", relative_index=6)
        
        return self.script
    
    def add_videos(self, video_urls: List[str], timelines: List[Dict[str, int]], 
                   volume: float = 1.0, track_index: int = 0) -> List[draft.VideoSegment]:
        """æ‰¹é‡æ·»åŠ è§†é¢‘
        
        Args:
            video_urls: è§†é¢‘URLåˆ—è¡¨
            timelines: æ—¶é—´è½´ä¿¡æ¯åˆ—è¡¨ï¼ŒåŒ…å«startå’Œend(å•ä½ï¼šç§’)
            volume: éŸ³é‡(0-1)
            track_index: è½¨é“ç´¢å¼•
            
        Returns:
            è§†é¢‘ç‰‡æ®µåˆ—è¡¨
        """
        if not self.script:
            raise ValueError("è¯·å…ˆåˆ›å»ºè‰ç¨¿")
            
        video_segments = []
        total_video_duration = 0
        
        for i, (video_url, timeline) in enumerate(zip(video_urls, timelines)):
            # ä¸‹è½½è§†é¢‘åˆ°æœ¬åœ°
            local_video_path = self.download_material(
                video_url, 
                f"temp_materials/video_{i}.mp4"
            )
            
            # è®¡ç®—æ—¶é—´èŒƒå›´
            start_time = timeline.get('start', 0)  # ç§’
            duration = timeline.get('end', 10) - start_time  # æŒç»­æ—¶é•¿
            
            # åˆ›å»ºè§†é¢‘ç‰‡æ®µ
            video_segment = draft.VideoSegment(
                local_video_path,
                trange(tim(f"{start_time}s"), tim(f"{duration}s"))
            )
            
            # è®¾ç½®éŸ³é‡
            if hasattr(video_segment, 'set_volume'):
                video_segment.set_volume(volume)
            
            video_segments.append(video_segment)
            
            # æ·»åŠ åˆ°ä¸»è§†é¢‘è½¨é“
            self.script.add_segment(video_segment, track_name="ä¸»è§†é¢‘è½¨é“")
            
            # ç´¯è®¡è§†é¢‘æ—¶é•¿
            total_video_duration += duration
            
        # æ›´æ–°è§†é¢‘æ€»æ—¶é•¿
        self.video_duration = total_video_duration
        self._update_project_duration()
        print(f"ğŸ“Š è§†é¢‘æ€»æ—¶é•¿: {self.video_duration:.1f} ç§’")
            
        return video_segments
    
    def add_digital_human_video(self, digital_video_url: str, duration: int = None):
        """æ·»åŠ æ•°å­—äººè§†é¢‘
        
        Args:
            digital_video_url: æ•°å­—äººè§†é¢‘URL
            duration: æŒç»­æ—¶é•¿(ç§’)ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨æ•´ä¸ªè§†é¢‘
        """
        if not self.script:
            raise ValueError("è¯·å…ˆåˆ›å»ºè‰ç¨¿")
            
        # ä¸‹è½½æ•°å­—äººè§†é¢‘
        local_path = self.download_material(
            digital_video_url,
            "temp_materials/digital_human.mp4"
        )
        
        # è·å–è§†é¢‘ç´ æä¿¡æ¯
        video_material = draft.VideoMaterial(local_path)
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæŒç»­æ—¶é•¿ï¼Œä½¿ç”¨æ•´ä¸ªè§†é¢‘
        if duration is None:
            duration_microseconds = video_material.duration
            duration_seconds = duration_microseconds / 1000000
        else:
            duration_microseconds = tim(f"{duration}s")
            duration_seconds = duration
        
        # åˆ›å»ºæ•°å­—äººè§†é¢‘ç‰‡æ®µ
        digital_segment = draft.VideoSegment(
            video_material,
            trange(tim("0s"), duration_microseconds)
        )
        
        # æ·»åŠ åˆ°æ•°å­—äººè§†é¢‘è½¨é“
        self.script.add_segment(digital_segment, track_name="æ•°å­—äººè§†é¢‘è½¨é“")
        
        # æ›´æ–°è§†é¢‘æ—¶é•¿
        self.video_duration = max(self.video_duration, duration_seconds)
        self._update_project_duration()
        print(f"ğŸ“Š æ•°å­—äººè§†é¢‘æ—¶é•¿: {duration_seconds:.1f} ç§’")
        
        return digital_segment
    
    def add_audio(self, audio_url: str, duration: int = None, volume: float = 1.0):
        """æ·»åŠ éŸ³é¢‘
        
        Args:
            audio_url: éŸ³é¢‘URL
            duration: æŒç»­æ—¶é•¿(ç§’)ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ•´ä¸ªéŸ³é¢‘ï¼Œå¦‚æœæœ‰è§†é¢‘åˆ™é™åˆ¶ä¸ºè§†é¢‘æ—¶é•¿
            volume: éŸ³é‡(0-1)
        """
        if not self.script:
            raise ValueError("è¯·å…ˆåˆ›å»ºè‰ç¨¿")
            
        # ä¸‹è½½éŸ³é¢‘
        local_path = self.download_material(
            audio_url,
            "temp_materials/audio.mp3"
        )
        
        # è·å–éŸ³é¢‘ç´ æä¿¡æ¯
        audio_material = draft.AudioMaterial(local_path)
        original_audio_duration = audio_material.duration / 1000000  # è½¬æ¢ä¸ºç§’
        
        # ç¡®å®šå®é™…éŸ³é¢‘æ—¶é•¿
        if duration is None:
            # å¦‚æœæœ‰è§†é¢‘ï¼ŒéŸ³é¢‘æ—¶é•¿ä¸åº”è¶…è¿‡è§†é¢‘æ—¶é•¿
            if self.video_duration > 0:
                actual_duration = min(original_audio_duration, self.video_duration)
                if original_audio_duration > self.video_duration:
                    print(f"âš ï¸  éŸ³é¢‘æ—¶é•¿({original_audio_duration:.1f}s)è¶…è¿‡è§†é¢‘æ—¶é•¿({self.video_duration:.1f}s)ï¼Œå°†æˆªå–è‡³è§†é¢‘æ—¶é•¿")
            else:
                actual_duration = original_audio_duration
        else:
            # å¦‚æœæœ‰è§†é¢‘ï¼Œæ£€æŸ¥æŒ‡å®šæ—¶é•¿æ˜¯å¦è¶…è¿‡è§†é¢‘æ—¶é•¿
            if self.video_duration > 0 and duration > self.video_duration:
                actual_duration = self.video_duration
                print(f"âš ï¸  æŒ‡å®šéŸ³é¢‘æ—¶é•¿({duration:.1f}s)è¶…è¿‡è§†é¢‘æ—¶é•¿({self.video_duration:.1f}s)ï¼Œå°†æˆªå–è‡³è§†é¢‘æ—¶é•¿")
            else:
                actual_duration = duration
        
        duration_microseconds = tim(f"{actual_duration}s")
        self.audio_duration = actual_duration
        
        # åˆ›å»ºéŸ³é¢‘ç‰‡æ®µ
        audio_segment = draft.AudioSegment(
            audio_material,
            trange(tim("0s"), duration_microseconds),
            volume=volume
        )
        
        # æ·»åŠ æ·¡å…¥æ·¡å‡º
        audio_segment.add_fade(tim("0.5s"), tim("0.5s"))
        
        # æ·»åŠ åˆ°éŸ³é¢‘è½¨é“
        self.script.add_segment(audio_segment, track_name="éŸ³é¢‘è½¨é“")
        
        # æ›´æ–°é¡¹ç›®æ—¶é•¿
        self._update_project_duration()
        print(f"ğŸ“Š éŸ³é¢‘æ—¶é•¿: {self.audio_duration:.1f} ç§’")
        
        return audio_segment
    
    def add_background_music(self, music_path: str, target_duration: float = None, volume: float = 0.3):
        """æ·»åŠ èƒŒæ™¯éŸ³ä¹
        
        Args:
            music_path: èƒŒæ™¯éŸ³ä¹æ–‡ä»¶è·¯å¾„ï¼ˆæœ¬åœ°è·¯å¾„ï¼‰
            target_duration: ç›®æ ‡æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œå¦‚æœNoneåˆ™ä½¿ç”¨é¡¹ç›®æ€»æ—¶é•¿ï¼ˆéŸ³è§†é¢‘ä¸­æœ€é•¿è€…ï¼‰
            volume: éŸ³é‡(0-1)ï¼Œé»˜è®¤0.3æ¯”è¾ƒé€‚åˆèƒŒæ™¯éŸ³ä¹
        """
        if not self.script:
            raise ValueError("è¯·å…ˆåˆ›å»ºè‰ç¨¿")
            
        if not os.path.exists(music_path):
            raise ValueError(f"èƒŒæ™¯éŸ³ä¹æ–‡ä»¶ä¸å­˜åœ¨: {music_path}")
        
        # è·å–èƒŒæ™¯éŸ³ä¹ç´ æä¿¡æ¯
        bg_music_material = draft.AudioMaterial(music_path)
        
        # ç¡®å®šç›®æ ‡æ—¶é•¿ - ä¼˜å…ˆä½¿ç”¨é¡¹ç›®æ€»æ—¶é•¿ç¡®ä¿éŸ³è§†é¢‘åŒæ­¥
        if target_duration is None:
            if self.project_duration > 0:
                target_duration = self.project_duration
                print(f"ğŸµ èƒŒæ™¯éŸ³ä¹å°†ä½¿ç”¨é¡¹ç›®æ€»æ—¶é•¿: {target_duration:.1f}s (ç¡®ä¿ä¸éŸ³è§†é¢‘åŒæ­¥)")
            elif self.video_duration > 0:
                target_duration = self.video_duration
                print(f"ğŸµ èƒŒæ™¯éŸ³ä¹å°†ä½¿ç”¨è§†é¢‘æ—¶é•¿: {target_duration:.1f}s")
            elif self.audio_duration > 0:
                target_duration = self.audio_duration
                print(f"ğŸµ èƒŒæ™¯éŸ³ä¹å°†ä½¿ç”¨éŸ³é¢‘æ—¶é•¿: {target_duration:.1f}s")
            else:
                raise ValueError("æ— æ³•ç¡®å®šç›®æ ‡æ—¶é•¿ï¼Œè¯·å…ˆæ·»åŠ éŸ³é¢‘æˆ–è§†é¢‘ï¼Œæˆ–æŒ‡å®štarget_duration")
        
        target_duration_microseconds = tim(f"{target_duration}s")
        bg_music_duration_microseconds = bg_music_material.duration
        
        # è®¡ç®—æ˜¯å¦éœ€è¦å¾ªç¯æ’­æ”¾
        bg_music_duration_seconds = bg_music_duration_microseconds / 1000000
        
        if bg_music_duration_seconds >= target_duration:
            # èƒŒæ™¯éŸ³ä¹å¤Ÿé•¿ï¼Œç›´æ¥æˆªå–
            bg_music_segment = draft.AudioSegment(
                bg_music_material,
                trange(tim("0s"), target_duration_microseconds),
                volume=volume
            )
            # æ·»åŠ æ·¡å…¥æ·¡å‡º
            bg_music_segment.add_fade(tim("1.0s"), tim("1.0s"))
            # æ·»åŠ åˆ°èƒŒæ™¯éŸ³ä¹è½¨é“
            self.script.add_segment(bg_music_segment, track_name="èƒŒæ™¯éŸ³ä¹è½¨é“")
            print(f"ğŸµ èƒŒæ™¯éŸ³ä¹å·²æ·»åŠ : {os.path.basename(music_path)}ï¼Œæˆªå–æ—¶é•¿: {target_duration:.1f}sï¼ŒéŸ³é‡: {volume}")
        else:
            # èƒŒæ™¯éŸ³ä¹å¤ªçŸ­ï¼Œéœ€è¦å¾ªç¯
            print(f"ğŸµ èƒŒæ™¯éŸ³ä¹æ—¶é•¿ {bg_music_duration_seconds:.1f}sï¼Œç›®æ ‡æ—¶é•¿ {target_duration:.1f}sï¼Œå°†å¾ªç¯æ’­æ”¾")
            
            # è®¡ç®—éœ€è¦å¾ªç¯çš„æ¬¡æ•°
            loop_count = int(target_duration / bg_music_duration_seconds) + 1
            current_time = 0
            
            for i in range(loop_count):
                # è®¡ç®—å½“å‰å¾ªç¯çš„æŒç»­æ—¶é—´
                remaining_time = target_duration - current_time
                if remaining_time <= 0:
                    break
                    
                current_duration = min(bg_music_duration_seconds, remaining_time)
                
                # åˆ›å»ºå½“å‰å¾ªç¯çš„éŸ³é¢‘ç‰‡æ®µ
                loop_segment = draft.AudioSegment(
                    bg_music_material,
                    trange(tim(f"{current_time}s"), tim(f"{current_duration}s")),
                    volume=volume
                )
                
                # ä¸ºç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªç‰‡æ®µæ·»åŠ æ·¡å…¥æ·¡å‡º
                if i == 0:  # ç¬¬ä¸€ä¸ªç‰‡æ®µï¼Œæ·»åŠ æ·¡å…¥
                    loop_segment.add_fade(tim("1.0s"), tim("0s"))
                if current_time + current_duration >= target_duration - 0.1:  # æœ€åä¸€ä¸ªç‰‡æ®µï¼Œæ·»åŠ æ·¡å‡º
                    loop_segment.add_fade(tim("0s"), tim("1.0s"))
                
                # æ·»åŠ åˆ°èƒŒæ™¯éŸ³ä¹è½¨é“
                self.script.add_segment(loop_segment, track_name="èƒŒæ™¯éŸ³ä¹è½¨é“")
                
                current_time += current_duration
            
            print(f"ğŸµ èƒŒæ™¯éŸ³ä¹å¾ªç¯å·²æ·»åŠ : {os.path.basename(music_path)}ï¼Œ{loop_count}æ¬¡å¾ªç¯ï¼Œæ€»æ—¶é•¿: {target_duration:.1f}sï¼ŒéŸ³é‡: {volume}")
        
        return
    
    def add_styled_text_with_background(self, text_content: str, timerange_start: float, timerange_duration: float,
                                       track_name: str = "æ ‡é¢˜å­—å¹•è½¨é“", position: str = "center",
                                       background_style: Dict[str, Any] = None,
                                       text_transform_y: Optional[float] = None,
                                       line_spacing: int = 0,
                                       bg_height: Optional[float] = None) -> draft.TextSegment:
        """æ·»åŠ å¸¦èƒŒæ™¯çš„æ ·å¼åŒ–æ–‡æœ¬
        
        Args:
            text_content: æ–‡æœ¬å†…å®¹ï¼ˆæ”¯æŒæ¢è¡Œç¬¦\\nï¼‰
            timerange_start: å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
            timerange_duration: æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
            track_name: è½¨é“åç§°
            position: æ–‡æœ¬ä½ç½® ("top"é¡¶éƒ¨, "center"ä¸­é—´, "bottom"åº•éƒ¨)
            background_style: èƒŒæ™¯æ ·å¼å‚æ•°å­—å…¸
            text_transform_y: æ–‡æœ¬ç‰‡æ®µçš„transform_yï¼ˆ-1.0~1.0ï¼‰ã€‚ä¼ å…¥åˆ™è¦†ç›–positionæ˜ å°„ã€‚
            line_spacing: è¡Œé—´è·ï¼ˆä¸å‰ªæ˜ ä¸€è‡´çš„æ•´æ•°å•ä½ï¼Œé»˜è®¤0ï¼‰ã€‚
            bg_height: èƒŒæ™¯é«˜åº¦æ¯”ä¾‹ï¼ˆ0.0-1.0ï¼‰ã€‚ä¼ å…¥åˆ™è¦†ç›– background_style["height"]ã€‚
            
        Returns:
            åˆ›å»ºçš„æ–‡æœ¬ç‰‡æ®µ
        """
        if not self.script:
            raise ValueError("è¯·å…ˆåˆ›å»ºè‰ç¨¿")
        
        # é»˜è®¤èƒŒæ™¯æ ·å¼ï¼ˆæ ¹æ®æ‚¨æä¾›çš„æˆªå›¾å‚æ•°ï¼‰
        if background_style is None:
            background_style = {
                "color": "#000000",      # é»‘è‰²
                "alpha": 0.67,           # 67% ä¸é€æ˜åº¦
                "height": 0.31,          # 31% é«˜åº¦
                "width": 0.14,           # 14% å®½åº¦  
                "horizontal_offset": 0.5, # 50% å·¦å³é—´éš™
                "vertical_offset": 0.5,   # 50% ä¸Šä¸‹é—´éš™
                "round_radius": 0.0,     # åœ†è§’åŠå¾„
                "style": 1               # èƒŒæ™¯æ ·å¼
            }
        
        # æ ¹æ®ä½ç½®è®¾ç½®å‚ç›´åç§»ï¼ˆtransform_yï¼‰ï¼Œå¯è¢«text_transform_yè¦†ç›–
        if position == "top":
            transform_y = 0.4
        elif position == "center":
            transform_y = 0.0
        else:  # bottom
            transform_y = -0.4
        if text_transform_y is not None:
            # æ”¯æŒæ•´æ•°è¾“å…¥ï¼šè‹¥ä¸º-100~100æŒ‰ç™¾åˆ†æ¯”æ˜ å°„åˆ°-1~1ï¼›è‹¥å·²åœ¨-1~1å†…åˆ™ç›´æ¥ä½¿ç”¨
            ty = float(text_transform_y)
            if isinstance(text_transform_y, int) and abs(ty) > 1:
                ty = ty / 100.0
            transform_y = max(-1.0, min(1.0, ty))
        
        # è¦†ç›–èƒŒæ™¯é«˜åº¦ï¼ˆè‹¥æä¾›ï¼‰
        if bg_height is not None:
            background_style["height"] = float(bg_height)

        # åˆ›å»ºæ–‡æœ¬èƒŒæ™¯
        text_background = draft.TextBackground(
            color=background_style["color"],
            alpha=background_style["alpha"],
            height=background_style["height"],
            width=background_style["width"],
            horizontal_offset=background_style["horizontal_offset"],
            vertical_offset=background_style["vertical_offset"],
            round_radius=background_style.get("round_radius", 0.0),
            style=background_style.get("style", 1)
        )
        
        # åˆ›å»ºæ–‡æœ¬æ ·å¼
        text_style = draft.TextStyle(
            size=15.0,
            color=(1.0, 1.0, 1.0),  # ç™½è‰²æ–‡å­—
            bold=True,
            align=0,  # å±…ä¸­å¯¹é½
            line_spacing=line_spacing
        )
        
        # åˆ›å»ºæ–‡æœ¬ç‰‡æ®µ
        text_segment = draft.TextSegment(
            text_content,
            trange(tim(f"{timerange_start}s"), tim(f"{timerange_duration}s")),
            font=draft.FontType.æ–‡è½©ä½“,
            style=text_style,
            clip_settings=draft.ClipSettings(transform_y=transform_y),
            background=text_background,
            shadow=draft.TextShadow(
                alpha=0.8,
                color=(0.0, 0.0, 0.0),
                diffuse=20.0,
                distance=10.0,
                angle=-45.0
            )
        )
        
        # ç¡®ä¿ç›®æ ‡è½¨é“å­˜åœ¨ï¼ˆè‹¥ä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»ºä¸ºæ–‡æœ¬è½¨é“ï¼ŒæŒ‰è°ƒç”¨é¡ºåºè®¾ç½®å±‚çº§ï¼‰
        try:
            _ = self.script.tracks[track_name]
        except KeyError:
            # è®¡ç®—ä¸‹ä¸€ä¸ªå¯ç”¨çš„ç›¸å¯¹ç´¢å¼•ï¼ˆåŸºäºç°æœ‰è½¨é“æ•°é‡ï¼‰
            existing_text_tracks = [name for name in self.script.tracks.keys() 
                                  if self.script.tracks[name].track_type == TrackType.text]
            next_index = len(existing_text_tracks) + 1
            self.script.add_track(TrackType.text, track_name, relative_index=next_index)

        # æ·»åŠ åˆ°è½¨é“
        self.script.add_segment(text_segment, track_name=track_name)
        
        print(f"âœ… å¸¦èƒŒæ™¯çš„æ–‡æœ¬å·²æ·»åŠ : '{text_content[:20]}...' åˆ° {track_name}")
        print(f"   èƒŒæ™¯: {background_style['color']} {background_style['alpha']*100:.0f}% é€æ˜åº¦")
        print(f"   ä½ç½®: {position}, æ—¶é•¿: {timerange_duration:.1f}ç§’")
        
        return text_segment
    
    def transcribe_audio_and_generate_subtitles(self, audio_url: str) -> List[Dict[str, Any]]:
        """ä½¿ç”¨ç«å±±å¼•æ“ASRè¿›è¡ŒéŸ³é¢‘è½¬å½•ç”Ÿæˆå­—å¹•
        
        Args:
            audio_url: éŸ³é¢‘URLï¼ˆæœ¬åœ°è·¯å¾„æˆ–ç½‘ç»œURLï¼‰
            
        Returns:
            å­—å¹•å¯¹è±¡æ•°ç»„ [{'text': str, 'start': float, 'end': float}, ...]
        """
        
        print(f"ğŸ¤ å¼€å§‹éŸ³é¢‘è½¬å½•: {audio_url}")
        print(f"ğŸ”¥ ä½¿ç”¨ç«å±±å¼•æ“ASRè¿›è¡Œè½¬å½•")
        
        try:
            if not self.volcengine_asr:
                print("âŒ ç«å±±å¼•æ“ASRæœªåˆå§‹åŒ–ï¼Œæ— æ³•è¿›è¡Œè½¬å½•")
                return []
            
            # ä½¿ç”¨ç«å±±å¼•æ“ASRè¿›è¡Œè½¬å½•
            subtitle_objects = self.volcengine_asr.process_audio_file(audio_url)
            
            if subtitle_objects:
                print(f"âœ… ç«å±±å¼•æ“è½¬å½•å®Œæˆï¼Œç”Ÿæˆ {len(subtitle_objects)} æ®µå­—å¹•")
                
                # æ˜¾ç¤ºæœ€ç»ˆçš„å¥å­å’Œæ—¶é—´æˆ³
                print(f"\nğŸ“‹ ç«å±±å¼•æ“ASRè½¬å½•ç»“æœ:")
                print("-" * 60)
                
                total_duration = 0
                for i, subtitle in enumerate(subtitle_objects, 1):
                    start = subtitle['start']
                    end = subtitle['end']
                    text = subtitle['text']
                    duration = end - start
                    total_duration += duration
                    
                    print(f"{i:2d}. [{start:7.3f}s-{end:7.3f}s] ({duration:5.2f}s) {text}")
                
                # æå–è½¬å½•çš„å®Œæ•´æ–‡æœ¬
                transcribed_text = " ".join([sub['text'] for sub in subtitle_objects])
                print(f"\nğŸ“ å®Œæ•´è½¬å½•æ–‡æœ¬: {transcribed_text}")
                print(f"ğŸ“Š ç»Ÿè®¡: {len(subtitle_objects)}æ®µ, æ€»æ—¶é•¿{total_duration:.1f}ç§’, å¹³å‡{total_duration/len(subtitle_objects):.1f}ç§’/æ®µ")
                
                return subtitle_objects
            else:
                print("âŒ ç«å±±å¼•æ“è½¬å½•å¤±è´¥")
                return []
                
        except Exception as e:
            print(f"âŒ éŸ³é¢‘è½¬å½•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return []
    
    def adjust_subtitle_timing(self, subtitle_objects: List[Dict[str, Any]],
                             delay_seconds: float = 0.0, 
                             speed_factor: float = 1.0) -> List[Dict[str, Any]]:
        """è°ƒæ•´å­—å¹•æ—¶é—´ - æ·»åŠ å»¶è¿Ÿå’Œè°ƒæ•´è¯­é€Ÿ
        
        Args:
            subtitle_objects: å­—å¹•å¯¹è±¡åˆ—è¡¨
            delay_seconds: å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œæ­£å€¼è¡¨ç¤ºå­—å¹•å»¶åï¼Œè´Ÿå€¼è¡¨ç¤ºå­—å¹•æå‰
            speed_factor: é€Ÿåº¦ç³»æ•°ï¼Œ>1è¡¨ç¤ºåŠ å¿«ï¼Œ<1è¡¨ç¤ºå‡æ…¢
            
        Returns:
            è°ƒæ•´åçš„å­—å¹•å¯¹è±¡åˆ—è¡¨
        """
        if not subtitle_objects:
            return []
        
        print(f"â° è°ƒæ•´å­—å¹•æ—¶é—´: å»¶è¿Ÿ={delay_seconds:.1f}s, é€Ÿåº¦ç³»æ•°={speed_factor:.2f}")
        
        adjusted_subtitles = []
        
        for i, subtitle in enumerate(subtitle_objects):
            # åº”ç”¨é€Ÿåº¦ç³»æ•°
            original_start = subtitle['start']
            original_end = subtitle['end']
            original_duration = original_end - original_start
            
            # è°ƒæ•´æ—¶é—´
            new_start = original_start / speed_factor + delay_seconds
            new_duration = original_duration / speed_factor
            new_end = new_start + new_duration
            
            # ç¡®ä¿æ—¶é—´ä¸ä¸ºè´Ÿ
            new_start = max(0, new_start)
            new_end = max(new_start + 0.5, new_end)  # æœ€å°‘0.5ç§’æ˜¾ç¤ºæ—¶é—´
            
            adjusted_subtitle = {
                'text': subtitle['text'],
                'start': new_start,
                'end': new_end
            }
            adjusted_subtitles.append(adjusted_subtitle)
            
            print(f"   ç¬¬{i+1}æ®µ: {original_start:.1f}s-{original_end:.1f}s â†’ {new_start:.1f}s-{new_end:.1f}s")
        
        print(f"âœ… å­—å¹•æ—¶é—´è°ƒæ•´å®Œæˆ")
        return adjusted_subtitles
    

    
    def add_captions(self, caption_data: List[Dict[str, Any]],
                    track_name: str = "å†…å®¹å­—å¹•è½¨é“", position: str = "bottom",
                    keywords: List[str] = None,
                    base_font_size: float = 8.0,
                    base_color: Tuple[float, float, float] = (1.0, 1.0, 1.0),
                    font_type: Optional[draft.FontType] = None,
                    highlight_color: Tuple[float, float, float] = (1.0, 0.7529411765, 0.2470588235),
                    highlight_size: float = 10.0,
                    bottom_transform_y: float = -0.3,
                    scale: float = 1.39):
        """æ·»åŠ å­—å¹•ï¼Œæ”¯æŒå…³é”®è¯é«˜äº®
        
        Args:
            caption_data: å­—å¹•æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«text, start, endç­‰ä¿¡æ¯
            font_size: å­—ä½“å¤§å°
            track_name: è½¨é“åç§°
            position: å­—å¹•ä½ç½® ("top"é¡¶éƒ¨, "bottom"åº•éƒ¨)
            keywords: éœ€è¦é«˜äº®çš„å…³é”®è¯åˆ—è¡¨
            keyword_color: å…³é”®è¯é«˜äº®é¢œè‰²ï¼Œé»˜è®¤ä¸ºé»„è‰²
        """
        if not self.script:
            raise ValueError("è¯·å…ˆåˆ›å»ºè‰ç¨¿")
            
        text_segments = []
        
        for caption in caption_data:
            text = caption.get('text', '')
            start_time = caption.get('start', 0)  # ç§’
            end_time = caption.get('end', start_time + 2)  # ç§’
            
            if not text:
                continue
                
            # æ ¹æ®ä½ç½®è®¾ç½®ä¸åŒçš„å‚ç›´ä½ç½®
            if position == "top":
                transform_y = 0.4
                text_color = base_color
            else:
                transform_y = bottom_transform_y
                text_color = base_color
                
            # è¿‡æ»¤å‡ºåœ¨å½“å‰æ–‡æœ¬ä¸­å®é™…å­˜åœ¨çš„å…³é”®è¯
            current_keywords = []
            if keywords:
                for keyword in keywords:
                    if keyword and keyword.strip() and keyword in text:
                        current_keywords.append(keyword)
                        
            # åˆ›å»ºæ–‡æœ¬ç‰‡æ®µï¼Œåªä¼ å…¥å½“å‰æ–‡æœ¬ä¸­å­˜åœ¨çš„å…³é”®è¯
            text_segment = draft.TextSegment(
                text,
                trange(tim(f"{start_time}s"), tim(f"{end_time - start_time}s")),
                font=(font_type if font_type is not None else draft.FontType.ä¿ªé‡‘é»‘),
                style=draft.TextStyle(
                    color=text_color,
                    size=base_font_size,
                    auto_wrapping=True,
                    bold=True,
                    align=0,
                    max_line_width=0.82
                ),
                clip_settings=draft.ClipSettings(transform_y=transform_y, scale_x=scale, scale_y=scale)
            )

            # å¤–éƒ¨ä¼ å…¥çš„å…³é”®è¯é«˜äº®ï¼šæŒ‰ç»™å®šé¢œè‰²ä¸å­—å·
            if current_keywords:
                for kw in current_keywords:
                    start_idx = 0
                    while True:
                        pos = text.find(kw, start_idx)
                        if pos == -1:
                            break
                        end_idx = pos + len(kw)
                        try:
                            text_segment.add_highlight(pos, end_idx, color=highlight_color, size=highlight_size, bold=True)
                        except Exception:
                            pass
                        start_idx = pos + 1
            
            # å¦‚æœæœ‰å…³é”®è¯è¢«é«˜äº®ï¼Œæ‰“å°è°ƒè¯•ä¿¡æ¯
            if current_keywords:
                print(f"   ğŸ¯ '{text}' ä¸­é«˜äº®å…³é”®è¯: {current_keywords}")
            
            text_segments.append(text_segment)
            self.script.add_segment(text_segment, track_name=track_name)
            
        return text_segments
    
    def add_caption_backgrounds(self, caption_data: List[Dict[str, Any]], 
                               position: str = "bottom",
                               bottom_transform_y: float = -0.3,
                               scale: float = 1.39,
                               background_style: Dict[str, Any] = None):
        """ä¸ºå­—å¹•æ·»åŠ èƒŒæ™¯è‰²å—ï¼ˆç‹¬ç«‹åŠŸèƒ½ï¼Œå…¨ç¨‹æ˜¾ç¤ºä¸€ä¸ªèƒŒæ™¯ï¼Œå¤ç”¨æ ‡é¢˜èƒŒæ™¯æ–¹æ³•ï¼‰
        
        Args:
            caption_data: å­—å¹•æ•°æ®åˆ—è¡¨ï¼Œç”¨äºè®¡ç®—æ€»æ—¶é•¿
            position: å­—å¹•ä½ç½® ("top"é¡¶éƒ¨, "bottom"åº•éƒ¨)
            bottom_transform_y: åº•éƒ¨ä½ç½®çš„transform_y
            scale: ç¼©æ”¾æ¯”ä¾‹
            background_style: èƒŒæ™¯æ ·å¼å‚æ•°
        """
        if not self.script:
            raise ValueError("è¯·å…ˆåˆ›å»ºè‰ç¨¿")
        
        if not caption_data:
            return None
        
        # é»˜è®¤èƒŒæ™¯æ ·å¼ï¼ˆå‚è€ƒæ ‡é¢˜èƒŒæ™¯æ ·å¼ï¼Œä½†é«˜åº¦è°ƒæ•´ä¸ºé€‚åˆå­—å¹•ï¼‰
        if background_style is None:
            background_style = {
                "color": "#000000",      # é»‘è‰²
                "alpha": 0.67,           # 67% ä¸é€æ˜åº¦
                "height": 0.25,          # 25% é«˜åº¦ï¼ˆæ¯”æ ‡é¢˜èƒŒæ™¯ç¨å°ï¼‰
                "width": 0.14,           # 14% å®½åº¦  
                "horizontal_offset": 0.5, # 50% å·¦å³é—´éš™
                "vertical_offset": 0.5,   # 50% ä¸Šä¸‹é—´éš™
                "round_radius": 0.0,     # åœ†è§’åŠå¾„
                "style": 1               # èƒŒæ™¯æ ·å¼
            }
        
        # è®¡ç®—å­—å¹•çš„æ€»æ—¶é•¿ï¼ˆä»ç¬¬ä¸€ä¸ªå­—å¹•å¼€å§‹åˆ°æœ€åä¸€ä¸ªå­—å¹•ç»“æŸï¼‰
        start_time = min(caption.get('start', 0) for caption in caption_data)
        end_time = max(caption.get('end', 0) for caption in caption_data)
        total_duration = end_time - start_time
        
        # æ ¹æ®ä½ç½®è®¾ç½®ä¸åŒçš„å‚ç›´ä½ç½®
        if position == "top":
            transform_y = 0.4
        else:
            transform_y = bottom_transform_y
        
        # åˆ›å»ºèƒŒæ™¯æ–‡æœ¬ç‰‡æ®µï¼ˆä½¿ç”¨å ä½ç¬¦ç¡®ä¿èƒŒæ™¯æ˜¾ç¤ºï¼‰
        placeholder_text = " " * 50  # ä½¿ç”¨å›ºå®šé•¿åº¦çš„å ä½ç¬¦
        
        # å¤ç”¨ add_styled_text_with_background æ–¹æ³•ï¼Œåˆ›å»ºå…¨ç¨‹æ˜¾ç¤ºçš„èƒŒæ™¯
        bg_segment = self.add_styled_text_with_background(
            text_content=placeholder_text,
            timerange_start=start_time,
            timerange_duration=total_duration,
            track_name="å†…å®¹å­—å¹•èƒŒæ™¯",
            position=position,
            background_style=background_style,
            text_transform_y=transform_y,
            line_spacing=0,
            bg_height=background_style["height"]
        )
        
        return bg_segment
    
    def add_transitions_and_effects(self, video_segments: List[draft.VideoSegment]):
        """ä¸ºè§†é¢‘ç‰‡æ®µæ·»åŠ è½¬åœºå’Œç‰¹æ•ˆ
        
        Args:
            video_segments: è§†é¢‘ç‰‡æ®µåˆ—è¡¨
        """
        for i, segment in enumerate(video_segments):
            # ä¸ºæ¯ä¸ªç‰‡æ®µæ·»åŠ å…¥åœºåŠ¨ç”»
            if i < len(video_segments) - 1:  # é™¤æœ€åä¸€ä¸ªç‰‡æ®µå¤–éƒ½æ·»åŠ è½¬åœº
                segment.add_transition(TransitionType.æ·¡åŒ–)
                
            # æ·»åŠ å…¥åœºåŠ¨ç”»
            segment.add_animation(IntroType.æ·¡å…¥)
    
    def process_workflow(self, inputs: Dict[str, Any]) -> str:
        """å¤„ç†å®Œæ•´çš„å·¥ä½œæµ - ä¸“æ³¨éŸ³é¢‘è½¬å½•ç”Ÿæˆå­—å¹•
        
        Args:
            inputs: è¾“å…¥å‚æ•°ï¼ŒåŒ…å«ï¼š
                - digital_video_url: æ•°å­—äººè§†é¢‘URL
                - material_video_url: ç´ æè§†é¢‘URL (å¯é€‰)
                - audio_url: éŸ³é¢‘URL (å¿…éœ€ï¼Œç”¨äºè½¬å½•)
                - title: è§†é¢‘æ ‡é¢˜ (å¯é€‰)
                - volcengine_appid: ç«å±±å¼•æ“AppID (å¿…éœ€)
                - volcengine_access_token: ç«å±±å¼•æ“è®¿é—®ä»¤ç‰Œ (å¿…éœ€)
                - subtitle_delay: å­—å¹•å»¶è¿Ÿï¼ˆç§’ï¼‰ï¼Œæ­£å€¼å»¶åï¼Œè´Ÿå€¼æå‰ (é»˜è®¤0)
                - subtitle_speed: å­—å¹•é€Ÿåº¦ç³»æ•°ï¼Œ>1åŠ å¿«ï¼Œ<1å‡æ…¢ (é»˜è®¤1.0)
                - background_music_path: èƒŒæ™¯éŸ³ä¹æ–‡ä»¶è·¯å¾„ (å¯é€‰)
                - background_music_volume: èƒŒæ™¯éŸ³ä¹éŸ³é‡ (é»˜è®¤0.3)
                
        Returns:
            è‰ç¨¿ä¿å­˜è·¯å¾„
        """
        # 0. è·å–é…ç½®å‚æ•°
        # ç«å±±å¼•æ“ASRé…ç½®ï¼ˆç”¨äºè¯­éŸ³è¯†åˆ«ï¼‰
        volcengine_appid = inputs.get('volcengine_appid')
        volcengine_access_token = inputs.get('volcengine_access_token')
        
        # è±†åŒ…APIé…ç½®ï¼ˆç”¨äºå…³é”®è¯æå–ï¼‰
        doubao_token = inputs.get('doubao_token')
        doubao_model = inputs.get('doubao_model', 'doubao-1-5-pro-32k-250115')
        
        # å…¶ä»–å‚æ•°
        audio_url = inputs.get('audio_url')
        subtitle_delay = inputs.get('subtitle_delay', 0.0)  # å­—å¹•å»¶è¿Ÿ
        subtitle_speed = inputs.get('subtitle_speed', 1.0)  # å­—å¹•é€Ÿåº¦ç³»æ•°
        background_music_path = inputs.get('background_music_path')  # èƒŒæ™¯éŸ³ä¹è·¯å¾„
        background_music_volume = inputs.get('background_music_volume', 0.3)  # èƒŒæ™¯éŸ³ä¹éŸ³é‡
        
        # éªŒè¯å¿…éœ€å‚æ•°
        if not audio_url:
            raise ValueError("audio_url æ˜¯å¿…éœ€å‚æ•°ï¼Œç”¨äºéŸ³é¢‘è½¬å½•")
        
        print(f"ğŸ¤ éŸ³é¢‘è½¬å½•å­—å¹•å·¥ä½œæµ + AIå…³é”®è¯é«˜äº®")
        print(f"ğŸ“¥ éŸ³é¢‘URL: {audio_url}")
        print(f"â° å­—å¹•å»¶è¿Ÿ: {subtitle_delay:.1f}ç§’")
        print(f"ğŸš€ å­—å¹•é€Ÿåº¦: {subtitle_speed:.1f}x")
        print(f"ğŸ”¥ ç«å±±å¼•æ“ASR (è¯­éŸ³è¯†åˆ«)")
        print(f"ğŸ¤– è±†åŒ…API (å…³é”®è¯æå–): {'å·²é…ç½®' if doubao_token else 'æœªé…ç½®ï¼Œå°†ä½¿ç”¨æœ¬åœ°ç®—æ³•'}")
        
        # åˆå§‹åŒ–ç«å±±å¼•æ“ASR
        if volcengine_appid and volcengine_access_token:
            self.volcengine_asr = VolcengineASR(
                appid=volcengine_appid, 
                access_token=volcengine_access_token,
                doubao_token=doubao_token,
                doubao_model=doubao_model
            )
            print(f"âœ… ç«å±±å¼•æ“ASRå·²åˆå§‹åŒ– (AppID: {volcengine_appid})")
            if doubao_token:
                print(f"âœ… è±†åŒ…APIå·²é…ç½® (Model: {doubao_model})")
        else:
            raise ValueError("å¿…é¡»æä¾› volcengine_appid å’Œ volcengine_access_token å‚æ•°")
        
        # 1. åˆ›å»ºè‰ç¨¿
        self.create_draft()
        
        # 2. æ·»åŠ æ•°å­—äººè§†é¢‘
        digital_video_url = inputs.get('digital_video_url')
        if digital_video_url:
            self.add_digital_human_video(digital_video_url)
        
        # 3. æ·»åŠ ç´ æè§†é¢‘ï¼ˆå¦‚æœæœ‰ï¼‰
        material_video_url = inputs.get('material_video_url')
        if material_video_url:
            # æ¨¡æ‹Ÿæ—¶é—´è½´æ•°æ®
            timelines = [{'start': 0, 'end': 10}]  # å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´
            self.add_videos([material_video_url], timelines, volume=0.3)
        
        # 4. æ·»åŠ éŸ³é¢‘
        self.add_audio(audio_url, volume=0.8)
        print(f"ğŸ“Š éŸ³é¢‘æ—¶é•¿: {self.audio_duration:.1f} ç§’")
        
        # 4.5. æ·»åŠ èƒŒæ™¯éŸ³ä¹ï¼ˆå¦‚æœæä¾›ï¼‰
        if background_music_path:
            print(f"ğŸµ å‡†å¤‡æ·»åŠ èƒŒæ™¯éŸ³ä¹: {background_music_path}")
            try:
                self.add_background_music(background_music_path, volume=background_music_volume)
                print(f"âœ… èƒŒæ™¯éŸ³ä¹å·²æˆåŠŸæ·»åŠ : {background_music_path}")
            except Exception as e:
                print(f"âŒ èƒŒæ™¯éŸ³ä¹æ·»åŠ å¤±è´¥: {e}")
                import traceback
                print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        else:
            print("ğŸ“‹ æœªæä¾›èƒŒæ™¯éŸ³ä¹è·¯å¾„ï¼Œè·³è¿‡èƒŒæ™¯éŸ³ä¹æ·»åŠ ")

        # 4.8 æ·»åŠ ä¸€ä¸ªä¸‰è¡Œæ–‡æœ¬å¹¶åº”ç”¨èƒŒæ™¯æ ·å¼ï¼ˆä½äºç”»é¢ä¸­éƒ¨ï¼‰
        try:
            multiline_text = "                                                           \n\n "
            # ä½¿ç”¨ä¸æˆªå›¾ä¸€è‡´çš„èƒŒæ™¯å‚æ•°
            background_style = {
                "color": "#000000",      # é»‘è‰²
                "alpha": 0.67,           # ä¸é€æ˜åº¦ 67%
                "height": 1,          # é«˜åº¦ 31%
                "width": 1,           # å®½åº¦ 14%
                "horizontal_offset": 0.5, # å·¦å³é—´éš™ 50%
                "vertical_offset": 0.5,   # ä¸Šä¸‹é—´éš™ 50%
                "round_radius": 0.0,
                "style": 1
            }
            # èƒŒæ™¯æ—¶é•¿ä¸æ ‡é¢˜ä¸€è‡´ï¼šä½¿ç”¨é¡¹ç›®æ€»æ—¶é•¿ï¼ˆæˆ–éŸ³é¢‘æ—¶é•¿ï¼‰
            display_duration = self.project_duration if self.project_duration > 0 else (self.audio_duration if self.audio_duration > 0 else 5.0)
            self.add_styled_text_with_background(
                text_content=multiline_text,
                timerange_start=0,
                timerange_duration=display_duration,
                track_name="æ ‡é¢˜å­—å¹•èƒŒæ™¯",
                position="center",
                background_style=background_style,
                text_transform_y=0.73,
                line_spacing=4,
                bg_height=0.48
            )
        except Exception as e:
            print(f"âŒ æ·»åŠ ä¸‰è¡ŒèƒŒæ™¯æ–‡å­—å¤±è´¥: {e}")
        
        # 5. ç”ŸæˆéŸ³é¢‘è½¬å½•å­—å¹•
        title = inputs.get('title', '')
        
        # éŸ³é¢‘è½¬å½•ç”Ÿæˆå­—å¹•
        print("ğŸ¤ å¼€å§‹éŸ³é¢‘è½¬å½•ç”Ÿæˆå­—å¹•")
        subtitle_objects = self.transcribe_audio_and_generate_subtitles(audio_url)
        print(f"ğŸ” éŸ³é¢‘è½¬å½•å­—å¹•: {subtitle_objects}")
        
        if subtitle_objects:
            print(f"âœ… éŸ³é¢‘è½¬å½•æˆåŠŸï¼Œç”Ÿæˆ {len(subtitle_objects)} æ®µå­—å¹•")
            
            # ğŸ”¥ ä½¿ç”¨ç«å±±å¼•æ“ASRç»“æœï¼Œç›´æ¥ä½¿ç”¨
            print(f"ğŸš€ ä½¿ç”¨ç«å±±å¼•æ“ASRç»“æœ")
            final_subtitles = subtitle_objects
            
            # åªåœ¨éœ€è¦æ—¶åº”ç”¨æ—¶é—´è°ƒæ•´
            if subtitle_delay != 0.0 or subtitle_speed != 1.0:
                print(f"â° åº”ç”¨æ—¶é—´è°ƒæ•´: å»¶è¿Ÿ{subtitle_delay:.1f}s, é€Ÿåº¦{subtitle_speed:.1f}x")
                final_subtitles = self.adjust_subtitle_timing(final_subtitles, subtitle_delay, subtitle_speed)
            
            # ğŸ¤– ä½¿ç”¨AIæå–å…³é”®è¯ç”¨äºé«˜äº®
            print("\nğŸ¤– å¼€å§‹AIå…³é”®è¯æå–...")
            all_text = " ".join([sub['text'] for sub in final_subtitles])
            keywords = self.volcengine_asr.extract_keywords_with_ai(all_text, max_keywords=8)
            
            if keywords:
                print(f"âœ… AIæå–åˆ° {len(keywords)} ä¸ªå…³é”®è¯: {keywords}")
                keyword_color = (1.0, 0.984313725490196, 0.7254901960784313)  # é»„è‰²é«˜äº®
            else:
                print("âš ï¸ æœªæå–åˆ°å…³é”®è¯ï¼Œä½¿ç”¨æ™®é€šå­—å¹•")
                keyword_color = None
            
            # æ·»åŠ å­—å¹•åˆ°è§†é¢‘é¡¹ç›®ï¼ˆå¸¦å…³é”®è¯é«˜äº®ï¼‰
            self.add_captions(final_subtitles, track_name="å†…å®¹å­—å¹•è½¨é“", position="bottom",
                            keywords=keywords, 
                            base_color=(1.0, 1.0, 1.0),  # ç™½è‰²
                            base_font_size=8.0,  # 8å·
                            font_type=draft.FontType.ä¿ªé‡‘é»‘,  # ä¿ªé‡‘é»‘
                            highlight_size=10.0,  # é«˜äº®10å·
                            highlight_color=(1.0, 0.7529411765, 0.2470588235),  # #ffc03f
                            scale=1.39)  # ç¼©æ”¾1.39
            
            # ä¸ºå­—å¹•æ·»åŠ èƒŒæ™¯è‰²å—ï¼ˆç‹¬ç«‹åŠŸèƒ½ï¼‰
            self.add_caption_backgrounds(final_subtitles, position="bottom", 
                                       bottom_transform_y=-0.3, scale=1.39)
            
            # æ˜¾ç¤ºå­—å¹•æ·»åŠ ç»“æœ
            print(f"\nğŸ“‹ å·²æ·»åŠ  {len(final_subtitles)} æ®µå­—å¹•åˆ°å‰ªæ˜ é¡¹ç›®")
            print("å‰3æ®µé¢„è§ˆ:")
            for i, subtitle in enumerate(final_subtitles[:3], 1):
                start = subtitle['start']
                end = subtitle['end']
                text = subtitle['text']
                print(f"   {i}. [{start:.3f}s-{end:.3f}s] {text}")
            
            # æ·»åŠ æ ‡é¢˜å­—å¹•ï¼ˆä¸‰è¡Œæ ‡é¢˜ï¼Œç¬¬äºŒè¡Œé«˜äº®ï¼‰
            if title:
                title_duration = self.project_duration if self.project_duration > 0 else self.audio_duration
                print(f"ğŸ“‹ æ·»åŠ ä¸‰è¡Œæ ‡é¢˜: {title} (0s - {title_duration:.1f}s)")
                self.add_three_line_title(
                    title=title,
                    start=0.0,
                    duration=title_duration,
                    transform_y=0.72,
                    line_spacing=4,
                    highlight_color=(1.0, 0.7529411765, 0.2470588235),  # #ffc03f
                    track_name="æ ‡é¢˜å­—å¹•è½¨é“"
                )
        else:
            print("âŒ éŸ³é¢‘è½¬å½•å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆå­—å¹•")
            raise ValueError("éŸ³é¢‘è½¬å½•å¤±è´¥ï¼Œè¯·æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶å’ŒAPIé…ç½®")
        
        # 6. ä¿å­˜è‰ç¨¿
        self.script.save()
        
        return self.script.save_path


def main():
    """ä¸»å‡½æ•° - éŸ³é¢‘è½¬å½•æ™ºèƒ½å­—å¹•å·¥ä½œæµ"""
    # é…ç½®å‰ªæ˜ è‰ç¨¿æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆéœ€è¦æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰
    draft_folder_path = r"C:\Users\nrgc\AppData\Local\JianyingPro\User Data\Projects\com.lveditor.draft"
    
    print("ğŸ¤ éŸ³é¢‘è½¬å½•æ™ºèƒ½å­—å¹•å·¥ä½œæµ + AIå…³é”®è¯é«˜äº® + èƒŒæ™¯éŸ³ä¹")
    print("=" * 60)
    print("è‡ªåŠ¨è½¬å½•éŸ³é¢‘å¹¶ç”Ÿæˆæ™ºèƒ½å­—å¹•ï¼Œä½¿ç”¨AIè¯†åˆ«å…³é”®è¯è¿›è¡Œé«˜äº®æ˜¾ç¤ºï¼Œå¹¶æ·»åŠ åå°”å…¹èƒŒæ™¯éŸ³ä¹")
    
    # åˆ›å»ºå·¥ä½œæµå®ä¾‹
    workflow = VideoEditingWorkflow(draft_folder_path, "audio_transcription_demo")
    
    # é…ç½®åå°”å…¹èƒŒæ™¯éŸ³ä¹è·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.join(current_dir, '..', '..')
    background_music_path = os.path.join(project_root, 'åå°”å…¹.mp3')
    
    # é…ç½®è¾“å…¥å‚æ•°
    inputs = {
        'digital_video_url': 'https://oss.oemi.jdword.com/prod/order/video/202509/V20250901153106001.mp4',
        'audio_url': 'https://oss.oemi.jdword.com/prod/temp/srt/V20250901152556001.wav',
        'title': 'ç«å±±å¼•æ“ASRæ™ºèƒ½å­—å¹•æ¼”ç¤º',
        
        # ğŸ”¥ ç«å±±å¼•æ“ASRé…ç½®ï¼ˆç”¨äºè¯­éŸ³è¯†åˆ«ï¼‰
        'volcengine_appid': '6046310832',                # ç«å±±å¼•æ“ASR AppID
        'volcengine_access_token': 'fMotJVOsyk6K_dDRoqM14kGdMJYBrcJY',  # ç«å±±å¼•æ“ASR AccessToken
        
        # ğŸ¤– è±†åŒ…APIé…ç½®ï¼ˆç”¨äºå…³é”®è¯æå–ï¼‰
        'doubao_token': 'adac0afb-5fd4-4c66-badb-370a7ff42df5',  # è¯·æ›¿æ¢ä¸ºæ‚¨çš„è±†åŒ…API token
        'doubao_model': 'doubao-1-5-pro-32k-250115',  # è±†åŒ…æ¨¡å‹åç§°
        
        # ğŸµ èƒŒæ™¯éŸ³ä¹é…ç½®
        'background_music_path': background_music_path,  # åå°”å…¹.mp3è·¯å¾„
        'background_music_volume': 0.25,  # èƒŒæ™¯éŸ³ä¹éŸ³é‡
    }
    
    try:
        print(f"\nğŸ¬ å¼€å§‹å¤„ç†å·¥ä½œæµ...")
        save_path = workflow.process_workflow(inputs)
        print(f"\nâœ… éŸ³é¢‘è½¬å½•å·¥ä½œæµå®Œæˆ!")
        print(f"ğŸ“ å‰ªæ˜ é¡¹ç›®å·²ä¿å­˜åˆ°: {save_path}")
        print("ğŸ¬ è¯·æ‰“å¼€å‰ªæ˜ æŸ¥çœ‹ç”Ÿæˆçš„æ™ºèƒ½å­—å¹•è§†é¢‘é¡¹ç›®")
        
    except Exception as e:
        print(f"âŒ å·¥ä½œæµå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()